![](images/300/300.JPG)  
Updated: December 20, 2017 for BDC Version 17.4.6

# Lab: More about Big Data Cloud

## Introduction

This lab will walk you through additional features of **Oracle Big Data Cloud**.  

In particular, this lab will focus on interacting with **Spark** and **Spark SQL**. 


Please direct comments to: David Bayard (david.bayard@oracle.com)

## Objectives

- Learn how to work with Spark and Spark SQL
- Learn how to work with Maps with Spark and Zeppelin

## Required Artifacts

- A running BDC instance and Storage Cloud Object Store instance, created as per the instructions in Lab 100.  These instructions included the use of a special "bootstrap.sh" script which setup the BDC environment for this workshop.
- You completed the tutorials in Lab 200 Getting to know Oracle Big Data Cloud



# Connect to the BDC Console

## Steps 

### **STEP 1**: Navigate/login to the Oracle Cloud My Services Dashboard  

![](images/300/snap0011988.jpg) 

### **STEP 2**: Navigate to the My Services page for your BDC cluster

![](images/300/snap0011989.jpg)  

### **STEP 3**: Launch the Big Data Cluster Console

![](images/300/snap0012205.jpg)  






# Learn how to work with Spark and Spark SQL

## Open and run the Tutorial 4 note in the notebook

### **STEP 1**: Click on the Notebook tab. Expand the Journeys folder.  Then expand the New Data Lake folder. 

![](images/200/snap0012200.jpg) 

### **STEP 2**: Click on the Tutorial 4  Working with the Spark Interpreter tutorial to open it. 

![](images/300/snap0012204.jpg) 

### **STEP 3**: Read and follow the instructions in the Tutorial


![](images/300/snap0012206.jpg)

## Open and run Tutorials 4b and 4c in the notebook

### **STEP 1**: Click on the Notebook tab. Expand the Journeys folder.  Then expand the New Data Lake folder. Then click on the Tutorial 4b Adding more datasets tutorial to open it. 

![](images/300/snap0012851.jpg) 

### **STEP 2**: Read and follow the instructions in the Tutorial

![](images/300/snap0012852.jpg)

### **STEP 3**: Click on the Notebook tab. Expand the Journeys folder.  Then expand the New Data Lake folder. Then click on the Tutorial 4c Getting Started with DV Desktop tutorial to open it. 

![](images/300/snap0012853.jpg) 

### **STEP 4**: Read and follow the instructions in the Tutorial

![](images/300/snap0012854.jpg)





# Learn how to work with Maps with Spark and Zeppelin

## Open and run the Tutorial 5 note in the notebook

### **STEP 1**: Click on the Notebook tab. Expand the Journeys folder.  Then expand the New Data Lake folder. Then click on the Tutorial 5 Working with Spark and Maps tutorial to open it. 

![](images/300/snap0012207.jpg) 

### **STEP 2**: Read and follow the instructions in the Tutorial


![](images/300/snap0012208.jpg)


# Check out a bonus demonstration using Spark with Presidential Speeches

## Open and run the Demonstration Presidential Speeches note in the notebook

### **STEP 1**: Click on the Notebook tab. Expand the Journeys folder.  Then expand the New Data Lake folder. Then expand the Demos folder. 

![](images/300/snap0013443.jpg) 

### **STEP 2**: Click on the Presidential Speeches with Spark and Spark SQL note to open it. 

![](images/300/snap0012209.jpg) 

### **STEP 3**: Read and follow the instructions in the note


![](images/300/snap0012210.jpg)



# What you Learned

- Learned how to work with Spark and Spark SQL
- Learned how to work with Maps and Spark and Zeppelin

# Next Steps

- Experiment with your own data.  Load it into the Object Store, define Spark or Hive tables against it, and run queries against your data.
- Proceed to the next Lab to learn how to add Oracle Event Hub Cloud Service to the architcture and how to leverage Spark Streaming