{"paragraphs":[{"text":"%md\n# Demonstration: Citi Bike New York - Working with the Spark Interpeter\n\nThis tutorial was built for BDCS-CE version 17.3.1. If you are using a later version of BDCS-CE, there may be a newer version of this tutorial notebook at <https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake> . Questions and feedback about the tutorial: david.bayard@oracle.com\n\n\n    Be sure you previously ran the Tutorial: \"Citi Bike New York Demo Introduction and Setup\" which places the necessary CSV File into the \"citibike\" Object Store container.\n\nThis tutorial will illustrate how to run Spark interpreter to define a temporary Spark SQL table against a CSV file and then query it.\n\n## Contents\n+ Configuring Spark to read CSV files\n+ Reading the data and registering as a Spark SQL table\n+ Querying bike trip information\n+ Next Steps\n\nAs a reminder, the documentation for BDCS-CE can be found here: <http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html>","user":"anonymous","dateUpdated":"2017-07-28T00:51:27+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Demonstration: Citi Bike New York - Working with the Spark Interpeter</h1>\n<p>This tutorial was built for BDCS-CE version 17.3.1. If you are using a later version of BDCS-CE, there may be a newer version of this tutorial notebook at <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\">https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake</a> . Questions and feedback about the tutorial: <a href=\"mailto:&#x64;&#97;&#118;i&#x64;&#46;b&#x61;&#x79;a&#114;&#100;&#64;o&#114;&#x61;c&#x6c;&#x65;.co&#x6d;\">&#x64;&#97;&#118;i&#x64;&#46;b&#x61;&#x79;a&#114;&#100;&#64;o&#114;&#x61;c&#x6c;&#x65;.co&#x6d;</a></p>\n<pre><code>Be sure you previously ran the Tutorial: &quot;Citi Bike New York Demo Introduction and Setup&quot; which places the necessary CSV File into the &quot;citibike&quot; Object Store container.\n</code></pre>\n<p>This tutorial will illustrate how to run Spark interpreter to define a temporary Spark SQL table against a CSV file and then query it.</p>\n<h2>Contents</h2>\n<ul>\n  <li>Configuring Spark to read CSV files</li>\n  <li>Reading the data and registering as a Spark SQL table</li>\n  <li>Querying bike trip information</li>\n  <li>Next Steps</li>\n</ul>\n<p>As a reminder, the documentation for BDCS-CE can be found here: <a href=\"http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html\">http://docs.oracle.com/cloud/latest/big-data-compute-cloud/index.html</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1501203017271_1696630414","id":"20170414-131903_889251720","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T00:51:27+0000","dateFinished":"2017-07-28T00:51:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:488"},{"text":"%md\n# About Spark and Spark SQL\n\nBDCS-CE version 17.3.1 comes with Spark version 1.6.1, Scala version 2.10, and Python version 2.6.6.  This BDCS-CE version supplies Zeppelin interpreters for Spark(Scala), Spark(Python), and Spark SQL.  This tutorial will give you examples using all of these.\n\nThe tutorial assumes you have a basic knowledge about Spark.  To learn more about Spark, check out <https://spark.apache.org/docs/1.6.1/quick-start.html> and <https://spark.apache.org/docs/1.6.1/sql-programming-guide.html>\n\n","user":"anonymous","dateUpdated":"2017-07-28T00:51:54+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>About Spark and Spark SQL</h1>\n<p>BDCS-CE version 17.3.1 comes with Spark version 1.6.1, Scala version 2.10, and Python version 2.6.6. This BDCS-CE version supplies Zeppelin interpreters for Spark(Scala), Spark(Python), and Spark SQL. This tutorial will give you examples using all of these.</p>\n<p>The tutorial assumes you have a basic knowledge about Spark. To learn more about Spark, check out <a href=\"https://spark.apache.org/docs/1.6.1/quick-start.html\">https://spark.apache.org/docs/1.6.1/quick-start.html</a> and <a href=\"https://spark.apache.org/docs/1.6.1/sql-programming-guide.html\">https://spark.apache.org/docs/1.6.1/sql-programming-guide.html</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1501203017271_1696630414","id":"20170616-103849_1176559517","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T00:51:54+0000","dateFinished":"2017-07-28T00:51:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:489"},{"text":"%md\n## Configuring Spark to read CSV files\n\nThe next step is to configure the Zeppelin Spark Interpreter to read CSV files.  BDCS-CE version 17.3.1 includes Spark version 1.6.1 (it also includes Spark2, but this tutorial is built assuming Spark 1.6).  This version of Spark can read CSVs, but the functionality is not loaded in Spark by default.  To use the CSV functionality, we need to add it as a dependency.\n\nFollow this procedure ( **hint: you might want to open up a new browser window so you can keep this instructions open** ):\n + Go to the Settings tab\n + Click on Notebook\n + In the Spark Interpreter section, click on Edit\n + Scroll down to the bottom of the Spark section, type in com.databricks:spark-csv_2.10:1.5.0 in the Artifact field to add a new dependency\n![csv image](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/snap0011518.jpg \"CSV Dependency\")\n + Click the Save button at the bottom of the Spark section\n + Then, click the OK button to restart the Spark interpreter to pick up the new settings\n\nHere is an animation of the above:\n![sparkCSVvideo](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/SparkCSV.gif \"sparkCSVvideo\")\n\nFor more details about Spark CSV support, see <https://github.com/databricks/spark-csv>.  As an aside, Zeppelin has a Spark Dependency interpreter (%dep) but that interpreter is depreciated and you will find that packages you list via the %dep interpreter will not be picked up if you leverage Spark SQL.  Therefore, you should use the Settings tab to define your Spark dependencies, not the %dep interpreter.","user":"anonymous","dateUpdated":"2017-07-31T18:59:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Configuring Spark to read CSV files</h2>\n<p>The next step is to configure the Zeppelin Spark Interpreter to read CSV files. BDCS-CE version 17.3.1 includes Spark version 1.6.1 (it also includes Spark2, but this tutorial is built assuming Spark 1.6). This version of Spark can read CSVs, but the functionality is not loaded in Spark by default. To use the CSV functionality, we need to add it as a dependency.</p>\n<p>Follow this procedure ( <strong>hint: you might want to open up a new browser window so you can keep this instructions open</strong> ):<br/> + Go to the Settings tab<br/> + Click on Notebook<br/> + In the Spark Interpreter section, click on Edit<br/> + Scroll down to the bottom of the Spark section, type in com.databricks:spark-csv_2.10:1.5.0 in the Artifact field to add a new dependency<br/><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/snap0011518.jpg\" alt=\"csv image\" title=\"CSV Dependency\" /><br/> + Click the Save button at the bottom of the Spark section<br/> + Then, click the OK button to restart the Spark interpreter to pick up the new settings</p>\n<p>Here is an animation of the above:<br/><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/SparkCSV.gif\" alt=\"sparkCSVvideo\" title=\"sparkCSVvideo\" /></p>\n<p>For more details about Spark CSV support, see <a href=\"https://github.com/databricks/spark-csv\">https://github.com/databricks/spark-csv</a>. As an aside, Zeppelin has a Spark Dependency interpreter (%dep) but that interpreter is depreciated and you will find that packages you list via the %dep interpreter will not be picked up if you leverage Spark SQL. Therefore, you should use the Settings tab to define your Spark dependencies, not the %dep interpreter.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1501203017272_1694706669","id":"20170417-082204_950298429","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-31T18:59:33+0000","dateFinished":"2017-07-31T18:59:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:490"},{"text":"%md\n## Before you continue...\n\n    Before you continue, be sure that you followed the manual instructions in the Paragraph above to configure the Spark CSV support. ","user":"anonymous","dateUpdated":"2017-07-28T00:52:58+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Before you continue&hellip;</h2>\n<pre><code>Before you continue, be sure that you followed the manual instructions in the Paragraph above to configure the Spark CSV support.\n</code></pre>\n</div>"}]},"apps":[],"jobName":"paragraph_1501203017272_1694706669","id":"20170417-085159_2076873409","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T00:52:58+0000","dateFinished":"2017-07-28T00:52:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:491"},{"text":"%md\n## Reading the data and registering as a Spark SQL table\n\nThe next step is to use Spark to read our bike data CSV file that we uploaded to the Object Store.  Once we read the CSV into a Spark Data Frame, we will ask Spark to cache the data in memory.  Then we will register the data frame as a Spark SQL temp table.\n\nYou can review the Spark SQL programming guide for a refresher about Data Frames and Temporary Tables: <https://spark.apache.org/docs/1.6.1/sql-programming-guide.html>\n\n","user":"anonymous","dateUpdated":"2017-07-28T00:53:05+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Reading the data and registering as a Spark SQL table</h2>\n<p>The next step is to use Spark to read our bike data CSV file that we uploaded to the Object Store. Once we read the CSV into a Spark Data Frame, we will ask Spark to cache the data in memory. Then we will register the data frame as a Spark SQL temp table.</p>\n<p>You can review the Spark SQL programming guide for a refresher about Data Frames and Temporary Tables: <a href=\"https://spark.apache.org/docs/1.6.1/sql-programming-guide.html\">https://spark.apache.org/docs/1.6.1/sql-programming-guide.html</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1501203017272_1694706669","id":"20170417-090240_1793194469","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T00:53:05+0000","dateFinished":"2017-07-28T00:53:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:492"},{"title":"Spark Scala to read CSV and register as table","text":"%spark\n\n//a previous tutorial placed the csv file into your Object Store citibike container\n//notice the use of the swift://CONTAINER.default/ syntax\nval Container = \"citibike\"\n\nval df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"swift://\"+Container+\".default/201612-citibike-tripdata.csv\")\n\n//cache the data frame for performance\ndf.cache()\n\n\nprintln(\"Here is the schema detected from the CSV\")\ndf.printSchema()\nprintln(\"..\")\n\nprintln(\"# of rows: %s\".format(\n  df.count() \n)) \nprintln(\"..\")\n\ndf.registerTempTable(\"bike_trips_temp\")\nprintln(\"done\")","user":"anonymous","dateUpdated":"2017-07-31T19:04:06+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"graph":{"mode":"table","height":247,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"}},"settings":{"params":{"container":"dcb-bdcs-apr12","CONTAINER":"citibike","FILENAME":"201612-citibike-tripdata"},"forms":{}},"apps":[],"jobName":"paragraph_1501203017273_1694321920","id":"20170414-134031_1271833288","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-31T19:04:06+0000","dateFinished":"2017-07-31T19:04:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:493","errorMessage":""},{"text":"%md\n# Querying the bike trip information\n\nNow we can show some examples of querying our bike_trips table.  You will need to have first run the above paragraph to ensure that the temporary table bike_trips_temp is registered in your current Spark Session.","user":"anonymous","dateUpdated":"2017-07-28T00:53:14+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Querying the bike trip information</h1>\n<p>Now we can show some examples of querying our bike_trips table. You will need to have first run the above paragraph to ensure that the temporary table bike_trips_temp is registered in your current Spark Session.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1501203017273_1694321920","id":"20170417-093337_291620887","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T00:53:14+0000","dateFinished":"2017-07-28T00:53:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:494"},{"title":"Trips by Gender","text":"%sql\nselect \n case when a.gender=1 then 'Male' when a.gender=2 then 'Female' else 'unknown' end gender ,\n        a.trip_count \nfrom (select gender, count(*) trip_count from bike_trips_temp\ngroup by gender) a","user":"anonymous","dateUpdated":"2017-07-28T13:17:10+0000","config":{"colWidth":6,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"pieChart","height":294,"optionOpen":false,"keys":[{"name":"gender","index":0,"aggr":"sum"}],"values":[{"name":"trip_count","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"gender","index":0,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501203017273_1694321920","id":"20170417-095126_1698083225","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T13:17:11+0000","dateFinished":"2017-07-28T13:17:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:495"},{"title":"Trips by Day of Month","text":"%sql\nselect dayofmonth, count(*)\nfrom (select date_format(`Start Time`,\"H\") hour,\n date_format(`Start Time`,\"E\") dayofweek,\n date_format(`Start Time`,\"d\") dayofmonth\nfrom bike_trips_temp) bike_times\ngroup by dayofmonth","user":"anonymous","dateUpdated":"2017-07-28T13:17:24+0000","config":{"colWidth":6,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"lineChart","height":314,"optionOpen":false,"keys":[{"name":"dayofmonth","index":0,"aggr":"sum"}],"values":[{"name":"_c1","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"dayofmonth","index":0,"aggr":"sum"},"yAxis":{"name":"_c1","index":1,"aggr":"sum"}},"forceY":true}}],"enabled":true,"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501203017274_1695476167","id":"20170417-095623_1767722062","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T13:17:25+0000","dateFinished":"2017-07-28T13:17:31+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:496"},{"title":"Trips by Day of Week and Gender","text":"%sql\nselect dayofweek, count(*)\nfrom (select date_format(`Start Time`,\"H\") hour,\n date_format(`Start Time`,\"E\") dayofweek,\n date_format(`Start Time`,\"d\") dayofmonth,\n case when gender=1 then 'Male' when gender=2 then 'Female' else 'unknown' end gender \nfrom bike_trips_temp) bike_times\nwhere (gender=\"${gender=Male,Male|Female|unknown}\" )\ngroup by dayofweek","dateUpdated":"2017-07-28T00:50:17+0000","config":{"colWidth":6,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"pieChart","height":300,"optionOpen":false,"keys":[{"name":"dayofweek","index":0,"aggr":"sum"}],"values":[{"name":"_c1","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"dayofweek","index":0,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"language":"sql"}},"settings":{"params":{"gender":"Male"},"forms":{"gender":{"name":"gender","defaultValue":"Male","options":[{"value":"Male","$$hashKey":"object:962"},{"value":"Female","$$hashKey":"object:963"},{"value":"unknown","$$hashKey":"object:964"}],"hidden":false,"$$hashKey":"object:955"}}},"apps":[],"jobName":"paragraph_1501203017274_1695476167","id":"20170417-101619_429877425","dateCreated":"2017-07-28T00:50:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:497"},{"title":"Bike Trips by Hour by day of week","text":"%sql\nselect dayofweek, hour, count(*)\nfrom (select date_format(`Start Time`,\"H\") hour,\n date_format(`Start Time`,\"E\") dayofweek,\n date_format(`Start Time`,\"d\") dayofmonth,\n case when gender=1 then 'Male' when gender=2 then 'Female' else 'unknown' end gender \nfrom bike_trips_temp) bike_times\nwhere (gender=\"${gender=Male,Male|Female|unknown}\" )\ngroup by dayofweek, hour","user":"anonymous","dateUpdated":"2017-07-28T13:17:39+0000","config":{"colWidth":6,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"lineChart","height":300,"optionOpen":false,"keys":[{"name":"hour","index":1,"aggr":"sum"}],"values":[{"name":"_c2","index":2,"aggr":"sum"}],"groups":[{"name":"dayofweek","index":0,"aggr":"sum"}],"scatter":{"xAxis":{"name":"dayofweek","index":0,"aggr":"sum"},"yAxis":{"name":"hour","index":1,"aggr":"sum"}},"forceY":true,"lineWithFocus":false}}],"enabled":true,"editorSetting":{"language":"sql"}},"settings":{"params":{"gender":"Male"},"forms":{"gender":{"name":"gender","defaultValue":"Male","options":[{"value":"Male","$$hashKey":"object:972"},{"value":"Female","$$hashKey":"object:973"},{"value":"unknown","$$hashKey":"object:974"}],"hidden":false,"$$hashKey":"object:965"}}},"apps":[],"jobName":"paragraph_1501203017275_1695091418","id":"20170414-134451_506665191","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T13:17:39+0000","dateFinished":"2017-07-28T13:17:47+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:498"},{"text":"%md\n# Next Steps\n\nSo far, we have downloaded Citi Bike data and stored it into the Object Store.  Then, we configured Spark to be able to work with CSV files.  Then, we read in the data and defined a Spark SQL temporary table with it.  Finally, we demonstrated a number of different queries.  Did you notice any patterns?  For instance, that men use Citi Bikes more than women?  That on workdays (Mon-Fri) there is a peak around 8am and 5pm, but that peak does not exist on Saturday and Sunday?   \n\nIn the next tutorial, we will look at identifying the top stations for bike checkin and checkout and show how to present that data on a map.\n\n","user":"anonymous","dateUpdated":"2017-07-28T13:18:06+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Next Steps</h1>\n<p>So far, we have downloaded Citi Bike data and stored it into the Object Store. Then, we configured Spark to be able to work with CSV files. Then, we read in the data and defined a Spark SQL temporary table with it. Finally, we demonstrated a number of different queries. Did you notice any patterns? For instance, that men use Citi Bikes more than women? That on workdays (Mon-Fri) there is a peak around 8am and 5pm, but that peak does not exist on Saturday and Sunday? </p>\n<p>In the next tutorial, we will look at identifying the top stations for bike checkin and checkout and show how to present that data on a map.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1501203017276_1693167674","id":"20170417-103925_248941849","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T13:18:06+0000","dateFinished":"2017-07-28T13:18:06+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:499"},{"text":"%md\n# Extra Credit - Saving our temporary Spark SQL table as a permanent Hive table\n\nThe next few paragraphs show you how you can save a copy of the Spark SQL temporary table as a new permament Hive table.  This might be useful if you want to use BI tools, like Oracle Data Visualization Desktop, to query the permanent table.\n\nThe only trick is that Hive doesn't like spaces in column names, so we rename our columns in our Create Table as Select statement below.","user":"anonymous","dateUpdated":"2017-07-28T00:53:30+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Extra Credit - Saving our temporary Spark SQL table as a permanent Hive table</h1>\n<p>The next few paragraphs show you how you can save a copy of the Spark SQL temporary table as a new permament Hive table. This might be useful if you want to use BI tools, like Oracle Data Visualization Desktop, to query the permanent table.</p>\n<p>The only trick is that Hive doesn&rsquo;t like spaces in column names, so we rename our columns in our Create Table as Select statement below.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1501203017277_1692782925","id":"20170505-092652_1652882871","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T00:53:30+0000","dateFinished":"2017-07-28T00:53:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:500"},{"title":"Query to list our hive tables BEFORE","text":"%sql\nshow tables","user":"anonymous","dateUpdated":"2017-07-28T13:18:19+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"table","height":174,"optionOpen":false,"keys":[{"name":"tableName","index":0,"aggr":"sum"}],"values":[{"name":"isTemporary","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"tableName","index":0,"aggr":"sum"},"yAxis":{"name":"isTemporary","index":1,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501203017277_1692782925","id":"20170505-092452_1351056533","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T13:18:19+0000","dateFinished":"2017-07-28T13:18:19+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:501"},{"title":"HiveQL to drop the table (in case you already ran the next step)","text":"%sql\ndrop table bike_trips_parquet","dateUpdated":"2017-07-28T00:50:17+0000","config":{"colWidth":12,"title":true,"results":[],"enabled":true,"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1501203017277_1692782925","id":"20170612-094821_740135087","dateCreated":"2017-07-28T00:50:17+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:502"},{"title":"HiveQL to create a permanent Hive table from our SparkSQL temporary table","text":"%sql\ncreate table bike_trips_parquet\nstored as parquet\nas select `Trip Duration` TRIPDURATION,\n`Start Time` STARTTIME,\n`Stop Time` STOPTIME,\n`Start Station ID` STARTSTATIONID,\n`Start Station Name` STARTSTATIONNAME,\n`Start Station Latitude` STARTSTATIONLATITUDE,\n`Start Station Longitude` STARTSTATIONLONGITUDE,\n`End Station ID` ENDSTATIONID,\n`End Station Name` ENDSTATIONNAME,\n`End Station Latitude` ENDSTATIONLATITUDE,\n`End Station Longitude` ENDSTATIONLONGITUDE,\n`Bike ID` BIKEID,\n`User Type` USERTYPE,\n`Birth Year` BIRTHYEAR,\n`Gender` GENDER\n from bike_trips_temp","user":"anonymous","dateUpdated":"2017-07-28T13:18:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[],"enabled":true,"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501203017278_1693937171","id":"20170414-151953_1584996855","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T13:18:29+0000","dateFinished":"2017-07-28T13:18:44+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:503"},{"title":"Query to show our new permanent table in action","text":"%sql\nselect * from bike_trips_parquet limit 5","user":"anonymous","dateUpdated":"2017-07-28T13:18:53+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"tripduration","index":0,"aggr":"sum"}],"values":[{"name":"starttime","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"tripduration","index":0,"aggr":"sum"},"yAxis":{"name":"starttime","index":1,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501203017278_1693937171","id":"20170503-195617_839333002","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T13:18:53+0000","dateFinished":"2017-07-28T13:18:54+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:504"},{"title":"Query to list our Hive tables AFTER","text":"%sql\nshow tables","user":"anonymous","dateUpdated":"2017-07-28T13:18:59+0000","config":{"colWidth":12,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"tableName","index":0,"aggr":"sum"}],"values":[{"name":"isTemporary","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"tableName","index":0,"aggr":"sum"},"yAxis":{"name":"isTemporary","index":1,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501203017278_1693937171","id":"20170503-195744_526374432","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T13:18:59+0000","dateFinished":"2017-07-28T13:18:59+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:505"},{"text":"%md\n### Change Log\nJuly 28, 2017 - Confirmed it works with 17.3.1-20.","user":"anonymous","dateUpdated":"2017-07-28T13:19:05+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Change Log</h3>\n<p>July 28, 2017 - Confirmed it works with 17.3.1-20.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1501203017279_1693552422","id":"20170614-163657_1564876178","dateCreated":"2017-07-28T00:50:17+0000","dateStarted":"2017-07-28T13:16:07+0000","dateFinished":"2017-07-28T13:16:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:506"},{"text":"%md\n","user":"anonymous","dateUpdated":"2017-07-28T13:16:06+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1501247766920_1295747701","id":"20170728-131606_1414555962","dateCreated":"2017-07-28T13:16:06+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:507"}],"name":"Tutorial 6 Working with the Spark Interpreter","id":"2CPR7XJQU","angularObjects":{"2CQVFQFWU:shared_process":[],"2CRFREMNU:shared_process":[],"2CPRZVQKR:shared_process":[],"2CQWU46XZ:shared_process":[],"2CPKCF4R9:shared_process":[],"2CR7Y2CFK:shared_process":[],"2CQQM64RT:shared_process":[],"2CQX3UW3S:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}