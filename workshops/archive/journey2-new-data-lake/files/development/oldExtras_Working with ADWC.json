{"paragraphs":[{"text":"%md\n# Tutorial: Working with Oracle Autonomous Data Warehouse Cloud\n\nThis tutorial was built for BDC version 17.4.6 as part of the New Data Lake User Journey.: .  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\nThe Autonomous Data Warehouse Cloud provides an easy-to-use, fully autonomous database that scales elastically, delivers fast query performance and requires no database administration.  It is a fully-managed data warehouse designed to support all standard SQL and business intelligence (BI) tools and deliver scalable analytic query performance.  Find out more at the <a href=\"https://cloud.oracle.com/en_US/datawarehouse\" target=\"_blank\">ADWC website</a> or check out the <a href=\"https://docs.oracle.com/en/cloud/paas/autonomous-data-warehouse-cloud/index.html\" target=\"_blank\">product documentation.</a>\n\n\nNote: This tutorial replaces the Working with Oracle Database tutorial, in that this tutorial goes the extra-step of setting up the 12.2 JDBC-OCI connectivity.  You can use this same connectivity to other non-ADWC databases.  In other words, if you follow this tutorial, don't follow the steps in the Working with Oracle Database tutorial as that tutorial assumes you want to use the 12.1 thin JDBC driver (not the 12.2 JDBC-OCI driver).\n\n","user":"anonymous","dateUpdated":"2018-01-05T17:47:16+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Tutorial: Working with Oracle Autonomous Data Warehouse Cloud</h1>\n<p>This tutorial was built for BDC version 17.4.6 as part of the New Data Lake User Journey.: . Questions and feedback about the tutorial: <a href=\"mailto:&#100;&#x61;v&#105;&#100;&#46;&#x62;&#97;y&#97;rd@&#111;&#x72;&#x61;&#x63;l&#x65;.c&#111;&#109;\">&#100;&#x61;v&#105;&#100;&#46;&#x62;&#97;y&#97;rd@&#111;&#x72;&#x61;&#x63;l&#x65;.c&#111;&#109;</a></p>\n<p>The Autonomous Data Warehouse Cloud provides an easy-to-use, fully autonomous database that scales elastically, delivers fast query performance and requires no database administration. It is a fully-managed data warehouse designed to support all standard SQL and business intelligence (BI) tools and deliver scalable analytic query performance. Find out more at the <a href=\"https://cloud.oracle.com/en_US/datawarehouse\" target=\"_blank\">ADWC website</a> or check out the <a href=\"https://docs.oracle.com/en/cloud/paas/autonomous-data-warehouse-cloud/index.html\" target=\"_blank\">product documentation.</a></p>\n<p>Note: This tutorial replaces the Working with Oracle Database tutorial, in that this tutorial goes the extra-step of setting up the 12.2 JDBC-OCI connectivity. You can use this same connectivity to other non-ADWC databases. In other words, if you follow this tutorial, don&rsquo;t follow the steps in the Working with Oracle Database tutorial as that tutorial assumes you want to use the 12.1 thin JDBC driver (not the 12.2 JDBC-OCI driver).</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1515082741600_-318861869","id":"20170414-115315_151675592","dateCreated":"2018-01-04T16:19:01+0000","dateStarted":"2018-01-05T17:47:16+0000","dateFinished":"2018-01-05T17:47:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:632"},{"text":"%md\n# About connecting to ADWC\n\nConnections to the Autonomous Data Warehouse Cloud are made over the public Internet, and all applications must use a secure connection to the Autonomous Data Warehouse Cloud. If you are familiar with using an Oracle Database within your own data center, you may not have previously used these kind of secure SQL*Net connections, so some of the connection details may be new to you.\n\nConnections to Autonomous Data Warehouse Cloud use certificate authentication and Secure Sockets Layer (SSL). This ensures that there is no unauthorized access to the Autonomous Data Warehouse Cloud and that communications between the client and server are fully encrypted and cannot be intercepted or altered. To enable these features, it requires that the client machine has a copy of a special set of files (known as the \"Client Credentials\" or the \"wallet\") that are configured for your ADWC instance.\n\nADWC connections can be made with all types of SQL*Net connections: Oracle Client Interface (OCI), JDBC Thin, and JDBC Thick (JDBC-OCI).  For this tutorial, we will use the JDBC Thick (JDBC-OCI) type of connection as JDBC-OCI makes working with wallets easier than using JDBC Thin.\n\nTo use JDBC-OCI with BDC, here are the high-level steps we need to follow:\n\n- Copy the Client Credentials zip file from your ADWC instance to BDC\n\n- Install the Oracle Instant Client (the 12.2 version is pre-installed, so no need to do anything here)\n\n- Configure the YARN and Spark environments to work with Oracle Instant Client libraries\n\n- Configure the Zeppelin environment to use the 12.2 Oracle JDBC driver for the JDBC interpreter and Spark interpreter\n\n\nLearn more about ADWC Connectivity in the <a href=\"https://docs.oracle.com/en/cloud/paas/autonomous-data-warehouse-cloud/user/connect-data-warehouse.html\" target=\"_blank\">product documentation</a>.\n","user":"anonymous","dateUpdated":"2018-01-05T15:09:19+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>About connecting to ADWC</h1>\n<p>Connections to the Autonomous Data Warehouse Cloud are made over the public Internet, and all applications must use a secure connection to the Autonomous Data Warehouse Cloud. If you are familiar with using an Oracle Database within your own data center, you may not have previously used these kind of secure SQL*Net connections, so some of the connection details may be new to you.</p>\n<p>Connections to Autonomous Data Warehouse Cloud use certificate authentication and Secure Sockets Layer (SSL). This ensures that there is no unauthorized access to the Autonomous Data Warehouse Cloud and that communications between the client and server are fully encrypted and cannot be intercepted or altered. To enable these features, it requires that the client machine has a copy of a special set of files (known as the &ldquo;Client Credentials&rdquo; or the &ldquo;wallet&rdquo;) that are configured for your ADWC instance.</p>\n<p>ADWC connections can be made with all types of SQL*Net connections: Oracle Client Interface (OCI), JDBC Thin, and JDBC Thick (JDBC-OCI). For this tutorial, we will use the JDBC Thick (JDBC-OCI) type of connection as JDBC-OCI makes working with wallets easier than using JDBC Thin.</p>\n<p>To use JDBC-OCI with BDC, here are the high-level steps we need to follow:</p>\n<ul>\n  <li>\n  <p>Copy the Client Credentials zip file from your ADWC instance to BDC</p></li>\n  <li>\n  <p>Install the Oracle Instant Client (the 12.2 version is pre-installed, so no need to do anything here)</p></li>\n  <li>\n  <p>Configure the YARN and Spark environments to work with Oracle Instant Client libraries</p></li>\n  <li>\n  <p>Configure the Zeppelin environment to use the 12.2 Oracle JDBC driver for the JDBC interpreter and Spark interpreter</p></li>\n</ul>\n<p>Learn more about ADWC Connectivity in the <a href=\"https://docs.oracle.com/en/cloud/paas/autonomous-data-warehouse-cloud/user/connect-data-warehouse.html\" target=\"_blank\">product documentation</a>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1515163999979_1372928847","id":"20180105-145319_2025443570","dateCreated":"2018-01-05T14:53:19+0000","dateStarted":"2018-01-05T15:09:15+0000","dateFinished":"2018-01-05T15:09:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:633"},{"text":"%md\n# Copy the Client Credentials zip file from your ADWC instance to BDC\n\n## Download the Client Credentials zip file from your ADWC instance\n\n\nTo download client credentials, do the following:\n\n- Navigate to the Service Console for Autonomous Data Warehouse Cloud.\n- Choose Administration.\n- On the Administration page Choose Download Client Credentials.\n- On the Client Credentials dialog, enter a wallet password and confirm the password.\n- Click Download to save the client security credentials zip file.\n\n## Upload the Client Credentials zip file to your BDC instance\n\nFor simplicity, we will upload the Client Credentials using the BDC Console.  Follow these steps:\n\n- Navigate to Data Stores in the Big Data Cloud console\n- Click on HDFS\n- Click on the tmp folder\n- Click on the Upload button\n- Select the Client Credentials zip file (it will likely be named something like wallet_UNIQUEID_DBNAME.zip) and upload it\n\nAt this point, you should see a wallet*.zip file in the HDFS /tmp directory.\n\n## Move the Client Credentials zip file from HDFS to the linux file system\n\nFinally, we need to move the client credentials zip file to the linux file system and unzip it.\n\n- Run the following paragraph to move and unzip the client credentials zip file\n\n","user":"anonymous","dateUpdated":"2018-01-05T15:33:22+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Copy the Client Credentials zip file from your ADWC instance to BDC</h1>\n<h2>Download the Client Credentials zip file from your ADWC instance</h2>\n<p>To download client credentials, do the following:</p>\n<ul>\n  <li>Navigate to the Service Console for Autonomous Data Warehouse Cloud.</li>\n  <li>Choose Administration.</li>\n  <li>On the Administration page Choose Download Client Credentials.</li>\n  <li>On the Client Credentials dialog, enter a wallet password and confirm the password.</li>\n  <li>Click Download to save the client security credentials zip file.</li>\n</ul>\n<h2>Upload the Client Credentials zip file to your BDC instance</h2>\n<p>For simplicity, we will upload the Client Credentials using the BDC Console. Follow these steps:</p>\n<ul>\n  <li>Navigate to Data Stores in the Big Data Cloud console</li>\n  <li>Click on HDFS</li>\n  <li>Click on the tmp folder</li>\n  <li>Click on the Upload button</li>\n  <li>Select the Client Credentials zip file (it will likely be named something like wallet_UNIQUEID_DBNAME.zip) and upload it</li>\n</ul>\n<p>At this point, you should see a wallet*.zip file in the HDFS /tmp directory.</p>\n<h2>Move the Client Credentials zip file from HDFS to the linux file system</h2>\n<p>Finally, we need to move the client credentials zip file to the linux file system and unzip it.</p>\n<ul>\n  <li>Run the following paragraph to move and unzip the client credentials zip file</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1515164960769_-1641803714","id":"20180105-150920_1546634221","dateCreated":"2018-01-05T15:09:20+0000","dateStarted":"2018-01-05T15:33:22+0000","dateFinished":"2018-01-05T15:33:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:634"},{"title":"Script to move the Client Credentials zip to the linux file system","text":"%sh\nsudo mkdir /opt/oracle/dbconnector/tns_admin\nsudo chown zeppelin /opt/oracle/dbconnector/tns_admin\ncd /opt/oracle/dbconnector/tns_admin\nhadoop fs -ls /tmp\nhadoop fs -get \"/tmp/wallet*.zip\" wallet.zip\nunzip wallet.zip\n\n#update the wallet directory path in the sqlnet.ora\ncp sqlnet.ora sqlnet.ora.save\ncat <<EOF > sqlnet.ora\nWALLET_LOCATION = (SOURCE = (METHOD = file) (METHOD_DATA = (DIRECTORY=\"/opt/oracle/dbconnector/tns_admin\")))\nSSL_SERVER_DN_MATCH=yes\nEOF\n\nls\necho \"done\"\n","user":"anonymous","dateUpdated":"2018-01-05T15:40:20+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":false,"title":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"mkdir: cannot create directory `/opt/oracle/dbconnector/tns_admin': File exists\nFound 3 items\ndrwxr-xr-x   - hdfs      hdfs          0 2017-12-13 15:30 /tmp/entity-file-history\ndrwx-wx-wx   - ambari-qa hdfs          0 2017-12-21 00:34 /tmp/hive\n-rw-r--r--   3 oracle    hdfs      21057 2018-01-05 15:34 /tmp/wallet_FA539F1A563D4_DBAYARDDW.zip\nget: `wallet.zip': File exists\nArchive:  wallet.zip\nreplace cwallet.sso? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n(EOF or read error, treating as \"[N]one\" ...)\ncwallet.sso\newallet.p12\nkeystore.jks\nojdbc.properties\nsqlnet.ora\nsqlnet.ora.save\ntnsnames.ora\ntruststore.jks\nwallet.zip\ndone\n"}]},"apps":[],"jobName":"paragraph_1515166187919_-1509119539","id":"20180105-152947_188131871","dateCreated":"2018-01-05T15:29:47+0000","dateStarted":"2018-01-05T15:40:10+0000","dateFinished":"2018-01-05T15:40:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:635"},{"text":"%md\n# Install the Oracle Instant Client\n\nWith BDC, the Oracle Instant Client should already be installed.  You should see it at /opt/oracle/dbconnector/instantclient.  As of 17.4.6, the Oracle Instant Client version is 12.2.0.1.\n\nYou can run the next paragraph to test connectivity with SQL*Plus.\n\n","user":"anonymous","dateUpdated":"2018-01-05T15:40:47+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Install the Oracle Instant Client</h1>\n<p>With BDC, the Oracle Instant Client should already be installed. You should see it at /opt/oracle/dbconnector/instantclient. As of 17.4.6, the Oracle Instant Client version is 12.2.0.1.</p>\n<p>You can run the next paragraph to test connectivity with SQL*Plus.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1515083486311_1939568955","id":"20180104-163126_74184324","dateCreated":"2018-01-04T16:31:26+0000","dateStarted":"2018-01-05T15:40:47+0000","dateFinished":"2018-01-05T15:40:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:636"},{"title":"Script to test ADWC Connectivity with SQL*Plus (you will need to edit the username/password and tns alias)","text":"%sh\nexport TNS_ADMIN=/opt/oracle/dbconnector/tns_admin\nexport LD_LIBRARY_PATH=/opt/oracle/dbconnector/instantclient:$LD_LIBRARY_PATH\nexport PATH=/opt/oracle/dbconnector/instantclient:$PATH\n\n\nsqlplus 'sh/Welcome1!@FA539F1A563D4_DBAYARDDW_medium.dwcs.oracle.com'\n","user":"anonymous","dateUpdated":"2018-01-05T15:45:23+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","title":true,"editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nSQL*Plus: Release 12.2.0.1.0 Production on Fri Jan 5 15:42:35 2018\n\nCopyright (c) 1982, 2016, Oracle.  All rights reserved.\n\nLast Successful login time: Thu Jan 04 2018 21:30:30 +00:00\n\nConnected to:\nOracle Database 12c Enterprise Edition Release 12.2.0.1.0 - 64bit Production\n\nSQL> Disconnected from Oracle Database 12c Enterprise Edition Release 12.2.0.1.0 - 64bit Production\n"}]},"apps":[],"jobName":"paragraph_1515083713473_266401613","id":"20180104-163513_422676257","dateCreated":"2018-01-04T16:35:13+0000","dateStarted":"2018-01-05T15:42:35+0000","dateFinished":"2018-01-05T15:44:07+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:637"},{"text":"%md\n# Configure the YARN and Spark environments to work with the Oracle Instant Client\n\nFirst, connect to Ambari (see the Extra tutorial on Connecting to Ambari if you need help).  Then while in Ambari, do the following:\n\n## Setup the YARN environment\n\n- In Ambari, click on YARN.\n- Then click on Configs\n- Then click on Advanced\n- Then expand Advanced yarn-env\n- Then add these 2 lines to the top of the yarn-env template:\n\n    export TNS_ADMIN=/opt/oracle/dbconnector/tns_admin\n    export LD_LIBRARY_PATH=/opt/oracle/dbconnector/instantclient:$LD_LIBRARY_PATH\n\n- Then click Save\n- Name the changes \"oracle instant client\" and click Save again\n- If you get a warning message, click Proceed Anyways\n- NOTE: you do not need to restart now\n\n## Setup the SPARK environment\n\n- In Ambari, click on Spark2\n- Click on Configs\n- Expand Advanced spark2-defaults\n- Edit the spark.driver.extraLibraryPath field and append this value:\n:/opt/oracle/dbconnector/instantclient/\n- Then click Save\n- Name the changes \"oracle instant client\" and click Save again\n\n\n- (Optional) Expand Advanced spark2-env and edit spark_thrift_cmd_opts\nsearch for ojdbc. change to /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar\nNOTE ojdbc7 appears 3 times. You need to change all 3\n\n## Setup the Zeppelin environment\n\n- In Ambari, click on Zeppelin Notebook\n- Click on Configs\n- Expand Advanced zeppelin-env\n- Then add these 2 lines to the top of the zeppelin_env_content:\n\n    export TNS_ADMIN=/opt/oracle/dbconnector/tns_admin\n    export LD_LIBRARY_PATH=/opt/oracle/dbconnector/instantclient:$LD_LIBRARY_PATH\n\n- Then click Save\n- Name the changes \"oracle instant client\" and click Save again\n\n## Restart services\n\n- In Ambari, click on the Actions button underneath the list of services\n- Choose Restart All Required\n- Then click on Confirm Restart All\n","user":"anonymous","dateUpdated":"2018-01-05T16:44:38+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Configure the YARN and Spark environments to work with the Oracle Instant Client</h1>\n<p>First, connect to Ambari (see the Extra tutorial on Connecting to Ambari if you need help). Then while in Ambari, do the following:</p>\n<h2>Setup the YARN environment</h2>\n<ul>\n  <li>In Ambari, click on YARN.</li>\n  <li>Then click on Configs</li>\n  <li>Then click on Advanced</li>\n  <li>Then expand Advanced yarn-env</li>\n  <li>Then add these 2 lines to the top of the yarn-env template:\n    <p>export TNS_ADMIN=/opt/oracle/dbconnector/tns_admin<br/>export LD_LIBRARY_PATH=/opt/oracle/dbconnector/instantclient:$LD_LIBRARY_PATH</p>\n  </li>\n  <li>\n  <p>Then click Save</p></li>\n  <li>Name the changes &ldquo;oracle instant client&rdquo; and click Save again</li>\n  <li>If you get a warning message, click Proceed Anyways</li>\n  <li>NOTE: you do not need to restart now</li>\n</ul>\n<h2>Setup the SPARK environment</h2>\n<ul>\n  <li>In Ambari, click on Spark2</li>\n  <li>Click on Configs</li>\n  <li>Expand Advanced spark2-defaults</li>\n  <li>Edit the spark.driver.extraLibraryPath field and append this value:<br/>:/opt/oracle/dbconnector/instantclient/</li>\n  <li>Then click Save</li>\n  <li>Name the changes &ldquo;oracle instant client&rdquo; and click Save again</li>\n  <li>\n  <p>(Optional) Expand Advanced spark2-env and edit spark_thrift_cmd_opts<br/>search for ojdbc. change to /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar<br/>NOTE ojdbc7 appears 3 times. You need to change all 3</p></li>\n</ul>\n<h2>Setup the Zeppelin environment</h2>\n<ul>\n  <li>In Ambari, click on Zeppelin Notebook</li>\n  <li>Click on Configs</li>\n  <li>Expand Advanced zeppelin-env</li>\n  <li>Then add these 2 lines to the top of the zeppelin_env_content:\n    <p>export TNS_ADMIN=/opt/oracle/dbconnector/tns_admin<br/>export LD_LIBRARY_PATH=/opt/oracle/dbconnector/instantclient:$LD_LIBRARY_PATH</p>\n  </li>\n  <li>\n  <p>Then click Save</p></li>\n  <li>Name the changes &ldquo;oracle instant client&rdquo; and click Save again</li>\n</ul>\n<h2>Restart services</h2>\n<ul>\n  <li>In Ambari, click on the Actions button underneath the list of services</li>\n  <li>Choose Restart All Required</li>\n  <li>Then click on Confirm Restart All</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1515167168020_-1026757971","id":"20180105-154608_1320202625","dateCreated":"2018-01-05T15:46:08+0000","dateStarted":"2018-01-05T16:44:38+0000","dateFinished":"2018-01-05T16:44:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:638"},{"text":"%md\n# Configure the Zeppelin JDBC Interpreter\n\nFollow these steps:\n\n- In the BDC console, click on Settings\n- Then click on Notebook\n- Scroll down to the JDBC interpreter section and click the Edit button\n- In the properties section, add the following properties\n    - adwc-sh.driver = oracle.jdbc.OracleDriver \n    - adwc-sh.user = sh\n    - adwc-sh.url = jdbc:oracle:oci8:@FA539F1A563D4_DBAYARDDW_high.dwcs.oracle.com\n    - adwc-sh.password = YourPassword\n    - Update values like \"sh\" with your database username.  Update the last part of the url with your tns alias.  Update password with your password.\n- In the dependencies section, overwrite/replace the ojdbc7 dependency with this value:\n/opt/oracle/dbconnector/instantclient/ojdbc8.jar\n- Click Save\n- Then click OK to restart the JDBC interpreter\n\n","user":"anonymous","dateUpdated":"2018-01-05T17:51:05+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Configure the Zeppelin JDBC Interpreter</h1>\n<p>Follow these steps:</p>\n<ul>\n  <li>In the BDC console, click on Settings</li>\n  <li>Then click on Notebook</li>\n  <li>Scroll down to the JDBC interpreter section and click the Edit button</li>\n  <li>In the properties section, add the following properties\n    <ul>\n      <li>adwc-sh.driver = oracle.jdbc.OracleDriver</li>\n      <li>adwc-sh.user = sh</li>\n      <li>adwc-sh.url = jdbc:oracle:oci8:@FA539F1A563D4_DBAYARDDW_high.dwcs.oracle.com</li>\n      <li>adwc-sh.password = YourPassword</li>\n      <li>Update values like &ldquo;sh&rdquo; with your database username. Update the last part of the url with your tns alias. Update password with your password.</li>\n    </ul>\n  </li>\n  <li>In the dependencies section, overwrite/replace the ojdbc7 dependency with this value:<br/>/opt/oracle/dbconnector/instantclient/ojdbc8.jar</li>\n  <li>Click Save</li>\n  <li>Then click OK to restart the JDBC interpreter</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1515167564868_-183573917","id":"20180105-155244_1736223466","dateCreated":"2018-01-05T15:52:44+0000","dateStarted":"2018-01-05T17:51:05+0000","dateFinished":"2018-01-05T17:51:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:639"},{"title":"Script to patch Zeppelin to fix performance issue (ZEPPELIN-1962)","text":"%sh\n# There are some performance issues with Zeppelin 0.7.x jdbc interpreter and OracleDB due to a costly (slow) autocompletion feature.\n# See https://issues.apache.org/jira/browse/ZEPPELIN-1962  (also being tracked as oracle bug 27037280)\n# The workaround for Zeppelin is 0.7.x is to use a patched zeppelin jdbc interpreter jar file which disables autocompletion.\n\nmkdir /tmp/zepjdbc\ncd /tmp/zepjdbc\nwget https://issues.apache.org/jira/secure/attachment/12874854/zeppelin-jdbc-0.7.2.jar\nls -l zepp*\n\necho \"now putting files into place\"\nsudo mv /u01/bdcsce/usr/hdp/2.4.2.0-258/zeppelin-spark21/interpreter/jdbc/zeppelin-jdbc-0.7.0.2.6.0.3-8.jar /u01/bdcsce/usr/hdp/2.4.2.0-258/zeppelin-spark21/interpreter/jdbc/zeppelin-jdbc-0.7.0.2.6.0.3-8.jar.orig\nsudo cp /tmp/zepjdbc/zeppelin-jdbc-0.7.2.jar /u01/bdcsce/usr/hdp/2.4.2.0-258/zeppelin-spark21/interpreter/jdbc/zeppelin-jdbc-0.7.2.jar\n\nhostname -f\necho \"done\"\n\n# You need to restart the zeppelin jdbc interpreter, but the next paragraph will do that for us\n","user":"anonymous","dateUpdated":"2018-01-05T17:18:04+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"mkdir: cannot create directory `/tmp/zepjdbc': File exists\n--2018-01-05 17:18:04--  https://issues.apache.org/jira/secure/attachment/12874854/zeppelin-jdbc-0.7.2.jar\nResolving issues.apache.org... 207.244.88.139\nConnecting to issues.apache.org|207.244.88.139|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 37587 (37K) [application/java-archive]\nSaving to: “zeppelin-jdbc-0.7.2.jar.4”\n\n     0K .......... .......... .......... ......               100%  439K=0.08s\n\n2018-01-05 17:18:05 (439 KB/s) - “zeppelin-jdbc-0.7.2.jar.4” saved [37587/37587]\n\n-rw-rw-r-- 1 zeppelin zeppelin 37587 Jan  4 16:46 zeppelin-jdbc-0.7.2.jar\n-rw-r--r-- 1 zeppelin zeppelin 37587 Jan  5 17:14 zeppelin-jdbc-0.7.2.jar.1\n-rw-r--r-- 1 zeppelin zeppelin 37587 Jan  5 17:17 zeppelin-jdbc-0.7.2.jar.2\n-rw-r--r-- 1 zeppelin zeppelin 37587 Jan  5 17:17 zeppelin-jdbc-0.7.2.jar.3\n-rw-r--r-- 1 zeppelin zeppelin 37587 Jan  5 17:18 zeppelin-jdbc-0.7.2.jar.4\nnow putting files into place\nmv: cannot stat `/u01/bdcsce/usr/hdp/2.4.2.0-258/zeppelin-spark21/interpreter/jdbc/zeppelin-jdbc-0.7.0.2.6.0.3-8.jar': No such file or directory\ndcbdec13-bdcsce-1.compute-gse00010212.oraclecloud.internal\ndone\n"}]},"apps":[],"jobName":"paragraph_1515172445385_1117582801","id":"20180105-171405_1432133900","dateCreated":"2018-01-05T17:14:05+0000","dateStarted":"2018-01-05T17:18:04+0000","dateFinished":"2018-01-05T17:18:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:640"},{"text":"%md\n# Additional step to correct Password for JDBC Interpreter\n\nThis step is currently required because of our temporary fix to the ZEPPELIN-1962 issue.  Long term, this step will not be needed.\n\n- Copy the hostname of your BDC server.  In the above paragraph, the hostname should be printed out on the next-to-last line of the output.\n- Click on Settings\n- Click on Notebook\n- Scroll down to the JDBC Interpreter section\n- Click on Edit\n- Find the property adwc-sh.jceks.file\n- Edit the value of the property so that instead of \"hdfs\" it now reads \"hdfs@hostname\".  For instance, here is an example after editing:\njceks://hdfs@dcbdec13-bdcsce-1.compute-gse00010212.oraclecloud.internal/user/zeppelin/interpreter-store.jks\n- Click Save\n- Click OK to restart","user":"anonymous","dateUpdated":"2018-01-05T17:48:57+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Additional step to correct Password for JDBC Interpreter</h1>\n<p>This step is currently required because of our temporary fix to the ZEPPELIN-1962 issue. Long term, this step will not be needed.</p>\n<ul>\n  <li>Copy the hostname of your BDC server. In the above paragraph, the hostname should be printed out on the next-to-last line of the output.</li>\n  <li>Click on Settings</li>\n  <li>Click on Notebook</li>\n  <li>Scroll down to the JDBC Interpreter section</li>\n  <li>Click on Edit</li>\n  <li>Find the property adwc-sh.jceks.file</li>\n  <li>Edit the value of the property so that instead of &ldquo;hdfs&rdquo; it now reads &quot;<a href=\"mailto:&#104;&#100;f&#115;&#64;&#104;&#x6f;&#x73;&#x74;&#x6e;&#97;&#109;e&#x22;\">&#104;&#100;f&#115;&#64;&#104;&#x6f;&#x73;&#x74;&#x6e;&#97;&#109;e&#x22;</a>. For instance, here is an example after editing:<br/><a href=\"jceks://hdfs@dcbdec13-bdcsce-1.compute-gse00010212.oraclecloud.internal/user/zeppelin/interpreter-store.jks\">jceks://hdfs@dcbdec13-bdcsce-1.compute-gse00010212.oraclecloud.internal/user/zeppelin/interpreter-store.jks</a></li>\n  <li>Click Save</li>\n  <li>Click OK to restart</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1515172596196_1233455162","id":"20180105-171636_804449940","dateCreated":"2018-01-05T17:16:36+0000","dateStarted":"2018-01-05T17:48:52+0000","dateFinished":"2018-01-05T17:48:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:641"},{"title":"Script to test Zeppelin JDBC interpreter","text":"%jdbc(adwc-sh)\nselect user from dual\n","user":"anonymous","dateUpdated":"2018-01-05T16:57:20+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515171410435_-1214463481","id":"20180105-165650_115558078","dateCreated":"2018-01-05T16:56:50+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:642"},{"text":"%md\n# Configure the Zeppelin Spark Interpeter\n\n- In the BDC console, click on Settings\n- Then click on Notebook\n- Scroll down to the spark2 interpreter section and click the Edit button\n- In the dependencies section, overwrite/replace the ojdbc7 dependency with this value:\n/opt/oracle/dbconnector/instantclient/ojdbc8.jar\n- Click Save\n- Then click OK to restart the JDBC interpreter\n- \n[root@dcbdec13-bdcsce-1 tnsadmin]# cd /u01/bdcsce/opt/oracle/bdcsce/current/lib/\n[root@dcbdec13-bdcsce-1 lib]# mv ojdbc7.jar ojdbc7.jar.dontuse\n[root@dcbdec13-bdcsce-1 lib]# cp /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar .\n\nIn Zeppelin SPark Settings, change ojdbc7 to ojdbc8.","user":"anonymous","dateUpdated":"2018-01-05T17:52:04+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Configure the Zeppelin Spark Interpeter</h1>\n<ul>\n  <li>In the BDC console, click on Settings</li>\n  <li>Then click on Notebook</li>\n  <li>Scroll down to the spark2 interpreter section and click the Edit button</li>\n  <li>In the dependencies section, overwrite/replace the ojdbc7 dependency with this value:<br/>/opt/oracle/dbconnector/instantclient/ojdbc8.jar</li>\n  <li>Click Save</li>\n  <li>Then click OK to restart the JDBC interpreter</li>\n  <li>[root@dcbdec13-bdcsce-1 tnsadmin]# cd /u01/bdcsce/opt/oracle/bdcsce/current/lib/<br/>[root@dcbdec13-bdcsce-1 lib]# mv ojdbc7.jar ojdbc7.jar.dontuse<br/>[root@dcbdec13-bdcsce-1 lib]# cp /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar .</li>\n</ul>\n<p>In Zeppelin SPark Settings, change ojdbc7 to ojdbc8.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1515167585263_-286671298","id":"20180105-155305_2073848723","dateCreated":"2018-01-05T15:53:05+0000","dateStarted":"2018-01-05T17:52:04+0000","dateFinished":"2018-01-05T17:52:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:643"},{"text":"%sh\nsudo mv /opt/oracle/bdcsce/current/lib/ojdbc7.jar ~zeppelin/ojdbc7.jar.dontuse","user":"anonymous","dateUpdated":"2018-01-05T18:00:41+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","title":true,"editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515175180588_-1102879198","id":"20180105-175940_1530123000","dateCreated":"2018-01-05T17:59:40+0000","status":"ERROR","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1470","dateFinished":"2018-01-05T18:00:32+0000","dateStarted":"2018-01-05T18:00:32+0000","title":"Script to ensure that 12.2 jdbc driver is used by Spark executors","results":{"code":"ERROR","msg":[{"type":"TEXT","data":"mv: cannot stat `/opt/oracle/bdcsce/current/lib/ojdbc7.jar': No such file or directory\n"},{"type":"TEXT","data":"ExitValue: 1"}]}},{"title":"Script to test Spark interpreter","text":"%spark\n\n// BEFORE RUNNING THIS, YOU WILL NEED TO EDIT THIS\n//  1.Insert your database Connect String\n//  2.Insert your database user name\n//  3.Insert your database password\n\n\n//define URL for the Oracle JDBC driver\nprintln(\">>>>>>>Defining url for Oracle JDBC\")\n\n// http://www.oracle.com/technetwork/topics/wp-oracle-jdbc-thin-ssl-130128.pdf\n// https://docs.oracle.com/en/cloud/paas/exadata-express-cloud/csdbp/property-settings-jdbc-thin-driver-and-ucp.html\n//val url=\"jdbc:oracle:thin:@//\" + \"DCB-db-nov17:1521/PDB1.gse00002281.oraclecloud.internal\"\n//val url=\"jdbc:oracle:thin:@(description=(address=(protocol=tcps)(port=1522)(host=129.146.10.23))(connect_data=(service_name=FA539F1A563D4_DCBDW_high.dwcs.oracle.com))(security=(ssl_server_cert_dn=\\\"CN=cman4test.us1.oracletest.com,O=Oracle Corporation Test,L=Redwood Shores,ST=California,C=US\\\"))   )\"\n//val url=\"jdbc:oracle:oci8:@(description= (address=(protocol=tcps)(port=1522)(host=129.146.10.23))(connect_data=(service_name=FA539F1A563D4_DBAYARDDW_high.dwcs.oracle.com))(security=(ssl_server_cert_dn=\\\"CN=cman4test.us1.oracletest.com,O=Oracle Corporation Test,L=Redwood Shores,ST=California,C=US\\\"))   )\"\nval url=\"jdbc:oracle:oci8:@FA539F1A563D4_DBAYARDDW_high.dwcs.oracle.com\"\n//val url=\"jdbc:oracle:thin:@FA539F1A563D4_DCBDW_high.dwcs.oracle.com\"\n//define the username and password as properties\nprintln(\">>>>>>>Defining Oracle JDBC username and password\")\nprintln(url)\nval prop = new java.util.Properties\n\n//https://blogs.oracle.com/gc/unable-to-find-valid-certification-path-to-requested-target\n//seems like zeppelin already has its own truststore and keystore...\n\nprop.setProperty(\"user\",\"sh\")\nprop.setProperty(\"password\",\"Welcome1!\")\n//prop.setProperty(\"oracle.net.tns_admin\",\"/var/lib/zeppelin/tnsadmin\")\n//prop.setProperty(\"javax.net.ssl.trustStore\", \n//                  \"/home/opc/wallet_stuff/xtruststore.jks\")\n//prop.setProperty(\"javax.net.ssl.trustStoreType\",\"JKS\") \n//prop.setProperty(\"javax.net.ssl.trustStorePassword\",\"Welcome1!\")\n//prop.setProperty(\"oracle.net.ssl_server_dn_match\",\"true\") \n//prop.setProperty(\"javax.net.ssl.keyStore\", \n//                  \"/home/opc/wallet_stuff/xkeystore.jks\")\n//prop.setProperty(\"javax.net.ssl.keyStoreType\",\"JKS\")\n//prop.setProperty(\"javax.net.ssl.keyStorePassword\",\"Welcome1!\")\n//prop.setProperty(\"oracle.net.ssl_version\",\"1.2\")\n//prop.setProperty(\"oracle.net.ssl_cipher_suites\",\"TLS_RSA_WITH_AES_256_CBC_SHA256\")\nprop.setProperty(\"driver\",\"oracle.jdbc.OracleDriver\") //the driver is needed to be defined with Spark 1.6.1 due to https://issues.apache.org/jira/browse/SPARK-14204\n\n//now you can use JDBC commands like: val movies = sqlContext.read.jdbc(url,\"movie\",prop)\nval utables = sqlContext.read.jdbc(url,\"user_tables\",prop)\n//utables.explain()\nutables.printSchema()\n//utables.show()\n\n//register the emp dataframe as a SparkSQL table\nutables.createOrReplaceTempView(\"utables_sparksql\")\n\n//we can also do specific queries like the following (note that we write our query as if it was a subquery in the FROM section of a select statement)\nval ora_query = sqlContext.read.jdbc(url, \"(select u.tablespace_name, ts.status, count(*) tcount from user_tables u, user_tablespaces ts where u.tablespace_name=ts.tablespace_name group by u.tablespace_name, ts.status) eq\", prop)\nora_query.show()\n//emp_query.explain()\n\nprintln(\"done\")","user":"anonymous","dateUpdated":"2018-01-05T17:54:16+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":"true"},"editorMode":"ace/mode/scala","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515174773384_-1657101505","id":"20180105-175253_1061772504","dateCreated":"2018-01-05T17:52:53+0000","dateStarted":"2018-01-05T17:54:16+0000","status":"RUNNING","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:644"},{"text":"%sql\nselect table_name, num_rows, last_analyzed from utables_sparksql\nwhere num_rows > 0\norder by num_rows desc","user":"anonymous","dateUpdated":"2018-01-05T18:01:54+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sql"},"editorMode":"ace/mode/sql"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515175306813_-821076082","id":"20180105-180146_1838254935","dateCreated":"2018-01-05T18:01:46+0000","status":"PENDING","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1615","dateStarted":"2018-01-05T18:01:54+0000","errorMessage":""},{"text":"%md\n\nIn AMBARI:\nAdd LD_LIBRARY_PATH to Zeppelin via ambari.  Restart zeppelin\nexport LD_LIBRARY_PATH=/u01/bdcsce/opt/oracle/dbconnector/instantclient:$LD_LIBRARY_PATH\n\nIn Zeppelin JDBC Settings:\nAdd /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar\n\nIssues:\nIf password has ! in the URL\njava.sql.SQLException: Invalid Oracle URL specified\n\tat oracle.jdbc.driver.PhysicalConnection.parseUrl(PhysicalConnection.java:1213)\nFix: don't use ! in password if you specify password in URL\n\nif mnaually define password in jdbc setting:\njava.io.IOException: Incomplete HDFS URI, no host: hdfs:///user/zeppelin/interpreter-store.jks\nFix: add hostname to jdbc setting. example: jceks://hdfs@dcbdec13-bdcsce-1.compute-gse00010212.oraclecloud.internal/user/zeppelin/interpreter-store.jks\n\n\nIn Ambari(spark)\nsearch for ojdbc.  change to /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar\nNOTE ojdbc7 appears 3 times.  You need to change all 3\n\n[root@dcbdec13-bdcsce-1 tnsadmin]# cd /u01/bdcsce/opt/oracle/bdcsce/current/lib/\n[root@dcbdec13-bdcsce-1 lib]# ls -l\ntotal 18184\n-rw-r--r-- 1 root root   123244 Nov 18 01:11 hadoop-openstack-spoc.jar\n-rw-r--r-- 1 root root   736658 Nov 18 01:11 httpclient-4.5.2.jar\n-rw-r--r-- 1 root root   327373 Nov 18 01:11 httpcore-4.4.5.jar\n-rw-r--r-- 1 root root   300735 Nov 18 01:11 joss-bdcsce.jar\n-rw-r--r-- 1 root root    23931 Nov 18 01:11 json-simple-1.1.1.jar\n-rw-r--r-- 1 root root 13258259 Nov 18 01:11 oci-hdfs-full-1.2.5.jar\n-rw-r--r-- 1 root root  3699265 Nov 18 01:11 ojdbc7.jar\n-rw-r--r-- 1 root root    59617 Nov 18 01:11 spoccs-hdfs-zeppelin-0.5.1.jar\n-rw-r--r-- 1 root root    76413 Nov 18 01:11 stocator-bdcsce.jar\n[root@dcbdec13-bdcsce-1 lib]# mv ojdbc7.jar ojdbc7.jar.dontuse\n[root@dcbdec13-bdcsce-1 lib]# cp /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar .\n\nIn Zeppelin SPark Settings, change ojdbc7 to ojdbc8.\n\nIn Ambari(Spark)\nadvanced env... add this:\nexport LD_LIBRARY_PATH=/u01/bdcsce/opt/oracle/dbconnector/instantclient:$LD_LIBRARY_PATH\nspark.executor.extraLibraryPath\n\ncustom defaults\nadd:   spark.yarn.appMasterEnv.TNS_ADMIN=/var/lib/zeppelin/tnsadmin\n--DONT THINK THIS DOES ANYTHING\n\nin ambari (YARN)\nadd TNS_ADMIN\n\n","user":"anonymous","dateUpdated":"2018-01-04T21:26:11+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":"true"},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In AMBARI:<br/>Add LD_LIBRARY_PATH to Zeppelin via ambari. Restart zeppelin<br/>export LD_LIBRARY_PATH=/u01/bdcsce/opt/oracle/dbconnector/instantclient:$LD_LIBRARY_PATH</p>\n<p>In Zeppelin JDBC Settings:<br/>Add /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar</p>\n<p>Issues:<br/>If password has ! in the URL<br/>java.sql.SQLException: Invalid Oracle URL specified<br/> at oracle.jdbc.driver.PhysicalConnection.parseUrl(PhysicalConnection.java:1213)<br/>Fix: don&rsquo;t use ! in password if you specify password in URL</p>\n<p>if mnaually define password in jdbc setting:<br/>java.io.IOException: Incomplete HDFS URI, no host: <a href=\"hdfs:///user/zeppelin/interpreter-store.jks\">hdfs:///user/zeppelin/interpreter-store.jks</a><br/>Fix: add hostname to jdbc setting. example: <a href=\"jceks://hdfs@dcbdec13-bdcsce-1.compute-gse00010212.oraclecloud.internal/user/zeppelin/interpreter-store.jks\">jceks://hdfs@dcbdec13-bdcsce-1.compute-gse00010212.oraclecloud.internal/user/zeppelin/interpreter-store.jks</a></p>\n<p>In Ambari(spark)<br/>search for ojdbc. change to /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar<br/>NOTE ojdbc7 appears 3 times. You need to change all 3</p>\n<p>[root@dcbdec13-bdcsce-1 tnsadmin]# cd /u01/bdcsce/opt/oracle/bdcsce/current/lib/<br/>[root@dcbdec13-bdcsce-1 lib]# ls -l<br/>total 18184<br/>-rw-r&ndash;r&ndash; 1 root root 123244 Nov 18 01:11 hadoop-openstack-spoc.jar<br/>-rw-r&ndash;r&ndash; 1 root root 736658 Nov 18 01:11 httpclient-4.5.2.jar<br/>-rw-r&ndash;r&ndash; 1 root root 327373 Nov 18 01:11 httpcore-4.4.5.jar<br/>-rw-r&ndash;r&ndash; 1 root root 300735 Nov 18 01:11 joss-bdcsce.jar<br/>-rw-r&ndash;r&ndash; 1 root root 23931 Nov 18 01:11 json-simple-1.1.1.jar<br/>-rw-r&ndash;r&ndash; 1 root root 13258259 Nov 18 01:11 oci-hdfs-full-1.2.5.jar<br/>-rw-r&ndash;r&ndash; 1 root root 3699265 Nov 18 01:11 ojdbc7.jar<br/>-rw-r&ndash;r&ndash; 1 root root 59617 Nov 18 01:11 spoccs-hdfs-zeppelin-0.5.1.jar<br/>-rw-r&ndash;r&ndash; 1 root root 76413 Nov 18 01:11 stocator-bdcsce.jar<br/>[root@dcbdec13-bdcsce-1 lib]# mv ojdbc7.jar ojdbc7.jar.dontuse<br/>[root@dcbdec13-bdcsce-1 lib]# cp /u01/bdcsce/opt/oracle/dbconnector/instantclient/ojdbc8.jar .</p>\n<p>In Zeppelin SPark Settings, change ojdbc7 to ojdbc8.</p>\n<p>In Ambari(Spark)<br/>advanced env&hellip; add this:<br/>export LD_LIBRARY_PATH=/u01/bdcsce/opt/oracle/dbconnector/instantclient:$LD_LIBRARY_PATH<br/>spark.executor.extraLibraryPath</p>\n<p>custom defaults<br/>add: spark.yarn.appMasterEnv.TNS_ADMIN=/var/lib/zeppelin/tnsadmin<br/>&ndash;DONT THINK THIS DOES ANYTHING</p>\n<p>in ambari (YARN)<br/>add TNS_ADMIN</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1515086361693_-543124873","id":"20180104-171921_105762624","dateCreated":"2018-01-04T17:19:21+0000","dateStarted":"2018-01-04T21:26:11+0000","dateFinished":"2018-01-04T21:26:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:645"},{"text":"%jdbc(oracle-dave)\nselect user from dual\n","user":"anonymous","dateUpdated":"2018-01-04T18:31:38+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"USER\nDAVE\n"}]},"apps":[],"jobName":"paragraph_1515086407056_621971418","id":"20180104-172007_47864998","dateCreated":"2018-01-04T17:20:07+0000","dateStarted":"2018-01-04T18:31:38+0000","dateFinished":"2018-01-04T18:31:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:646"},{"text":"%md\n# Identifying your Oracle Database Cloud Service Connection Details\n\nThis tutorial will assume you are using an Oracle Database running in the Oracle Database Cloud Service.  To connect from BDCS-CE, we need to:\n\n + Identify the database connect string (which embeds the database hostname and service name)\n + Ensure that an Access Rule allows network traffic from BDCS-CE to the Database server\n\nIn general, a very useful resource will be the \"Oracle Database Cloud - Database as a Service Quick Start\" which can be found <a href=\"http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html\" target=\"_blank\">here</a>.  In particular, the topic \"Finding the Connection Details for your Database Instance\" provides the necessary details.  For simplicity, we will repeat the steps here:\n\nFollow these steps:\n\n + Navigate to the Oracle Database Cloud Service page for your DBCS instance.\n + Click on the Connect String to see the full value, highlight the full connect string, copy it into the clipboard, and save it somewhere for later use.\n![DBCS](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSconnectstring.gif \"DBCS\")\n\n \n\n","dateUpdated":"2018-01-04T16:19:01+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Identifying your Oracle Database Cloud Service Connection Details</h1>\n<p>This tutorial will assume you are using an Oracle Database running in the Oracle Database Cloud Service. To connect from BDCS-CE, we need to:</p>\n<ul>\n  <li>Identify the database connect string (which embeds the database hostname and service name)</li>\n  <li>Ensure that an Access Rule allows network traffic from BDCS-CE to the Database server</li>\n</ul>\n<p>In general, a very useful resource will be the &ldquo;Oracle Database Cloud - Database as a Service Quick Start&rdquo; which can be found <a href=\"http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html\" target=\"_blank\">here</a>. In particular, the topic &ldquo;Finding the Connection Details for your Database Instance&rdquo; provides the necessary details. For simplicity, we will repeat the steps here:</p>\n<p>Follow these steps:</p>\n<ul>\n  <li>Navigate to the Oracle Database Cloud Service page for your DBCS instance.</li>\n  <li>Click on the Connect String to see the full value, highlight the full connect string, copy it into the clipboard, and save it somewhere for later use.<br/><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSconnectstring.gif\" alt=\"DBCS\" title=\"DBCS\" /></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1515082741601_-319246617","id":"20170504-100100_110721875","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:647"},{"title":"Shell command to identify the private IP address of your BDCS-CE instance (used by next paragraph)","text":"%sh\nifconfig eth0","dateUpdated":"2018-01-04T16:19:01+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"false","language":"sh"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515082741602_-318092371","id":"20170701-092625_199273309","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:648"},{"text":"%md\n# Setting up an Access Rule for DBCS to allow BDCS-CE to connect\n\nWe need to ensure that your BDCS-CE instance can communicate with the database listener (port 1521) in your DBCS instance.  If you defined an Association between your BDCS-CE instance and your DBCS database when you created your BDCS-CE instance, then this access rule was created for you.  \n\nMost likely, you probably did NOT define an association between your DBCS database and your BDCS-CE instance at the time you provisioned the BDCS-CE instance.  Therefore, you will probably need to manually define a new access rule.  For this manually defined rule, you will need to use the private IP address of your BDCS-CE instance, which can be looked up via running the shell paragraph above.\n\nFor reference, review the  “Oracle Database Cloud - Database as a Service Quick Start” which can be found <a href=\"http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html\" target=\"_blank\">here</a>. In particular, the topic “Enabling Secure Network Access to your Database Instance” provides the necessary details. \n\nHere is an animation showing you how to:\n\n- Identify the private IP address of your BDCS-CE instance\n- Navigate to the DBCS instance console\n- Add a new Access Rule to the DBCS instance\n\n\n![DBCS2](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSaccess.gif \"DBCS2\")","dateUpdated":"2018-01-04T16:19:01+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Setting up an Access Rule for DBCS to allow BDCS-CE to connect</h1>\n<p>We need to ensure that your BDCS-CE instance can communicate with the database listener (port 1521) in your DBCS instance. If you defined an Association between your BDCS-CE instance and your DBCS database when you created your BDCS-CE instance, then this access rule was created for you. </p>\n<p>Most likely, you probably did NOT define an association between your DBCS database and your BDCS-CE instance at the time you provisioned the BDCS-CE instance. Therefore, you will probably need to manually define a new access rule. For this manually defined rule, you will need to use the private IP address of your BDCS-CE instance, which can be looked up via running the shell paragraph above.</p>\n<p>For reference, review the “Oracle Database Cloud - Database as a Service Quick Start” which can be found <a href=\"http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html\" target=\"_blank\">here</a>. In particular, the topic “Enabling Secure Network Access to your Database Instance” provides the necessary details. </p>\n<p>Here is an animation showing you how to:</p>\n<ul>\n  <li>Identify the private IP address of your BDCS-CE instance</li>\n  <li>Navigate to the DBCS instance console</li>\n  <li>Add a new Access Rule to the DBCS instance</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSaccess.gif\" alt=\"DBCS2\" title=\"DBCS2\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1515082741602_-318092371","id":"20170701-085521_963139788","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:649"},{"title":"Script to patch the Zeppelin JDBC interpreter jar file (ZEPPELIN-1962)","text":"%sh\n# There are some performance issues with Zeppelin 0.7.x jdbc interpreter and OracleDB due to a costly (slow) autocompletion feature.\n# See https://issues.apache.org/jira/browse/ZEPPELIN-1962  (also being tracked as oracle bug 27037280)\n# The workaround for Zeppelin is 0.7.x is to use a patched zeppelin jdbc interpreter jar file which disables autocompletion.\n\nmkdir /tmp/zepjdbc\ncd /tmp/zepjdbc\nwget https://issues.apache.org/jira/secure/attachment/12874854/zeppelin-jdbc-0.7.2.jar\nls -l zepp*\n\necho \"now putting files into place\"\nsudo mv /u01/bdcsce/usr/hdp/2.4.2.0-258/zeppelin-spark21/interpreter/jdbc/zeppelin-jdbc-0.7.0.2.6.0.3-8.jar /u01/bdcsce/usr/hdp/2.4.2.0-258/zeppelin-spark21/interpreter/jdbc/zeppelin-jdbc-0.7.0.2.6.0.3-8.jar.orig\nsudo cp /tmp/zepjdbc/zeppelin-jdbc-0.7.2.jar /u01/bdcsce/usr/hdp/2.4.2.0-258/zeppelin-spark21/interpreter/jdbc/zeppelin-jdbc-0.7.2.jar\n\n#make a small permission fix so that spark can query the local file system for later in this tutorial\nchmod a+rx /var/lib/zeppelin\n\necho \"done\"\n\n# You need to restart the zeppelin jdbc interpreter, but the next paragraph will do that for us\n","user":"anonymous","dateUpdated":"2018-01-04T16:46:53+0000","config":{"editorSetting":{"language":"sh","editOnDblClick":"false"},"colWidth":12,"editorMode":"ace/mode/sh","title":true,"results":{},"enabled":true,"editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"--2018-01-04 16:46:46--  https://issues.apache.org/jira/secure/attachment/12874854/zeppelin-jdbc-0.7.2.jar\nResolving issues.apache.org... 207.244.88.139\nConnecting to issues.apache.org|207.244.88.139|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 37587 (37K) [application/java-archive]\nSaving to: “zeppelin-jdbc-0.7.2.jar”\n\n     0K .......... .......... .......... ......               100%  426K=0.09s\n\n2018-01-04 16:46:47 (426 KB/s) - “zeppelin-jdbc-0.7.2.jar” saved [37587/37587]\n\n-rw-rw-r-- 1 zeppelin zeppelin 37587 Jan  4 16:46 zeppelin-jdbc-0.7.2.jar\nnow putting files into place\ndone\n"}]},"apps":[],"jobName":"paragraph_1515082741603_-318477120","id":"20171121-194433_1601292239","dateCreated":"2018-01-04T16:19:01+0000","dateStarted":"2018-01-04T16:46:46+0000","dateFinished":"2018-01-04T16:46:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:650"},{"title":"Script to setup the Zeppelin JDBC settings for Oracle database connection (edit user, password, connectstring in script)","text":"%sh\n\necho \"Set the User, Password, and ConnectString parameters in the script as appropriate\"\nUser=system\nPassword=Welcome1#\nConnectString=\"DCB-db-nov17:1521/PDB1.gse00002281.oraclecloud.internal\"\n#echo $ConnectString\n\necho \"Script to set some zeppelin jdbc parameters.\"\n\ncat <<EOF > /tmp/jdbc_settings.py\n#!/usr/local/bin/python\n#based on https://community.hortonworks.com/articles/36031/sample-code-to-automate-interacting-with-zeppelin.html by Ali Bajwa\ndef post_request(url, body):\n  import json, urllib2\n  encoded_body = json.dumps(body)\n  req = urllib2.Request(str(url), encoded_body)\n  req.get_method = lambda: 'PUT'\n  try:\n    response = urllib2.urlopen(req, encoded_body).read()\n  except urllib2.HTTPError, error:\n    print 'Exception: ' + error.read()\n  jsonresp = json.loads(response.decode('utf-8'))\n  print jsonresp['status']\n        \n \nimport json, urllib2\nzeppelin_int_url = 'http://127.0.0.1:9995/api/interpreter/setting/'\ndata = json.load(urllib2.urlopen(zeppelin_int_url))\nfor body in data['body']:\n  if body['group'] == 'jdbc':\n    jdbcbody = body\n  elif body['group'] == 'spark':\n    sparkbody = body    \n    \n \njdbcbody['properties']['orcl-$User.driver'] = 'oracle.jdbc.OracleDriver'\njdbcbody['properties']['orcl-$User.user'] = '$User'\n#jdbcbody['properties']['orcl-$User.password'] = '$Password'  \n#jdbcbody['properties']['orcl-$User.url'] = 'jdbc:oracle:thin:@//$ConnectString'\n#Zeppelin seems to be setting password to null, so leave it out\n#so for now, put the password in the connect string\njdbcbody['properties']['orcl-$User.url'] = 'jdbc:oracle:thin:$User/$Password@//$ConnectString'\n\n#ojdbc7.jar should now be preconfigured in bdcs-ce\n#my_dict = {'groupArtifactVersion':  '/u01/bdcsce/opt/oracle/bdcsce/current/lib/ojdbc7.jar',       'local': False}\n#jdbcbody['dependencies'].append(my_dict)\n\npost_request(zeppelin_int_url + jdbcbody['id'], jdbcbody)\nEOF\n#cat /tmp/jdbc_settings.py\necho \"..\"\npython /tmp/jdbc_settings.py\necho \"done\"\necho \"..\"\necho \"Use this syntax in Zeppelin to use the jdbc connection:\"\necho \"%jdbc(orcl-$User)\"\n","user":"anonymous","dateUpdated":"2018-01-04T16:47:15+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":"false"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Set the User, Password, and ConnectString parameters in the script as appropriate\nScript to set some zeppelin jdbc parameters.\n..\nOK\ndone\n..\nUse this syntax in Zeppelin to use the jdbc connection:\n%jdbc(orcl-system)\n"}]},"apps":[],"jobName":"paragraph_1515082741603_-318477120","id":"20171121-195921_884075422","dateCreated":"2018-01-04T16:19:01+0000","dateStarted":"2018-01-04T16:47:08+0000","dateFinished":"2018-01-04T16:47:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:651"},{"title":"Example of JDBC (change system to your database username)","text":"%jdbc(orcl-system)\nselect user from dual","user":"anonymous","dateUpdated":"2018-01-04T18:01:35+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":false,"language":"text"},"colWidth":12,"editorMode":"ace/mode/text","editorHide":false,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"USER\nDAVE\n"}]},"apps":[],"jobName":"paragraph_1515082741604_-320400864","id":"20170504-132054_979805353","dateCreated":"2018-01-04T16:19:01+0000","dateStarted":"2018-01-04T18:01:35+0000","dateFinished":"2018-01-04T18:01:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:652"},{"text":"%md\n# Using Spark to query the Oracle Database\n\nIn this section of the tutorial, we will show you working code examples that define a Spark Dataframe as an Oracle SQL query.  We then define a Spark SQL temporary table against that Dataframe to show you how you can futher use Spark SQL to filter and manipulate your selected data.\n\nTo run the spark code, you should **first edit the code and insert your specific database connect string, username, and password**.\n\n\n\nTo learn more about how Spark Data Frames work with JDBC data sources, check out <a href=\"https://spark.apache.org/docs/2.1.0/sql-programming-guide.html#jdbc-to-other-databases\" target=\"_blank\">here</a>.\n\n\n\n\n","dateUpdated":"2018-01-04T16:19:01+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Using Spark to query the Oracle Database</h1>\n<p>In this section of the tutorial, we will show you working code examples that define a Spark Dataframe as an Oracle SQL query. We then define a Spark SQL temporary table against that Dataframe to show you how you can futher use Spark SQL to filter and manipulate your selected data.</p>\n<p>To run the spark code, you should <strong>first edit the code and insert your specific database connect string, username, and password</strong>.</p>\n<p>To learn more about how Spark Data Frames work with JDBC data sources, check out <a href=\"https://spark.apache.org/docs/2.1.0/sql-programming-guide.html#jdbc-to-other-databases\" target=\"_blank\">here</a>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1515082741604_-320400864","id":"20170414-115733_409524242","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:653"},{"text":"%sh\nls -la /home/opc/wallet_stuff/\ngrep FA539F1A563D4_DCBDW_high.dwcs.oracle.com /home/opc/wallet_stuff/tnsnames.ora","dateUpdated":"2018-01-04T16:19:01+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":"false"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"total 96\ndrwxr-xr-x  2 opc opc  4096 Dec  6 23:29 .\ndrwxr-xr-x. 7 opc 500  4096 Dec  7 19:58 ..\n-rw-r--r--  1 opc opc  7005 Dec  7 02:12 cwallet.sso\n-rw-r--r--  1 opc opc  6960 Dec  7 02:12 ewallet.p12\n-rw-r--r--  1 opc opc  3207 Dec  7 02:12 keystore.jks\n-rw-r--r--  1 opc opc    87 Dec  7 02:12 ojdbc.properties\n-rw-r--r--  1 opc opc   114 Dec  7 02:12 sqlnet.ora\n-rw-r--r--  1 opc opc 54492 Dec  6 23:29 tnsnames.ora\n-rw-r--r--  1 opc opc  3629 Dec  7 02:12 truststore.jks\nFA539F1A563D4_DCBDW_high.dwcs.oracle.com = (description= (address=(protocol=tcps)(port=1522)(host=129.146.10.23))(connect_data=(service_name=FA539F1A563D4_DCBDW_high.dwcs.oracle.com))(security=(ssl_server_cert_dn=\r\nFA539F1A563D4_DCBDW_high.dwcs.oracle.com_ODPM = (description= (address=(https_proxy=www-proxy.us.oracle.com)(https_proxy_port=80)(protocol=tcps)(port=1522)(host=129.146.10.23))(connect_data=(service_name=FA539F1A563D4_DCBDW_high.dwcs.oracle.com))(security=(ssl_server_cert_dn=\r\n"}]},"apps":[],"jobName":"paragraph_1515082741605_-320785613","id":"20171207-190403_2022300705","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:654"},{"title":"Spark code to query the Oracle Database and define results and Spark SQL tables","text":"%spark\n\n// BEFORE RUNNING THIS, YOU WILL NEED TO EDIT THIS\n//  1.Insert your database Connect String\n//  2.Insert your database user name\n//  3.Insert your database password\n\n\n//define URL for the Oracle JDBC driver\nprintln(\">>>>>>>Defining url for Oracle JDBC\")\n\n// http://www.oracle.com/technetwork/topics/wp-oracle-jdbc-thin-ssl-130128.pdf\n// https://docs.oracle.com/en/cloud/paas/exadata-express-cloud/csdbp/property-settings-jdbc-thin-driver-and-ucp.html\n//val url=\"jdbc:oracle:thin:@//\" + \"DCB-db-nov17:1521/PDB1.gse00002281.oraclecloud.internal\"\n//val url=\"jdbc:oracle:thin:@(description=(address=(protocol=tcps)(port=1522)(host=129.146.10.23))(connect_data=(service_name=FA539F1A563D4_DCBDW_high.dwcs.oracle.com))(security=(ssl_server_cert_dn=\\\"CN=cman4test.us1.oracletest.com,O=Oracle Corporation Test,L=Redwood Shores,ST=California,C=US\\\"))   )\"\n//val url=\"jdbc:oracle:oci8:@(description= (address=(protocol=tcps)(port=1522)(host=129.146.10.23))(connect_data=(service_name=FA539F1A563D4_DBAYARDDW_high.dwcs.oracle.com))(security=(ssl_server_cert_dn=\\\"CN=cman4test.us1.oracletest.com,O=Oracle Corporation Test,L=Redwood Shores,ST=California,C=US\\\"))   )\"\nval url=\"jdbc:oracle:oci8:@FA539F1A563D4_DBAYARDDW_high.dwcs.oracle.com\"\n//val url=\"jdbc:oracle:thin:@FA539F1A563D4_DCBDW_high.dwcs.oracle.com\"\n//define the username and password as properties\nprintln(\">>>>>>>Defining Oracle JDBC username and password\")\nprintln(url)\nval prop = new java.util.Properties\n\n//https://blogs.oracle.com/gc/unable-to-find-valid-certification-path-to-requested-target\n//seems like zeppelin already has its own truststore and keystore...\n\nprop.setProperty(\"user\",\"sh\")\nprop.setProperty(\"password\",\"Welcome1!\")\n//prop.setProperty(\"oracle.net.tns_admin\",\"/var/lib/zeppelin/tnsadmin\")\n//prop.setProperty(\"javax.net.ssl.trustStore\", \n//                  \"/home/opc/wallet_stuff/xtruststore.jks\")\n//prop.setProperty(\"javax.net.ssl.trustStoreType\",\"JKS\") \n//prop.setProperty(\"javax.net.ssl.trustStorePassword\",\"Welcome1!\")\n//prop.setProperty(\"oracle.net.ssl_server_dn_match\",\"true\") \n//prop.setProperty(\"javax.net.ssl.keyStore\", \n//                  \"/home/opc/wallet_stuff/xkeystore.jks\")\n//prop.setProperty(\"javax.net.ssl.keyStoreType\",\"JKS\")\n//prop.setProperty(\"javax.net.ssl.keyStorePassword\",\"Welcome1!\")\n//prop.setProperty(\"oracle.net.ssl_version\",\"1.2\")\n//prop.setProperty(\"oracle.net.ssl_cipher_suites\",\"TLS_RSA_WITH_AES_256_CBC_SHA256\")\nprop.setProperty(\"driver\",\"oracle.jdbc.OracleDriver\") //the driver is needed to be defined with Spark 1.6.1 due to https://issues.apache.org/jira/browse/SPARK-14204\n\n//now you can use JDBC commands like: val movies = sqlContext.read.jdbc(url,\"movie\",prop)\nval utables = sqlContext.read.jdbc(url,\"user_tables\",prop)\n//utables.explain()\nutables.printSchema()\n//utables.show()\n\n//register the emp dataframe as a SparkSQL table\nutables.createOrReplaceTempView(\"utables_sparksql\")\n\n//we can also do specific queries like the following (note that we write our query as if it was a subquery in the FROM section of a select statement)\nval ora_query = sqlContext.read.jdbc(url, \"(select u.tablespace_name, ts.status, count(*) tcount from user_tables u, user_tablespaces ts where u.tablespace_name=ts.tablespace_name group by u.tablespace_name, ts.status) eq\", prop)\nora_query.show()\n//emp_query.explain()\n\nprintln(\"done\")","user":"anonymous","dateUpdated":"2018-01-04T21:28:05+0000","config":{"tableHide":false,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":">>>>>>>Defining url for Oracle JDBC\n\nurl: String = jdbc:oracle:oci8:@FA539F1A563D4_DBAYARDDW_high.dwcs.oracle.com\n>>>>>>>Defining Oracle JDBC username and password\njdbc:oracle:oci8:@FA539F1A563D4_DBAYARDDW_high.dwcs.oracle.com\n\nprop: java.util.Properties = {}\n\nres28: Object = null\n\nres29: Object = null\n\nres30: Object = null\n\nutables: org.apache.spark.sql.DataFrame = [TABLE_NAME: string, TABLESPACE_NAME: string ... 74 more fields]\nroot\n |-- TABLE_NAME: string (nullable = false)\n |-- TABLESPACE_NAME: string (nullable = true)\n |-- CLUSTER_NAME: string (nullable = true)\n |-- IOT_NAME: string (nullable = true)\n |-- STATUS: string (nullable = true)\n |-- PCT_FREE: decimal(38,10) (nullable = true)\n |-- PCT_USED: decimal(38,10) (nullable = true)\n |-- INI_TRANS: decimal(38,10) (nullable = true)\n |-- MAX_TRANS: decimal(38,10) (nullable = true)\n |-- INITIAL_EXTENT: decimal(38,10) (nullable = true)\n |-- NEXT_EXTENT: decimal(38,10) (nullable = true)\n |-- MIN_EXTENTS: decimal(38,10) (nullable = true)\n |-- MAX_EXTENTS: decimal(38,10) (nullable = true)\n |-- PCT_INCREASE: decimal(38,10) (nullable = true)\n |-- FREELISTS: decimal(38,10) (nullable = true)\n |-- FREELIST_GROUPS: decimal(38,10) (nullable = true)\n |-- LOGGING: string (nullable = true)\n |-- BACKED_UP: string (nullable = true)\n |-- NUM_ROWS: decimal(38,10) (nullable = true)\n |-- BLOCKS: decimal(38,10) (nullable = true)\n |-- EMPTY_BLOCKS: decimal(38,10) (nullable = true)\n |-- AVG_SPACE: decimal(38,10) (nullable = true)\n |-- CHAIN_CNT: decimal(38,10) (nullable = true)\n |-- AVG_ROW_LEN: decimal(38,10) (nullable = true)\n |-- AVG_SPACE_FREELIST_BLOCKS: decimal(38,10) (nullable = true)\n |-- NUM_FREELIST_BLOCKS: decimal(38,10) (nullable = true)\n |-- DEGREE: string (nullable = true)\n |-- INSTANCES: string (nullable = true)\n |-- CACHE: string (nullable = true)\n |-- TABLE_LOCK: string (nullable = true)\n |-- SAMPLE_SIZE: decimal(38,10) (nullable = true)\n |-- LAST_ANALYZED: timestamp (nullable = true)\n |-- PARTITIONED: string (nullable = true)\n |-- IOT_TYPE: string (nullable = true)\n |-- TEMPORARY: string (nullable = true)\n |-- SECONDARY: string (nullable = true)\n |-- NESTED: string (nullable = true)\n |-- BUFFER_POOL: string (nullable = true)\n |-- FLASH_CACHE: string (nullable = true)\n |-- CELL_FLASH_CACHE: string (nullable = true)\n |-- ROW_MOVEMENT: string (nullable = true)\n |-- GLOBAL_STATS: string (nullable = true)\n |-- USER_STATS: string (nullable = true)\n |-- DURATION: string (nullable = true)\n |-- SKIP_CORRUPT: string (nullable = true)\n |-- MONITORING: string (nullable = true)\n |-- CLUSTER_OWNER: string (nullable = true)\n |-- DEPENDENCIES: string (nullable = true)\n |-- COMPRESSION: string (nullable = true)\n |-- COMPRESS_FOR: string (nullable = true)\n |-- DROPPED: string (nullable = true)\n |-- READ_ONLY: string (nullable = true)\n |-- SEGMENT_CREATED: string (nullable = true)\n |-- RESULT_CACHE: string (nullable = true)\n |-- CLUSTERING: string (nullable = true)\n |-- ACTIVITY_TRACKING: string (nullable = true)\n |-- DML_TIMESTAMP: string (nullable = true)\n |-- HAS_IDENTITY: string (nullable = true)\n |-- CONTAINER_DATA: string (nullable = true)\n |-- INMEMORY: string (nullable = true)\n |-- INMEMORY_PRIORITY: string (nullable = true)\n |-- INMEMORY_DISTRIBUTE: string (nullable = true)\n |-- INMEMORY_COMPRESSION: string (nullable = true)\n |-- INMEMORY_DUPLICATE: string (nullable = true)\n |-- DEFAULT_COLLATION: string (nullable = true)\n |-- DUPLICATED: string (nullable = true)\n |-- SHARDED: string (nullable = true)\n |-- EXTERNAL: string (nullable = true)\n |-- CELLMEMORY: string (nullable = true)\n |-- CONTAINERS_DEFAULT: string (nullable = true)\n |-- CONTAINER_MAP: string (nullable = true)\n |-- EXTENDED_DATA_LINK: string (nullable = true)\n |-- EXTENDED_DATA_LINK_MAP: string (nullable = true)\n |-- INMEMORY_SERVICE: string (nullable = true)\n |-- INMEMORY_SERVICE_NAME: string (nullable = true)\n |-- CONTAINER_MAP_OBJECT: string (nullable = true)\n\n\nora_query: org.apache.spark.sql.DataFrame = [TABLESPACE_NAME: string, STATUS: string ... 1 more field]\n+---------------+------+-------------+\n|TABLESPACE_NAME|STATUS|       TCOUNT|\n+---------------+------+-------------+\n|           DATA|ONLINE|11.0000000000|\n+---------------+------+-------------+\n\ndone\n"}]},"apps":[],"jobName":"paragraph_1515082741605_-320785613","id":"20170414-115750_30775030","dateCreated":"2018-01-04T16:19:01+0000","dateStarted":"2018-01-04T21:28:05+0000","dateFinished":"2018-01-04T21:28:12+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:655"},{"title":"SparkSQL Example against our Oracle Database-based Data Frame","text":"%sql\nselect table_name, num_rows, last_analyzed from utables_sparksql\nwhere num_rows > 0\norder by num_rows desc","user":"anonymous","dateUpdated":"2018-01-04T21:27:48+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","editorHide":false,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"EMPNO","index":0,"aggr":"sum"}],"values":[{"name":"ENAME","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"EMPNO","index":0,"aggr":"sum"},"yAxis":{"name":"ENAME","index":1,"aggr":"sum"}}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"table_name\tnum_rows\tlast_analyzed\nSALES_C\t377059456.0000000000\t2017-12-15 14:46:47.0\nSALES\t94264864.0000000000\t2017-12-15 12:52:46.0\nCUSTOMERS_C\t31220736.0000000000\t2017-12-15 14:39:52.0\nSUPPLEMENTARY_DEMOGRAPHICS_C\t28669440.0000000000\t2017-12-15 14:40:29.0\nCUSTOMERS\t10406912.0000000000\t2017-12-15 12:53:39.0\nSUPPLEMENTARY_DEMOGRAPHICS\t9556480.0000000000\t2017-12-15 12:53:59.0\nTIMES\t7305.0000000000\t2017-12-15 12:09:50.0\nPROMOTIONS\t503.0000000000\t2017-12-15 12:09:43.0\nPRODUCTS\t72.0000000000\t2017-12-15 12:09:43.0\nCOUNTRIES\t23.0000000000\t2017-12-15 12:09:39.0\nCHANNELS\t5.0000000000\t2017-12-15 12:09:39.0\n"}]},"apps":[],"jobName":"paragraph_1515082741606_-319631366","id":"20170414-120105_774930594","dateCreated":"2018-01-04T16:19:01+0000","dateStarted":"2018-01-04T21:27:48+0000","dateFinished":"2018-01-04T21:27:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:656"},{"text":"%md\n# Using Spark to write to the Oracle Database\n\nNow we will show a working example of writing back to the Oracle Database from Spark.  If you observed above, we created a Spark dataframe called emp_query.  In the following example, we will write this dataframe back to the Oracle Database as a new table called emp_query.\n\nFor this example, we will use Spark to read in some Citibike data and write that data into an Oracle table.\n","dateUpdated":"2018-01-04T16:19:01+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Using Spark to write to the Oracle Database</h1>\n<p>Now we will show a working example of writing back to the Oracle Database from Spark. If you observed above, we created a Spark dataframe called emp_query. In the following example, we will write this dataframe back to the Oracle Database as a new table called emp_query.</p>\n<p>For this example, we will use Spark to read in some Citibike data and write that data into an Oracle table.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1515082741606_-319631366","id":"20170504-134249_302037388","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:657"},{"title":"Spark Scala to read CSV and register as Spark SQL temporary table","text":"%spark\n\n//a previous tutorial placed the csv file into /var/lib/zeppelin/bikes/201612-citibike-tripdata.csv\n\nval df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"file:/var/lib/zeppelin/citibike/201612-citibike-tripdata.csv\")\n\n//cache the data frame for performance\ndf.cache()\n\n\nprintln(\"Here is the schema detected from the CSV\")\ndf.printSchema()\nprintln(\"..\")\n\nprintln(\"# of rows: %s\".format(\n  df.count() \n)) \nprintln(\"..\")\n\ndf.createOrReplaceTempView(\"bike_trips_csvtemp\")\nprintln(\"done\")","dateUpdated":"2018-01-04T16:19:01+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515082741607_-320016115","id":"20170701-170923_1753081660","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:658"},{"title":"Spark to write a DataFrame to an Oracle table","text":"%spark\n\n\n\n// To make sure we have Oracle friendly column names, lets select against our Spark SQL temp table and rename columns\nprintln(\"Renaming column names via bike_query...\")\nval bike_query = sqlContext.sql(\"\"\"select `Trip Duration` TRIPDURATION, \n`Start Time` STARTTIME, \n`Stop Time` STOPTIME, \n`Start Station ID` STARTSTATIONID, \n`Start Station Name` STARTSTATIONNAME, \n`Start Station Latitude` STARTSTATIONLATITUDE, \n`Start Station Longitude` STARTSTATIONLONGITUDE, \n`End Station ID` ENDSTATIONID, \n`End Station Name` ENDSTATIONNAME, \n`End Station Latitude` ENDSTATIONLATITUDE, \n`End Station Longitude` ENDSTATIONLONGITUDE, \n`Bike ID` BIKEID, \n`User Type` USERTYPE, \n`Birth Year` BIRTHYEAR, \n`Gender` GENDER \n from bike_trips_csvtemp\"\"\")\n \nbike_query.show()\nbike_query.printSchema()\n\n\nimport org.apache.spark.sql.SaveMode\n//possible SaveModes are SaveMode.Append, SaveMode.Overwrite, SaveMode.ErrorIfExists, SaveMode.Ignore\n\n\nprintln(\"Writing Spark DataFrame to Oracle Database.  This may take a few minutes.\")\nbike_query.write\n   .mode(SaveMode.Overwrite)\n   .jdbc(url,\"CITIBIKE_ORCL\",prop)\n\n\n//your Spark dataframe needs to use valid Oracle column names (i.e. no spaces, no reserved words, etc).  If you need to rename dataframe fields, you can do operations like this\n//val newdDF=oldDF.withColumnRenamed(\"Birth Year\",\"BirthYear\")\n\n\nprintln(\"done\")","dateUpdated":"2018-01-04T16:19:01+0000","config":{"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515082741607_-320016115","id":"20170813-182552_758023941","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:659"},{"title":"JDBC to query Oracle and see the new Oracle table","text":"%jdbc(orcl-system)\nselect * from CITIBIKE_ORCL","dateUpdated":"2018-01-04T16:19:01+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"text"},"colWidth":12,"editorMode":"ace/mode/text","editorHide":false,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515082741608_-321939860","id":"20170504-145612_585260865","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:660"},{"dateUpdated":"2018-01-04T16:19:01+0000","config":{"editorSetting":{},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1515082741608_-321939860","id":"20170414-131833_1025546137","dateCreated":"2018-01-04T16:19:01+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:661"}],"name":"Extras/Working with ADWC","id":"2D2PHQ84T","angularObjects":{"2D1TJSV9V:shared_process":[],"2D46JFPJG:shared_process":[],"2D2YE91QH:shared_process":[],"2CZX4RY25:shared_process":[],"2D2TS63QB:shared_process":[],"2D2URAWGN:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CZX56P84:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}