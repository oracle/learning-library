{"paragraphs":[{"text":"%md\n# DataSci Tutorial 2: Using R with Zeppelin\n\nThis tutorial was built for BDCS-CE version 17.4.1 as part of the Data Science Acceleration User Journey: <a href=\"https://oracle.github.io/learning-library/workshops/journey3-data-science/\" target=\"_blank\">here</a>.  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\n    Be sure you previously ran the Tutorial \"Setup R, SparkR, RStudio Server\".\n\nThis tutorial provides some examples of using R and SparkR in Zeppelin notebooks.  It will show:\n\n+ How to query a hive table from R\n+ How to read data directly from the Object Store\n+ How to convert a R data.frame into a Spark Temporary Table and query it with SparkSQL\n+ Machine Learning with R and Spark\n+ Save results back to the Object Store\n\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>DataSci Tutorial 2: Using R with Zeppelin</h1>\n<p>This tutorial was built for BDCS-CE version 17.4.1 as part of the Data Science Acceleration User Journey: <a href=\"https://oracle.github.io/learning-library/workshops/journey3-data-science/\" target=\"_blank\">here</a>. Questions and feedback about the tutorial: <a href=\"mailto:&#100;a&#118;&#x69;&#x64;&#x2e;&#x62;&#97;&#x79;&#x61;r&#100;&#x40;&#111;r&#97;&#99;&#108;e&#46;c&#x6f;&#109;\">&#100;a&#118;&#x69;&#x64;&#x2e;&#x62;&#97;&#x79;&#x61;r&#100;&#x40;&#111;r&#97;&#99;&#108;e&#46;c&#x6f;&#109;</a></p>\n<pre><code>Be sure you previously ran the Tutorial &quot;Setup R, SparkR, RStudio Server&quot;.\n</code></pre>\n<p>This tutorial provides some examples of using R and SparkR in Zeppelin notebooks. It will show:</p>\n<ul>\n  <li>How to query a hive table from R</li>\n  <li>How to read data directly from the Object Store</li>\n  <li>How to convert a R data.frame into a Spark Temporary Table and query it with SparkSQL</li>\n  <li>Machine Learning with R and Spark</li>\n  <li>Save results back to the Object Store</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1517497663201_1205196151","id":"20170811-183847_958683840","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:670"},{"text":"%md\n# About R and Zeppelin\n\nZeppelin includes an interpreter that is integrated with R and SparkR.  You can find some details about Zeppelin and R <a href=\"https://zeppelin.apache.org/docs/0.7.0/interpreter/r.html\" target=\"_blank\">here</a>.  You can find some details about SparkR <a href=\"https://spark.apache.org/docs/2.1.0/sparkr.html\" target=\"_blank\">here</a>.\n\nThese examples focuses on using R to work with Spark features like DataFrames.  As the SparkR documentation writes, \"A SparkDataFrame is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R, but with richer optimizations under the hood. SparkDataFrames can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing local R data frames\".  This tutorial will demonstrate some of these capabilities.\n\n\n\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>About R and Zeppelin</h1>\n<p>Zeppelin includes an interpreter that is integrated with R and SparkR. You can find some details about Zeppelin and R <a href=\"https://zeppelin.apache.org/docs/0.7.0/interpreter/r.html\" target=\"_blank\">here</a>. You can find some details about SparkR <a href=\"https://spark.apache.org/docs/2.1.0/sparkr.html\" target=\"_blank\">here</a>.</p>\n<p>These examples focuses on using R to work with Spark features like DataFrames. As the SparkR documentation writes, &ldquo;A SparkDataFrame is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R, but with richer optimizations under the hood. SparkDataFrames can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing local R data frames&rdquo;. This tutorial will demonstrate some of these capabilities.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1517497663202_1206350398","id":"20170807-213713_1708624789","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:671"},{"text":"%md\n# Example of R querying Hive\n\nThis example shows how to use R to query the bike_trips hive table via SparkR features.\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Example of R querying Hive</h1>\n<p>This example shows how to use R to query the bike_trips hive table via SparkR features.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1517497663202_1206350398","id":"20170810-001234_1882189757","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:672"},{"title":"SparkR to query a Hive table","text":"%r\nresults <- sql(\"SELECT * from bike_trips\")\nhead(results)\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"tableHide":false,"editorSetting":{"language":"r","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/r","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517497663202_1206350398","id":"20170810-001354_1251372462","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:673"},{"text":"%r\n# let's see what kind of class our results are...\nresults\n# It is a SparkDataFrame","dateUpdated":"2018-02-01T15:07:43+0000","config":{"colWidth":12,"editorMode":"ace/mode/r","results":{},"enabled":true,"editorSetting":{"language":"r"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517497663203_1205965649","id":"20170811-185109_995138400","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:674"},{"text":"%md\n# Example of reading a CSV from Object Store\n\nThis example shows SparkR features to read a CSV from Object Store via Spark's DataSources mechanisms\n\n\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"editorSetting":{"language":"text","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/text","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Example of reading a CSV from Object Store</h1>\n<p>This example shows SparkR features to read a CSV from Object Store via Spark&rsquo;s DataSources mechanisms</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1517497663203_1205965649","id":"20170810-001731_1366310690","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:675"},{"text":"%r\nbiketrips <- read.df(\"swift://journeyC.default/citibike/raw/201612-citibike-tripdata.csv\", \"csv\", header = \"true\", inferSchema = \"true\", na.strings = \"NA\")\nhead(biketrips)\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"colWidth":12,"editorMode":"ace/mode/r","results":{},"enabled":true,"editorSetting":{"language":"r","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517497663203_1205965649","id":"20170810-001850_158683843","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:676"},{"text":"%md\n# Example of making a R dataframe into a SparkSQL table\n\nHere is an example of converting a R data.frame into a Spark DataFrame and registering it as a Spark SQL table.  You can more examples like this <a href=\"https://rpubs.com/wendyu/sparkr\" target=\"_blank\">here</a>.\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Example of making a R dataframe into a SparkSQL table</h1>\n<p>Here is an example of converting a R data.frame into a Spark DataFrame and registering it as a Spark SQL table. You can more examples like this <a href=\"https://rpubs.com/wendyu/sparkr\" target=\"_blank\">here</a>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1517497663203_1205965649","id":"20170810-002107_611682017","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:677"},{"title":"Load an R data frame","text":"%r\ndata(iris)\niris","user":"anonymous","dateUpdated":"2018-03-02T16:07:13+0000","config":{"editorSetting":{"language":"r"},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nSepal.Length Sepal.Width Petal.Length Petal.Width    Species\n\n\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1517497663204_1204041904","id":"20170808-174600_955896680","dateCreated":"2018-02-01T15:07:43+0000","dateStarted":"2018-03-02T16:07:14+0000","dateFinished":"2018-03-02T16:07:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:678"},{"title":"SparkR code to register an R dataframe as a SparkSQL table","text":"%r\nirisDF <- as.DataFrame(iris)\nregisterTempTable(irisDF,\"iris\")\nirisDF\n","user":"anonymous","dateUpdated":"2018-03-02T16:08:41+0000","config":{"editorSetting":{"language":"r"},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nSparkDataFrame[Sepal_Length:double, Sepal_Width:double, Petal_Length:double, Petal_Width:double, Species:string]\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1517497663204_1204041904","id":"20170808-185507_1332635419","dateCreated":"2018-02-01T15:07:43+0000","dateStarted":"2018-03-02T16:08:41+0000","dateFinished":"2018-03-02T16:08:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:679"},{"text":"%sh\nsudo R -e \"install.packages('pryr', repos = 'http://cran.us.r-project.org')\"\n","user":"anonymous","dateUpdated":"2018-03-04T21:15:07+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\nOracle Distribution of R version 3.2.0  (--) -- \"Full of Ingredients\"\nCopyright (C)  The R Foundation for Statistical Computing\nPlatform: x86_64-unknown-linux-gnu (64-bit)\n\nR is free software and comes with ABSOLUTELY NO WARRANTY.\nYou are welcome to redistribute it under certain conditions.\nType 'license()' or 'licence()' for distribution details.\n\n  Natural language support but running in an English locale\n\nR is a collaborative project with many contributors.\nType 'contributors()' for more information and\n'citation()' on how to cite R or R packages in publications.\n\nType 'demo()' for some demos, 'help()' for on-line help, or\n'help.start()' for an HTML browser interface to help.\nType 'q()' to quit R.\n\nYou are using Oracle's distribution of R. Please contact\nOracle Support for any problems you encounter with this\ndistribution.\n\n> install.packages('pryr', repos = 'http://cran.us.r-project.org')\nInstalling package into ‘/usr/lib64/R/library’\n(as ‘lib’ is unspecified)\ntrying URL 'http://cran.us.r-project.org/src/contrib/pryr_0.1.4.tar.gz'\nContent type 'application/x-gzip' length 43041 bytes (42 KB)\n==================================================\ndownloaded 42 KB\n\n* installing *source* package ‘pryr’ ...\n** package ‘pryr’ successfully unpacked and MD5 sums checked\n** libs\ng++ -m64 -I/usr/include/R -DNDEBUG  -I/usr/local/include -I\"/usr/lib64/R/library/Rcpp/include\"   -fpic  -g -O2  -c RcppExports.cpp -o RcppExports.o\ng++ -m64 -I/usr/include/R -DNDEBUG  -I/usr/local/include -I\"/usr/lib64/R/library/Rcpp/include\"   -fpic  -g -O2  -c bytes.cpp -o bytes.o\ng++ -m64 -I/usr/include/R -DNDEBUG  -I/usr/local/include -I\"/usr/lib64/R/library/Rcpp/include\"   -fpic  -g -O2  -c inspect.cpp -o inspect.o\ng++ -m64 -I/usr/include/R -DNDEBUG  -I/usr/local/include -I\"/usr/lib64/R/library/Rcpp/include\"   -fpic  -g -O2  -c object_size.cpp -o object_size.o\ng++ -m64 -I/usr/include/R -DNDEBUG  -I/usr/local/include -I\"/usr/lib64/R/library/Rcpp/include\"   -fpic  -g -O2  -c promise.cpp -o promise.o\ngcc -m64 -std=gnu99 -I/usr/include/R -DNDEBUG  -I/usr/local/include -I\"/usr/lib64/R/library/Rcpp/include\"   -fpic  -g -O2  -c size-info.c -o size-info.o\ng++ -m64 -I/usr/include/R -DNDEBUG  -I/usr/local/include -I\"/usr/lib64/R/library/Rcpp/include\"   -fpic  -g -O2  -c slice.cpp -o slice.o\ng++ -m64 -I/usr/include/R -DNDEBUG  -I/usr/local/include -I\"/usr/lib64/R/library/Rcpp/include\"   -fpic  -g -O2  -c typename.cpp -o typename.o\ng++ -m64 -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o pryr.so RcppExports.o bytes.o inspect.o object_size.o promise.o size-info.o slice.o typename.o -L/usr/lib64/R/lib -lR\ninstalling to /usr/lib64/R/library/pryr/libs\n** R\n** preparing package for lazy loading\n** help\n*** installing help indices\n  converting help for package ‘pryr’\n    finding HTML links ... done\n    as.envlist                              html  \n    assign-active                           html  \n    assign-constant                         html  \n    assign-delayed                          html  \n    bytes                                   html  \n    call_tree                               html  \n    compose                                 html  \n    dots                                    html  \n    enclosing_env                           html  \n    explicit                                html  \n    f                                       html  \n    fget                                    html  \n    find_funs                               html  \n    find_uses                               html  \n    ftype                                   html  \n    inspect                                 html  \n    is_active_binding                       html  \n    is_promise                              html  \n    is_s3_generic                           html  \n    make_call                               html  \n    make_function                           html  \n    mem_change                              html  \n    mem_used                                html  \n    method_from_call                        html  \n    modify_call                             html  \n    modify_lang                             html  \n    names_c                                 html  \n    object_size                             html  \n    otype                                   html  \n    parent_promise                          html  \n    parenv                                  html  \n    parenvs                                 html  \n    partial                                 html  \n    print.envlist                           html  \n    rebind                                  html  \n    rls                                     html  \n    show_c_source                           html  \n    standardise_call                        html  \n    subs                                    html  \n    substitute_q                            html  \n    track_copy                              html  \n    unenclose                               html  \n    uneval                                  html  \n    where                                   html  \n** building package indices\n** testing if installed package can be loaded\n* DONE (pryr)\nMaking 'packages.html' ... done\n\nThe downloaded source packages are in\n\t‘/tmp/Rtmpl0ZARR/downloaded_packages’\nUpdating HTML index of packages in '.Library'\nMaking 'packages.html' ... done\n> \n> \n"}]},"apps":[],"jobName":"paragraph_1520198094616_201866568","id":"20180304-211454_794252440","dateCreated":"2018-03-04T21:14:54+0000","dateStarted":"2018-03-04T21:15:07+0000","dateFinished":"2018-03-04T21:15:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:680"},{"text":"%md\n# Memory issue with large R data.frames converting to Spark Dataframes\n\nhttps://stackoverflow.com/questions/28878654/spark-using-python-how-to-resolve-stage-x-contains-a-task-of-very-large-size-x\n\nhttps://stackoverflow.com/questions/39564422/how-to-load-large-r-data-frames-into-spark-using-sparkrs-as-dataframe\nhttps://stackoverflow.com/questions/39392327/how-best-to-handle-converting-a-large-local-data-frame-to-a-sparkr-data-frame\n\nConclusions:\n1.for big data sets, definitely use numPartitions.  For 10^6 rows with 3 columns, had to use numPartitions=2000\n2.R Dates are really slow to process\n3.Use a R List instead of a R data.frame to avoid some of the work needed.\n\n\n","user":"anonymous","dateUpdated":"2018-03-04T22:47:56+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520203565615_36142946","id":"20180304-224605_763138928","dateCreated":"2018-03-04T22:46:05+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3285","dateFinished":"2018-03-04T22:47:58+0000","dateStarted":"2018-03-04T22:47:56+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Memory issue with large R data.frames converting to Spark Dataframes</h1>\n<p><a href=\"https://stackoverflow.com/questions/28878654/spark-using-python-how-to-resolve-stage-x-contains-a-task-of-very-large-size-x\">https://stackoverflow.com/questions/28878654/spark-using-python-how-to-resolve-stage-x-contains-a-task-of-very-large-size-x</a></p>\n<p><a href=\"https://stackoverflow.com/questions/39564422/how-to-load-large-r-data-frames-into-spark-using-sparkrs-as-dataframe\">https://stackoverflow.com/questions/39564422/how-to-load-large-r-data-frames-into-spark-using-sparkrs-as-dataframe</a><br/><a href=\"https://stackoverflow.com/questions/39392327/how-best-to-handle-converting-a-large-local-data-frame-to-a-sparkr-data-frame\">https://stackoverflow.com/questions/39392327/how-best-to-handle-converting-a-large-local-data-frame-to-a-sparkr-data-frame</a></p>\n<p>Conclusions:<br/>1.for big data sets, definitely use numPartitions. For 10^6 rows with 3 columns, had to use numPartitions=2000<br/>2.R Dates are really slow to process<br/>3.Use a R List instead of a R data.frame to avoid some of the work needed.</p>\n</div>"}]}},{"text":"%r\nlibrary(pryr)\nmem_used()","user":"anonymous","dateUpdated":"2018-03-04T21:57:19+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n33.5 MB\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520197884142_-1675245050","id":"20180304-211124_185556331","dateCreated":"2018-03-04T21:11:24+0000","dateStarted":"2018-03-04T21:57:20+0000","dateFinished":"2018-03-04T21:58:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:681"},{"text":"%r\nn =10^6\n\nemployee <- rep(\"ABC\",n)\n\nsalary <- runif(n, min=240000, max=5000000)\n\nstartdate <- seq(as.Date(\"2000/1/1\"), by = \"day\", length.out = n)\n\n#schemaPeople <- data.frame(employee, salary, startdate)\nschemaPeople <- data.frame(employee, salary)\n\nformat(object.size(schemaPeople),units=\"MB\") \n\nbigDF <- as.DataFrame(schemaPeople, numPartitions = 1000)","user":"anonymous","dateUpdated":"2018-03-04T22:42:48+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520201803482_1130087525","id":"20180304-221643_787796410","dateCreated":"2018-03-04T22:16:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3138","dateFinished":"2018-03-04T22:43:06+0000","dateStarted":"2018-03-04T22:42:48+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n[1] “11.4 Mb”\n\n\n\n"}]}},{"text":"%r\nmem_used()\nn =10^7 * 4\n\nemployee <- rep(\"ABC\",n)\n\nsalary <- runif(n, min=240000, max=5000000)\n\nstartdate <- seq(as.Date(\"2000/1/1\"), by = \"day\", length.out = n)\n\n#schemaPeople <- data.frame(employee, salary, startdate)\nschemaPeople <- data.frame(employee, salary)\nformat(object.size(schemaPeople),units=\"MB\")\nmem_used()","user":"anonymous","dateUpdated":"2018-03-04T22:10:26+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n130 MB\n[1] “457.8 Mb”\n994 MB\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520198245793_-389137867","id":"20180304-211725_632508813","dateCreated":"2018-03-04T21:17:25+0000","dateStarted":"2018-03-04T22:10:27+0000","dateFinished":"2018-03-04T22:10:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:682"},{"text":"%r\ntmp <- tempfile()\nmem_used()\nRprof(tmp)\nmem_change(bigDF <- as.DataFrame(schemaPeople, numPartitions = 1000))\nRprof(NULL)\nmem_used()","user":"anonymous","dateUpdated":"2018-03-04T22:11:45+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n994 MB\n\nError in rep(start, end - start): invalid 'times' argument\n\n\n994 MB\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520198284548_205360480","id":"20180304-211804_1846776300","dateCreated":"2018-03-04T21:18:04+0000","dateStarted":"2018-03-04T22:11:45+0000","dateFinished":"2018-03-04T22:15:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:683"},{"text":"%r\nsummaryRprof(tmp, basenames=2)\nunlink(tmp) ","user":"anonymous","dateUpdated":"2018-03-04T21:22:56+0000","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":278.95,"optionOpen":false}}},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n$by.self\n                      self.time self.pct total.time total.pct\n“”              3.06    36.34       8.42    100.00\n“unserialize”              1.44    17.10       1.44     17.10\n“FUN”                      1.10    13.06       2.62     31.12\n“writeBin”                 0.80     9.50       0.80      9.50\n“as.character”             0.50     5.94       0.52      6.18\n“gc”                       0.44     5.23       0.44      5.23\n“structure”                0.40     4.75       0.84      9.98\n“rawConnectionValue”       0.38     4.51       0.38      4.51\n“split.default”            0.08     0.95       0.68      8.08\n“unique.default”           0.06     0.71       0.06      0.71\n“match”                    0.04     0.48       0.06      0.71\n“readBin”                  0.04     0.48       0.04      0.48\n“as.character.factor”      0.02     0.24       0.02      0.24\n“pmatch”                   0.02     0.24       0.02      0.24\n“raw”                      0.02     0.24       0.02      0.24\n“unlist”                   0.02     0.24       0.02      0.24\n\n$by.total\n                      total.time total.pct self.time self.pct\n“”               8.42    100.00      3.06    36.34\n“block_exec”                8.42    100.00      0.00     0.00\n“call_block”                8.42    100.00      0.00     0.00\n“doTryCatch”                8.42    100.00      0.00     0.00\n“eval”                      8.42    100.00      0.00     0.00\n“evaluate”                  8.42    100.00      0.00     0.00\n“evaluate_call”             8.42    100.00      0.00     0.00\n“handle”                    8.42    100.00      0.00     0.00\n“in_dir”                    8.42    100.00      0.00     0.00\n“knit”                      8.42    100.00      0.00     0.00\n“knit2html”                 8.42    100.00      0.00     0.00\n“mem_change”                8.42    100.00      0.00     0.00\n“process_file”              8.42    100.00      0.00     0.00\n“process_group”             8.42    100.00      0.00     0.00\n“process_group.block”       8.42    100.00      0.00     0.00\n“timing_fn”                 8.42    100.00      0.00     0.00\n“try”                       8.42    100.00      0.00     0.00\n“tryCatch”                  8.42    100.00      0.00     0.00\n“tryCatchList”              8.42    100.00      0.00     0.00\n“tryCatchOne”               8.42    100.00      0.00     0.00\n“withCallingHandlers”       8.42    100.00      0.00     0.00\n“withVisible”               8.42    100.00      0.00     0.00\n“as.DataFrame”              7.98     94.77      0.00     0.00\n“createDataFrame”           7.98     94.77      0.00     0.00\n“dispatchFunc”              7.98     94.77      0.00     0.00\n“f”                         7.98     94.77      0.00     0.00\n“parallelize”               3.38     40.14      0.00     0.00\n“do.call”                   3.06     36.34      0.00     0.00\n“FUN”                       2.62     31.12      1.10    13.06\n“lapply”                    2.62     31.12      0.00     0.00\n“standardGeneric”           2.62     31.12      0.00     0.00\n“convertJListToRList”       1.50     17.81      0.00     0.00\n“firstRDD”                  1.50     17.81      0.00     0.00\n“.local”                    1.50     17.81      0.00     0.00\n“takeRDD”                   1.50     17.81      0.00     0.00\n“unserialize”               1.44     17.10      1.44    17.10\n“invokeJava”                1.26     14.96      0.00     0.00\n“callJStatic”               1.18     14.01      0.00     0.00\n“structure”                 0.84      9.98      0.40     4.75\n“writeBin”                  0.80      9.50      0.80     9.50\n“split.default”             0.68      8.08      0.08     0.95\n“split”                     0.68      8.08      0.00     0.00\n“as.factor”                 0.60      7.13      0.00     0.00\n“factor”                    0.60      7.13      0.00     0.00\n“as.character”              0.52      6.18      0.50     5.94\n“gc”                        0.44      5.23      0.44     5.23\n“mem_used”                  0.44      5.23      0.00     0.00\n“show_bytes”                0.44      5.23      0.00     0.00\n“object.size”               0.40      4.75      0.00     0.00\n“rawConnectionValue”        0.38      4.51      0.38     4.51\n“writeArgs”                 0.38      4.51      0.00     0.00\n“writeArray”                0.38      4.51      0.00     0.00\n“writeObject”               0.38      4.51      0.00     0.00\n“writeRaw”                  0.38      4.51      0.00     0.00\n“callJMethod”               0.08      0.95      0.00     0.00\n“unique.default”            0.06      0.71      0.06     0.71\n“match”                     0.06      0.71      0.04     0.48\n“unique”                    0.06      0.71      0.00     0.00\n“readBin”                   0.04      0.48      0.04     0.48\n“rawConnection”             0.04      0.48      0.00     0.00\n“readObject”                0.04      0.48      0.00     0.00\n“readRaw”                   0.04      0.48      0.00     0.00\n“readTypedObject”           0.04      0.48      0.00     0.00\n“as.character.factor”       0.02      0.24      0.02     0.24\n“pmatch”                    0.02      0.24      0.02     0.24\n“raw”                       0.02      0.24      0.02     0.24\n“unlist”                    0.02      0.24      0.02     0.24\n“deparse”                   0.02      0.24      0.00     0.00\n“.deparseOpts”              0.02      0.24      0.00     0.00\n“%in%”                      0.02      0.24      0.00     0.00\n“mode”                      0.02      0.24      0.00     0.00\n“setNames”                  0.02      0.24      0.00     0.00\n\n$sample.interval\n[1] 0.02\n\n$sampling.time\n[1] 8.42\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520198454739_-1348946811","id":"20180304-212054_994999628","dateCreated":"2018-03-04T21:20:54+0000","dateStarted":"2018-03-04T21:22:57+0000","dateFinished":"2018-03-04T21:22:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:684"},{"text":"%r\nuntrace(SparkR:::parallelize)\nuntrace(do.call)\ntrace(SparkR:::parallelize,'t0 = Sys.time();')\ntrace(do.call,'print(Sys.time());')\ntmp <- tempfile()\nRprof(tmp)\n\nn =10^2 \n\nemployee <- rep(\"ABC\",n)\n\nsalary <- runif(n, min=240000, max=5000000)\n\nstartdate <- seq(as.Date(\"2000/1/1\"), by = \"day\", length.out = n)\n\n#schemaPeople <- data.frame(employee, salary, startdate)\nschemaPeople <- data.frame(employee, salary)\nformat(object.size(schemaPeople),units=\"MB\")\n\nbigDF <- as.DataFrame(schemaPeople, numPartitions = 4)\n\n#--############################# \n# Your R code goes here… \n#--#############################\n\nRprof(NULL, line.profiling=TRUE)\n#profile <- as.data.frame(summaryRprof(tmp, basenames=2)$by.total)\nsummaryRprof(tmp, basenames=2, lines=\"show\")\nunlink(tmp) \n\n#result <- cbind(\"function\"=rownames(profile), profile)\n#print(t0)","user":"anonymous","dateUpdated":"2018-03-02T22:17:06+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n[1] “parallelize”\n[1] “do.call”\n[1] “0 Mb”\nTracing do.call(mapply, append(args, data)) on entry \nTracing parallelize(sc, data, numSlices = numToInt(numPartitions)) on entry \nTracing do.call(structType, fields) on entry \n\nError in summaryRprof(tmp, basenames = 2, lines = \"show\"): profile does not contain line information\n\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520007434869_1822982143","id":"20180302-161714_1572171016","dateCreated":"2018-03-02T16:17:14+0000","dateStarted":"2018-03-02T21:08:21+0000","dateFinished":"2018-03-02T21:08:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:685"},{"text":"%r\nn =10^5 * 2\n\nemployee <- rep(\"ABC\",n)\n\nsalary <- runif(n, min=240000, max=5000000)\n\nstartdate <- seq(as.Date(\"2000/1/1\"), by = \"day\", length.out = n)\n\n#schemaPeople <- data.frame(employee, salary, startdate)\nschemaPeople <- data.frame(employee, salary)\nformat(object.size(schemaPeople),units=\"MB\")\n\ndata <- schemaPeople\nschema <- NULL\n\n sparkSession <- SparkR:::getSparkSession()\n\ninfer_type <- function(x) {\n  if (is.null(x)) {\n    stop(\"can not infer type from NULL\")\n  }\n\n  type <- getInternalType(x)\n\n  if (type == \"map\") {\n    stopifnot(length(x) > 0)\n    key <- ls(x)[[1]]\n    paste0(\"map<string,\", infer_type(get(key, x)), \">\")\n  } else if (type == \"array\") {\n    stopifnot(length(x) > 0)\n\n    paste0(\"array<\", infer_type(x[[1]]), \">\")\n  } else if (type == \"struct\") {\n    stopifnot(length(x) > 0)\n    names <- names(x)\n    stopifnot(!is.null(names))\n\n    type <- lapply(seq_along(x), function(i) {\n      paste0(names[[i]], \":\", infer_type(x[[i]]), \",\")\n    })\n    type <- Reduce(paste0, type)\n    type <- paste0(\"struct<\", substr(type, 1, nchar(type) - 1), \">\")\n  } else if (length(x) > 1 && type != \"binary\") {\n    paste0(\"array<\", infer_type(x[[1]]), \">\")\n  } else {\n    type\n  }\n}\n\ngetInternalType <- function(x) {\n  # class of POSIXlt is c(\"POSIXlt\" \"POSIXt\")\n  switch(class(x)[[1]],\n         integer = \"integer\",\n         character = \"string\",\n         logical = \"boolean\",\n         double = \"double\",\n         numeric = \"double\",\n         raw = \"binary\",\n         list = \"array\",\n         struct = \"struct\",\n         environment = \"map\",\n         Date = \"date\",\n         POSIXlt = \"timestamp\",\n         POSIXct = \"timestamp\",\n         stop(paste(\"Unsupported type for SparkDataFrame:\", class(x))))\n}\n\n  if (is.data.frame(data)) {\n      # Convert data into a list of rows. Each row is a list.\nprint(Sys.time());\n      # get the names of columns, they will be put into RDD\n      if (is.null(schema)) {\n        schema <- names(data)\n      }\n\n      # get rid of factor type\n      cleanCols <- function(x) {\n        if (is.factor(x)) {\n          as.character(x)\n        } else {\n          x\n        }\n      }\nprint(Sys.time());\n      # drop factors and wrap lists\n      data <- setNames(lapply(data, cleanCols), NULL)\nprint(Sys.time());\n      # check if all columns have supported type\n      lapply(data, getInternalType)\nprint(Sys.time());\n      # convert to rows\n      args <- list(FUN = list, SIMPLIFY = FALSE, USE.NAMES = FALSE)\n      data <- do.call(mapply, append(args, data))\nprint(Sys.time());      \n  }\n\nif (is.list(data)) {\n    sc <- SparkR:::callJStatic(\"org.apache.spark.sql.api.r.SQLUtils\", \"getJavaSparkContext\", sparkSession)\n    print(\"here0\"); \n      rdd <- SparkR:::parallelize(sc, data, numSlices = 1)\n  } else if (inherits(data, \"RDD\")) {\n    rdd <- data\n  } else {\n    stop(paste(\"unexpected type:\", class(data)))\n}\n\n\nprint(Sys.time());     \nprint(\"here\");\n\n\nif (is.null(schema) || (!inherits(schema, \"structType\") && is.null(names(schema)))) {\n    row <- SparkR:::firstRDD(rdd)\n    names <- if (is.null(schema)) {\n      names(row)\n    } else {\n      as.list(schema)\n    }\n    if (is.null(names)) {\n      names <- lapply(1:length(row), function(x) {\n        paste(\"_\", as.character(x), sep = \"\")\n      })\n    }\nprint(\"here2\");\n  print(Sys.time());  \n    # SPAKR-SQL does not support '.' in column name, so replace it with '_'\n    # TODO(davies): remove this once SPARK-2775 is fixed\n    names <- lapply(names, function(n) {\n      nn <- gsub(\"[.]\", \"_\", n)\n      if (nn != n) {\n        warning(paste(\"Use\", nn, \"instead of\", n, \" as column name\"))\n      }\n      nn\n    })\nprint(\"here3\");\n  print(Sys.time());  \n    types <- lapply(row, infer_type)\nprint(\"here4\"); \n  print(Sys.time());  \n    fields <- lapply(1:length(row), function(i) {\n      structField(names[[i]], types[[i]], TRUE)\n    })\nprint(\"here5\"); \n     print(Sys.time());  \n    schema <- do.call(structType, fields)\n  }\n\n  stopifnot(class(schema) == \"structType\")\n  print(Sys.time());  \n  \n    jrdd <- SparkR:::getJRDD(lapply(rdd, function(x) x), \"row\")\n    print(\"here6\"); \n  print(Sys.time());      \n  srdd <- SparkR:::callJMethod(jrdd, \"rdd\")\n  print(\"here7\"); \n    print(Sys.time());  \n  sdf <- SparkR:::callJStatic(\"org.apache.spark.sql.api.r.SQLUtils\", \"createDF\",\n                     srdd, schema$jobj, sparkSession)\n    print(\"here8\");                  \n    print(Sys.time());  \ndataFrame(sdf)\n  print(Sys.time());  \n","user":"anonymous","dateUpdated":"2018-03-02T22:13:37+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n[1] “2.3 Mb”\n[1] “2018-03-02 22:13:37 UTC”\n[1] “2018-03-02 22:13:37 UTC”\n[1] “2018-03-02 22:13:37 UTC”\n[1] “2018-03-02 22:13:37 UTC”\n[1] “2018-03-02 22:13:38 UTC”\n[1] “here0”\n[1] “2018-03-02 22:13:38 UTC”\n[1] “here”\n\nError in handleErrors(returnStatus, conn): org.apache.spark.SparkException: Job 13 cancelled part of cancelled job group zeppelin-20180302-210929_194682957\n    at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n    at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)\n    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply$mcVI$sp(DAGScheduler.scala:788)\n    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:788)\n    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:788)\n    at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n    at org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:788)\n    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1625)\n    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n    at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n    at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)\n    at org.apache.spark.api.java.JavaRDDLike$class.collectPartitions(JavaRDDLike.scala:377)\n    at org.apache.spark.api.java.AbstractJavaRDDLike.collectPartitions(JavaRDDLike.scala:45)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.apache.spark.api.r.RBackendHandler.handleMethodCall(RBackendHandler.scala:167)\n    at org.apache.spark.api.r.RBackendHandler.channelRead0(RBackendHandler.scala:108)\n    at org.apache.spark.api.r.RBackendHandler.channelRead0(RBackendHandler.scala:40)\n    at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)\n    at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)\n    at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)\n    at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293)\n    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)\n    at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)\n    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)\n    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)\n    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)\n    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)\n    at java.lang.Thread.run(Thread.java:748)\n\n\nError: class(schema) == \"structType\" is not TRUE\n\n\n[1] “2018-03-02 22:17:00 UTC”\n\nError in SparkR:::getJRDD(lapply(rdd, function(x) x), \"row\"): error in evaluating the argument 'rdd' in selecting a method for function 'getJRDD': Error in as.list.default(X) : \n  no method for coercing this S4 class to a vector\nCalls: lapply -&gt; as.list -&gt; as.list.default\n\n\n[1] “here6”\n[1] “2018-03-02 22:17:00 UTC”\n\nError in stopifnot(class(objId) == \"jobj\"): object 'jrdd' not found\n\n\n[1] “here7”\n[1] “2018-03-02 22:17:00 UTC”\n\nError in invokeJava(isStatic = TRUE, className, methodName, ...): object 'srdd' not found\n\n\n[1] “here8”\n[1] “2018-03-02 22:17:00 UTC”\n\nError in eval(expr, envir, enclos): could not find function \"dataFrame\"\n\n\n[1] “2018-03-02 22:17:00 UTC”\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520024969763_163674590","id":"20180302-210929_194682957","dateCreated":"2018-03-02T21:09:29+0000","dateStarted":"2018-03-02T22:13:37+0000","dateFinished":"2018-03-02T22:17:00+0000","status":"ABORT","progressUpdateIntervalMs":500,"$$hashKey":"object:686"},{"text":"%r\ndata<-schemaPeople\nnames(data)","user":"anonymous","dateUpdated":"2018-03-02T22:00:28+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n[1] “employee” “salary”  \n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520027506651_-1390280245","id":"20180302-215146_2054511848","dateCreated":"2018-03-02T21:51:46+0000","dateStarted":"2018-03-02T22:00:28+0000","dateFinished":"2018-03-02T22:00:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:687"},{"text":"%r\n rdd <- SparkR:::toRDD(bigDF);\n print(Sys.time());   \n\nif (is.null(schema) || (!inherits(schema, \"structType\") && is.null(names(schema)))) {\n    row <- SparkR:::firstRDD(rdd)\n    names <- if (is.null(schema)) {\n      names(row)\n    } else {\n      as.list(schema)\n    }\n    if (is.null(names)) {\n      names <- lapply(1:length(row), function(x) {\n        paste(\"_\", as.character(x), sep = \"\")\n      })\n    }\n\n    # SPAKR-SQL does not support '.' in column name, so replace it with '_'\n    # TODO(davies): remove this once SPARK-2775 is fixed\n    names <- lapply(names, function(n) {\n      nn <- gsub(\"[.]\", \"_\", n)\n      if (nn != n) {\n        warning(paste(\"Use\", nn, \"instead of\", n, \" as column name\"))\n      }\n      nn\n    })\n\n    types <- lapply(row, infer_type)\n    fields <- lapply(1:length(row), function(i) {\n      structField(names[[i]], types[[i]], TRUE)\n    })\n     print(Sys.time());  \n    schema <- do.call(structType, fields)\n  }\n\n  stopifnot(class(schema) == \"structType\")\n  print(Sys.time());  \n  ","user":"anonymous","dateUpdated":"2018-03-02T21:37:48+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n[1] “2018-03-02 21:37:48 UTC”\n\nError in handleErrors(returnStatus, conn): org.apache.spark.SparkException: Job 19 cancelled part of cancelled job group zeppelin-20180302-205714_467715581\n    at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n    at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1375)\n    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply$mcVI$sp(DAGScheduler.scala:788)\n    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:788)\n    at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:788)\n    at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n    at org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:788)\n    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1625)\n    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n    at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n    at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n    at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)\n    at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)\n    at org.apache.spark.api.java.JavaRDDLike$class.collectPartitions(JavaRDDLike.scala:377)\n    at org.apache.spark.api.java.AbstractJavaRDDLike.collectPartitions(JavaRDDLike.scala:45)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.apache.spark.api.r.RBackendHandler.handleMethodCall(RBackendHandler.scala:167)\n    at org.apache.spark.api.r.RBackendHandler.channelRead0(RBackendHandler.scala:108)\n    at org.apache.spark.api.r.RBackendHandler.channelRead0(RBackendHandler.scala:40)\n    at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)\n    at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:266)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)\n    at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)\n    at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293)\n    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)\n    at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)\n    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)\n    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)\n    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)\n    at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)\n    at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)\n    at java.lang.Thread.run(Thread.java:748)\n\n\nError: class(schema) == \"structType\" is not TRUE\n\n\n[1] “2018-03-02 21:39:03 UTC”\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520024234583_33973172","id":"20180302-205714_467715581","dateCreated":"2018-03-02T20:57:14+0000","dateStarted":"2018-03-02T21:37:48+0000","dateFinished":"2018-03-02T21:39:03+0000","status":"ABORT","progressUpdateIntervalMs":500,"$$hashKey":"object:688"},{"text":"%r\nresult","user":"anonymous","dateUpdated":"2018-03-02T19:39:58+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"\n                                       function total.time total.pct\n\n\n“”                         “”      58.44    100.00\n“eval”                                       “eval”      58.44    100.00\n“block_exec”                           “block_exec”      58.44    100.00\n“call_block”                           “call_block”      58.44    100.00\n“doTryCatch”                           “doTryCatch”      58.44    100.00\n“evaluate”                               “evaluate”      58.44    100.00\n“in_dir”                                   “in_dir”      58.44    100.00\n“knit”                                       “knit”      58.44    100.00\n“knit2html”                             “knit2html”      58.44    100.00\n“process_file”                       “process_file”      58.44    100.00\n“process_group”                     “process_group”      58.44    100.00\n“process_group.block”         “process_group.block”      58.44    100.00\n“tryCatch”                               “tryCatch”      58.44    100.00\n“tryCatchList”                       “tryCatchList”      58.44    100.00\n“tryCatchOne”                         “tryCatchOne”      58.44    100.00\n“withCallingHandlers”         “withCallingHandlers”      58.44    100.00\n“evaluate_call”                     “evaluate_call”      58.42     99.97\n“handle”                                   “handle”      58.40     99.93\n“timing_fn”                             “timing_fn”      58.40     99.93\n“try”                                         “try”      58.40     99.93\n“withVisible”                         “withVisible”      58.40     99.93\n“as.DataFrame”                       “as.DataFrame”      54.80     93.77\n“createDataFrame”                 “createDataFrame”      54.80     93.77\n“dispatchFunc”                       “dispatchFunc”      54.80     93.77\n“f”                                             “f”      54.80     93.77\n“parallelize”                         “parallelize”      28.00     47.91\n“do.call”                                 “do.call”      26.48     45.31\n“factor”                                   “factor”      11.58     19.82\n“split.default”                     “split.default”      11.20     19.16\n“split”                                     “split”      11.20     19.16\n“as.factor”                             “as.factor”      10.50     17.97\n“FUN”                                         “FUN”      10.28     17.59\n“lapply”                                   “lapply”      10.28     17.59\n“standardGeneric”                 “standardGeneric”      10.24     17.52\n“as.character”                       “as.character”       9.54     16.32\n“structure”                             “structure”       6.38     10.92\n“object.size”                         “object.size”       6.38     10.92\n“unique.default”                   “unique.default”       1.20      2.05\n“unique”                                   “unique”       1.20      2.05\n“as.data.frame”                     “as.data.frame”       1.08      1.85\n“as.data.frame.character” “as.data.frame.character”       1.08      1.85\n“data.frame”                           “data.frame”       1.08      1.85\n“match”                                     “match”       1.06      1.81\n“runif”                                     “runif”       0.64      1.10\n“writeBin”                               “writeBin”       0.38      0.65\n“writeToTempFile”                 “writeToTempFile”       0.36      0.62\n“as.character.factor”         “as.character.factor”       0.28      0.48\n“setNames”                               “setNames”       0.28      0.48\n“unlist”                                   “unlist”       0.12      0.21\n“seq.int”                                 “seq.int”       0.06      0.10\n“seq”                                         “seq”       0.06      0.10\n“seq.Date”                               “seq.Date”       0.06      0.10\n“callJStatic”                         “callJStatic”       0.04      0.07\n“invokeJava”                           “invokeJava”       0.04      0.07\n“removeJObject”                     “removeJObject”       0.04      0.07\n“sapply”                                   “sapply”       0.04      0.07\n“[[.data.frame”                     “[[.data.frame”       0.02      0.03\n“deparse”                                 “deparse”       0.02      0.03\n“exists”                                   “exists”       0.02      0.03\n“file.remove”                         “file.remove”       0.02      0.03\n“[[”                                           “[[”       0.02      0.03\n“\\(”                                             “\\)”       0.02      0.03\n“\\(.data.frame”                       “\\).data.frame”       0.02      0.03\n“dev.cur”                                 “dev.cur”       0.02      0.03\n“handle_output”                     “handle_output”       0.02      0.03\n“identical”                             “identical”       0.02      0.03\n“rawConnection”                     “rawConnection”       0.02      0.03\n“writeInt”                               “writeInt”       0.02      0.03\n                          self.time self.pct\n“”                 26.48    45.31\n“eval”                         1.82     3.11\n“block_exec”                   0.00     0.00\n“call_block”                   0.00     0.00\n“doTryCatch”                   0.00     0.00\n“evaluate”                     0.00     0.00\n“in_dir”                       0.00     0.00\n“knit”                         0.00     0.00\n“knit2html”                    0.00     0.00\n“process_file”                 0.00     0.00\n“process_group”                0.00     0.00\n“process_group.block”          0.00     0.00\n“tryCatch”                     0.00     0.00\n“tryCatchList”                 0.00     0.00\n“tryCatchOne”                  0.00     0.00\n“withCallingHandlers”          0.00     0.00\n“evaluate_call”                0.00     0.00\n“handle”                       0.00     0.00\n“timing_fn”                    0.00     0.00\n“try”                          0.00     0.00\n“withVisible”                  0.00     0.00\n“as.DataFrame”                 0.00     0.00\n“createDataFrame”              0.00     0.00\n“dispatchFunc”                 0.00     0.00\n“f”                            0.00     0.00\n“parallelize”                  0.00     0.00\n“do.call”                      0.00     0.00\n“factor”                       0.06     0.10\n“split.default”                0.70     1.20\n“split”                        0.00     0.00\n“as.factor”                    0.00     0.00\n“FUN”                          9.96    17.04\n“lapply”                       0.00     0.00\n“standardGeneric”              0.00     0.00\n“as.character”                 9.26    15.85\n“structure”                    6.38    10.92\n“object.size”                  0.00     0.00\n“unique.default”               1.20     2.05\n“unique”                       0.00     0.00\n“as.data.frame”                0.00     0.00\n“as.data.frame.character”      0.00     0.00\n“data.frame”                   0.00     0.00\n“match”                        1.06     1.81\n“runif”                        0.64     1.10\n“writeBin”                     0.38     0.65\n“writeToTempFile”              0.00     0.00\n“as.character.factor”          0.28     0.48\n“setNames”                     0.00     0.00\n“unlist”                       0.08     0.14\n“seq.int”                      0.06     0.10\n“seq”                          0.00     0.00\n“seq.Date”                     0.00     0.00\n“callJStatic”                  0.00     0.00\n“invokeJava”                   0.00     0.00\n“removeJObject”                0.00     0.00\n“sapply”                       0.00     0.00\n“[[.data.frame”                0.02     0.03\n“deparse”                      0.02     0.03\n“exists”                       0.02     0.03\n“file.remove”                  0.02     0.03\n“[[”                           0.00     0.00\n“\\(”                            0.00     0.00\n“\\).data.frame”                 0.00     0.00\n“dev.cur”                      0.00     0.00\n“handle_output”                0.00     0.00\n“identical”                    0.00     0.00\n“rawConnection”                0.00     0.00\n“writeInt”                     0.00     0.00\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520013610781_-225750507","id":"20180302-180010_1307080769","dateCreated":"2018-03-02T18:00:10+0000","dateStarted":"2018-03-02T19:39:58+0000","dateFinished":"2018-03-02T19:40:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:689"},{"text":"%r\n","user":"anonymous","dateUpdated":"2018-03-02T19:50:55+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1520020255048_721234351","id":"20180302-195055_799198899","dateCreated":"2018-03-02T19:50:55+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:690"},{"text":"%r\ntrace(sum)\nhist(rnorm(100)) # shows about 3-4 calls to sum()\nuntrace(sum)","user":"anonymous","dateUpdated":"2018-03-02T19:56:08+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>trace: sum\ntrace: sum\ntrace: sum\ntrace: sum\ntrace: sum\ntrace: sum\n<img src=\"data:image/png;base64,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\" alt=\"plot of chunk unnamed-chunk-1\" width=\"100%\">trace: sum\ntrace: sum\ntrace: sum</p>"}]},"apps":[],"jobName":"paragraph_1520020563551_2134292823","id":"20180302-195603_2090998552","dateCreated":"2018-03-02T19:56:03+0000","dateStarted":"2018-03-02T19:56:08+0000","dateFinished":"2018-03-02T19:56:09+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:691"},{"text":"%r\nprint(as.list(body(f)))","user":"anonymous","dateUpdated":"2018-03-02T18:11:27+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"r"},"editorMode":"ace/mode/r"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"\n<pre><code>Error in body(f): object 'f' not found\n</code></pre>\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1520014195352_1829793179","id":"20180302-180955_1104229493","dateCreated":"2018-03-02T18:09:55+0000","dateStarted":"2018-03-02T18:11:27+0000","dateFinished":"2018-03-02T18:11:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:692"},{"title":"SparkSQL querying R data","text":"%sql\nselect * from iris\n\n","user":"anonymous","dateUpdated":"2018-03-02T16:08:55+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"scatterChart","height":300,"optionOpen":false,"setting":{"scatterChart":{"xAxis":{"name":"Sepal_Length","index":0,"aggr":"sum"},"yAxis":{"name":"Sepal_Width","index":1,"aggr":"sum"},"group":{"name":"Species","index":4,"aggr":"sum"}}}},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"Sepal_Length\tSepal_Width\tPetal_Length\tPetal_Width\tSpecies\n5.1\t3.5\t1.4\t0.2\tsetosa\n4.9\t3.0\t1.4\t0.2\tsetosa\n4.7\t3.2\t1.3\t0.2\tsetosa\n4.6\t3.1\t1.5\t0.2\tsetosa\n5.0\t3.6\t1.4\t0.2\tsetosa\n5.4\t3.9\t1.7\t0.4\tsetosa\n4.6\t3.4\t1.4\t0.3\tsetosa\n5.0\t3.4\t1.5\t0.2\tsetosa\n4.4\t2.9\t1.4\t0.2\tsetosa\n4.9\t3.1\t1.5\t0.1\tsetosa\n5.4\t3.7\t1.5\t0.2\tsetosa\n4.8\t3.4\t1.6\t0.2\tsetosa\n4.8\t3.0\t1.4\t0.1\tsetosa\n4.3\t3.0\t1.1\t0.1\tsetosa\n5.8\t4.0\t1.2\t0.2\tsetosa\n5.7\t4.4\t1.5\t0.4\tsetosa\n5.4\t3.9\t1.3\t0.4\tsetosa\n5.1\t3.5\t1.4\t0.3\tsetosa\n5.7\t3.8\t1.7\t0.3\tsetosa\n5.1\t3.8\t1.5\t0.3\tsetosa\n5.4\t3.4\t1.7\t0.2\tsetosa\n5.1\t3.7\t1.5\t0.4\tsetosa\n4.6\t3.6\t1.0\t0.2\tsetosa\n5.1\t3.3\t1.7\t0.5\tsetosa\n4.8\t3.4\t1.9\t0.2\tsetosa\n5.0\t3.0\t1.6\t0.2\tsetosa\n5.0\t3.4\t1.6\t0.4\tsetosa\n5.2\t3.5\t1.5\t0.2\tsetosa\n5.2\t3.4\t1.4\t0.2\tsetosa\n4.7\t3.2\t1.6\t0.2\tsetosa\n4.8\t3.1\t1.6\t0.2\tsetosa\n5.4\t3.4\t1.5\t0.4\tsetosa\n5.2\t4.1\t1.5\t0.1\tsetosa\n5.5\t4.2\t1.4\t0.2\tsetosa\n4.9\t3.1\t1.5\t0.2\tsetosa\n5.0\t3.2\t1.2\t0.2\tsetosa\n5.5\t3.5\t1.3\t0.2\tsetosa\n4.9\t3.6\t1.4\t0.1\tsetosa\n4.4\t3.0\t1.3\t0.2\tsetosa\n5.1\t3.4\t1.5\t0.2\tsetosa\n5.0\t3.5\t1.3\t0.3\tsetosa\n4.5\t2.3\t1.3\t0.3\tsetosa\n4.4\t3.2\t1.3\t0.2\tsetosa\n5.0\t3.5\t1.6\t0.6\tsetosa\n5.1\t3.8\t1.9\t0.4\tsetosa\n4.8\t3.0\t1.4\t0.3\tsetosa\n5.1\t3.8\t1.6\t0.2\tsetosa\n4.6\t3.2\t1.4\t0.2\tsetosa\n5.3\t3.7\t1.5\t0.2\tsetosa\n5.0\t3.3\t1.4\t0.2\tsetosa\n7.0\t3.2\t4.7\t1.4\tversicolor\n6.4\t3.2\t4.5\t1.5\tversicolor\n6.9\t3.1\t4.9\t1.5\tversicolor\n5.5\t2.3\t4.0\t1.3\tversicolor\n6.5\t2.8\t4.6\t1.5\tversicolor\n5.7\t2.8\t4.5\t1.3\tversicolor\n6.3\t3.3\t4.7\t1.6\tversicolor\n4.9\t2.4\t3.3\t1.0\tversicolor\n6.6\t2.9\t4.6\t1.3\tversicolor\n5.2\t2.7\t3.9\t1.4\tversicolor\n5.0\t2.0\t3.5\t1.0\tversicolor\n5.9\t3.0\t4.2\t1.5\tversicolor\n6.0\t2.2\t4.0\t1.0\tversicolor\n6.1\t2.9\t4.7\t1.4\tversicolor\n5.6\t2.9\t3.6\t1.3\tversicolor\n6.7\t3.1\t4.4\t1.4\tversicolor\n5.6\t3.0\t4.5\t1.5\tversicolor\n5.8\t2.7\t4.1\t1.0\tversicolor\n6.2\t2.2\t4.5\t1.5\tversicolor\n5.6\t2.5\t3.9\t1.1\tversicolor\n5.9\t3.2\t4.8\t1.8\tversicolor\n6.1\t2.8\t4.0\t1.3\tversicolor\n6.3\t2.5\t4.9\t1.5\tversicolor\n6.1\t2.8\t4.7\t1.2\tversicolor\n6.4\t2.9\t4.3\t1.3\tversicolor\n6.6\t3.0\t4.4\t1.4\tversicolor\n6.8\t2.8\t4.8\t1.4\tversicolor\n6.7\t3.0\t5.0\t1.7\tversicolor\n6.0\t2.9\t4.5\t1.5\tversicolor\n5.7\t2.6\t3.5\t1.0\tversicolor\n5.5\t2.4\t3.8\t1.1\tversicolor\n5.5\t2.4\t3.7\t1.0\tversicolor\n5.8\t2.7\t3.9\t1.2\tversicolor\n6.0\t2.7\t5.1\t1.6\tversicolor\n5.4\t3.0\t4.5\t1.5\tversicolor\n6.0\t3.4\t4.5\t1.6\tversicolor\n6.7\t3.1\t4.7\t1.5\tversicolor\n6.3\t2.3\t4.4\t1.3\tversicolor\n5.6\t3.0\t4.1\t1.3\tversicolor\n5.5\t2.5\t4.0\t1.3\tversicolor\n5.5\t2.6\t4.4\t1.2\tversicolor\n6.1\t3.0\t4.6\t1.4\tversicolor\n5.8\t2.6\t4.0\t1.2\tversicolor\n5.0\t2.3\t3.3\t1.0\tversicolor\n5.6\t2.7\t4.2\t1.3\tversicolor\n5.7\t3.0\t4.2\t1.2\tversicolor\n5.7\t2.9\t4.2\t1.3\tversicolor\n6.2\t2.9\t4.3\t1.3\tversicolor\n5.1\t2.5\t3.0\t1.1\tversicolor\n5.7\t2.8\t4.1\t1.3\tversicolor\n6.3\t3.3\t6.0\t2.5\tvirginica\n5.8\t2.7\t5.1\t1.9\tvirginica\n7.1\t3.0\t5.9\t2.1\tvirginica\n6.3\t2.9\t5.6\t1.8\tvirginica\n6.5\t3.0\t5.8\t2.2\tvirginica\n7.6\t3.0\t6.6\t2.1\tvirginica\n4.9\t2.5\t4.5\t1.7\tvirginica\n7.3\t2.9\t6.3\t1.8\tvirginica\n6.7\t2.5\t5.8\t1.8\tvirginica\n7.2\t3.6\t6.1\t2.5\tvirginica\n6.5\t3.2\t5.1\t2.0\tvirginica\n6.4\t2.7\t5.3\t1.9\tvirginica\n6.8\t3.0\t5.5\t2.1\tvirginica\n5.7\t2.5\t5.0\t2.0\tvirginica\n5.8\t2.8\t5.1\t2.4\tvirginica\n6.4\t3.2\t5.3\t2.3\tvirginica\n6.5\t3.0\t5.5\t1.8\tvirginica\n7.7\t3.8\t6.7\t2.2\tvirginica\n7.7\t2.6\t6.9\t2.3\tvirginica\n6.0\t2.2\t5.0\t1.5\tvirginica\n6.9\t3.2\t5.7\t2.3\tvirginica\n5.6\t2.8\t4.9\t2.0\tvirginica\n7.7\t2.8\t6.7\t2.0\tvirginica\n6.3\t2.7\t4.9\t1.8\tvirginica\n6.7\t3.3\t5.7\t2.1\tvirginica\n7.2\t3.2\t6.0\t1.8\tvirginica\n6.2\t2.8\t4.8\t1.8\tvirginica\n6.1\t3.0\t4.9\t1.8\tvirginica\n6.4\t2.8\t5.6\t2.1\tvirginica\n7.2\t3.0\t5.8\t1.6\tvirginica\n7.4\t2.8\t6.1\t1.9\tvirginica\n7.9\t3.8\t6.4\t2.0\tvirginica\n6.4\t2.8\t5.6\t2.2\tvirginica\n6.3\t2.8\t5.1\t1.5\tvirginica\n6.1\t2.6\t5.6\t1.4\tvirginica\n7.7\t3.0\t6.1\t2.3\tvirginica\n6.3\t3.4\t5.6\t2.4\tvirginica\n6.4\t3.1\t5.5\t1.8\tvirginica\n6.0\t3.0\t4.8\t1.8\tvirginica\n6.9\t3.1\t5.4\t2.1\tvirginica\n6.7\t3.1\t5.6\t2.4\tvirginica\n6.9\t3.1\t5.1\t2.3\tvirginica\n5.8\t2.7\t5.1\t1.9\tvirginica\n6.8\t3.2\t5.9\t2.3\tvirginica\n6.7\t3.3\t5.7\t2.5\tvirginica\n6.7\t3.0\t5.2\t2.3\tvirginica\n6.3\t2.5\t5.0\t1.9\tvirginica\n6.5\t3.0\t5.2\t2.0\tvirginica\n6.2\t3.4\t5.4\t2.3\tvirginica\n5.9\t3.0\t5.1\t1.8\tvirginica\n"}]},"apps":[],"jobName":"paragraph_1517497663204_1204041904","id":"20170810-002439_1141063356","dateCreated":"2018-02-01T15:07:43+0000","dateStarted":"2018-03-02T16:08:55+0000","dateFinished":"2018-03-02T16:08:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:693"},{"text":"%md\n# Machine Learning with R and Spark\n\nThis example shows running a Spark machine learning algorithm - Generalized Linear Model (glm).\n\nWe will use our citibike data and model tripduration based on age and gender.\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Machine Learning with R and Spark</h1>\n<p>This example shows running a Spark machine learning algorithm - Generalized Linear Model (glm).</p>\n<p>We will use our citibike data and model tripduration based on age and gender.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1517497663205_1203657155","id":"20170810-004712_451598661","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:694"},{"title":"SparkR code to build generalized linear model (GLM) of tripduration based on gender and age","text":"%r\nageGender  <- sql(\"SELECT tripduration, (2016-birthyear) age, gender from bike_trips\")\ntraining <- dropna(ageGender)\n\nmodel <- glm(tripduration ~ age + gender,\n    family = \"gaussian\", data = training)\nsummary(model)","dateUpdated":"2018-02-01T15:07:43+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517497663205_1203657155","id":"20170810-004706_1398119785","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:695"},{"title":"Check our predictions (not so good)","text":"%r\nfitted <- predict(model, training)\nregisterTempTable(fitted,\"fitted\")\ncompare <- sql(\"select prediction, tripduration, age, gender from fitted\")\nhead(compare)\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"editorSetting":{"language":"r"},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517497663205_1203657155","id":"20170810-010230_308509598","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:696"},{"title":"SparkSQL to view predictions","text":"%sql\nselect prediction, tripduration, gender, age from fitted\nlimit 100\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":true,"setting":{"lineChart":{},"scatterChart":{"xAxis":{"name":"prediction","index":0,"aggr":"sum"},"yAxis":{"name":"tripduration","index":1,"aggr":"sum"},"group":{"name":"gender","index":2,"aggr":"sum"}},"stackedAreaChart":{}},"keys":[],"groups":[],"values":[{"name":"tripduration","index":1,"aggr":"sum"},{"name":"prediction","index":0,"aggr":"sum"}],"commonSetting":{}},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517497663205_1203657155","id":"20170808-202112_1798282605","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:697"},{"text":"%md\n# Example of writing a DataFrame back to Object Store\n\nThe follow shows an example of writing a DataFrame back to the Object Store.  We use the write.df method from SparkR.  It supports multiple source types (csv, json, parquet, etc).","dateUpdated":"2018-02-01T15:07:43+0000","config":{"editorSetting":{"language":"text","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/text","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Example of writing a DataFrame back to Object Store</h1>\n<p>The follow shows an example of writing a DataFrame back to the Object Store. We use the write.df method from SparkR. It supports multiple source types (csv, json, parquet, etc).</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1517497663206_1204811402","id":"20170811-191501_1517148443","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:698"},{"title":"R code to write our predictions back to the Object Store","text":"%r\n# Since we know the resulting file is small, we will do a repartition command to force Spark to write the output as a single file.  This is an optional step.\nfitted_singlepartition <- repartition(fitted,1)\nwrite.df(fitted_singlepartition, \"swift://journeyC.default/citibike/results/201612-fitted-projections\", source=\"csv\", mode=\"overwrite\")\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517497663206_1204811402","id":"20170811-190712_164268436","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:699"},{"title":"Explore the contents of the Object Store","text":"%sh\n# this command will show you the contents of the Object Store that were just written\nhadoop fs -ls swift://journeyC.default/citibike/results/201612-fitted-projections\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":"false"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517497663206_1204811402","id":"20170807-214237_845297194","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:700"},{"text":"%md\n### Change Log\nNovember 16, 2017 - Confirmed it works with 17.4.1\nSeptember 12, 2017 - Confirmed it works with 17.3.5\nAugust 13, 2017 - Confirmed it works with BDCSCE 17.3.3-20\nAugust 11, 2017 - First version\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Change Log</h3>\n<p>November 16, 2017 - Confirmed it works with 17.4.1<br/>September 12, 2017 - Confirmed it works with 17.3.5<br/>August 13, 2017 - Confirmed it works with BDCSCE 17.3.3-20<br/>August 11, 2017 - First version</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1517497663207_1204426653","id":"20170811-191623_826620851","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:701"},{"text":"%md\n","dateUpdated":"2018-02-01T15:07:43+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":"true"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1517497663207_1204426653","id":"20170811-191958_1291497317","dateCreated":"2018-02-01T15:07:43+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:702"}],"name":"SparkR memory debugging","id":"2D7Q6GFB7","angularObjects":{"2D7AG6DRJ:shared_process":[],"2D5F2RENJ:shared_process":[],"2D4A2Y22C:shared_process":[],"2D7MAKX2Q:shared_process":[],"2D7YC4S1W:shared_process":[],"2D5PGP84N:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2D72FH4V7:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}