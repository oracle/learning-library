{"paragraphs":[{"text":"%md\n# DataSci Tutorial 2: Using R with Zeppelin\n\nThis tutorial was built for BDCS-CE version 17.3.5-20 as part of the Data Science Acceleration User Journey: <a href=\"https://oracle.github.io/learning-library/workshops/journey3-data-science/\" target=\"_blank\">here</a>.  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\n    Be sure you previously ran the Tutorial \"Setup R, SparkR, RStudio Server\".\n\nThis tutorial provides some examples of using R and SparkR in Zeppelin notebooks.  It will show:\n\n+ How to query a hive table from R\n+ How to read data directly from the Object Store\n+ How to convert a R data.frame into a Spark Temporary Table and query it with SparkSQL\n+ Machine Learning with R and Spark\n+ Save results back to the Object Store\n\n","dateUpdated":"2017-09-11T18:41:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>DataSci Tutorial 2: Using R with Zeppelin</h1>\n<p>This tutorial was built for BDCS-CE version 17.3.5-20 as part of the Data Science Acceleration User Journey: <a href=\"https://oracle.github.io/learning-library/workshops/journey3-data-science/\" target=\"_blank\">here</a>. Questions and feedback about the tutorial: <a href=\"mailto:&#100;&#97;&#x76;i&#x64;&#46;b&#x61;&#x79;&#97;&#x72;&#x64;&#64;&#111;&#x72;a&#99;&#108;&#x65;&#x2e;&#x63;&#x6f;&#109;\">&#100;&#97;&#x76;i&#x64;&#46;b&#x61;&#x79;&#97;&#x72;&#x64;&#64;&#111;&#x72;a&#99;&#108;&#x65;&#x2e;&#x63;&#x6f;&#109;</a></p>\n<pre><code>Be sure you previously ran the Tutorial &quot;Setup R, SparkR, RStudio Server&quot;.\n</code></pre>\n<p>This tutorial provides some examples of using R and SparkR in Zeppelin notebooks. It will show:</p>\n<ul>\n  <li>How to query a hive table from R</li>\n  <li>How to read data directly from the Object Store</li>\n  <li>How to convert a R data.frame into a Spark Temporary Table and query it with SparkSQL</li>\n  <li>Machine Learning with R and Spark</li>\n  <li>Save results back to the Object Store</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646600401_887340396","id":"20170811-183847_958683840","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:488","user":"anonymous","dateFinished":"2017-09-11T18:41:13+0000","dateStarted":"2017-09-11T18:41:13+0000"},{"text":"%md\n# About R and Zeppelin\n\nZeppelin includes an interpreter that is integrated with R and SparkR.  You can find some details about Zeppelin and R <a href=\"https://zeppelin.apache.org/docs/0.7.0/interpreter/r.html\" target=\"_blank\">here</a>.  You can find some details about SparkR <a href=\"https://spark.apache.org/docs/2.1.0/sparkr.html\" target=\"_blank\">here</a>.\n\nThese examples focuses on using R to work with Spark features like DataFrames.  As the SparkR documentation writes, \"A SparkDataFrame is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R, but with richer optimizations under the hood. SparkDataFrames can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing local R data frames\".  This tutorial will demonstrate some of these capabilities.\n\n\n\n","dateUpdated":"2017-09-05T21:23:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>About R and Zeppelin</h1>\n<p>Zeppelin includes an interpreter that is integrated with R and SparkR. You can find some details about Zeppelin and R <a href=\"https://zeppelin.apache.org/docs/0.7.0/interpreter/r.html\" target=\"_blank\">here</a>. You can find some details about SparkR <a href=\"https://spark.apache.org/docs/2.1.0/sparkr.html\" target=\"_blank\">here</a>.</p>\n<p>These examples focuses on using R to work with Spark features like DataFrames. As the SparkR documentation writes, &ldquo;A SparkDataFrame is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R, but with richer optimizations under the hood. SparkDataFrames can be constructed from a wide array of sources such as: structured data files, tables in Hive, external databases, or existing local R data frames&rdquo;. This tutorial will demonstrate some of these capabilities.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646600403_888109894","id":"20170807-213713_1708624789","dateCreated":"2017-09-05T21:23:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:489"},{"text":"%md\n# Example of R querying Hive\n\nThis example shows how to use R to query the bike_trips hive table via SparkR features.\n","dateUpdated":"2017-09-05T21:23:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Example of R querying Hive</h1>\n<p>This example shows how to use R to query the bike_trips hive table via SparkR features.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646600404_886186149","id":"20170810-001234_1882189757","dateCreated":"2017-09-05T21:23:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:490"},{"title":"SparkR to query a Hive table","text":"%r\nresults <- sql(\"SELECT * from bike_trips\")\nhead(results)\n","dateUpdated":"2017-09-11T18:41:28+0000","config":{"tableHide":false,"editorSetting":{"language":"r","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/r","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600405_885801400","id":"20170810-001354_1251372462","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:491","user":"anonymous","dateFinished":"2017-09-11T18:41:25+0000","dateStarted":"2017-09-11T18:41:19+0000"},{"text":"%r\n# let's see what kind of class our results are...\nresults\n# It is a SparkDataFrame","dateUpdated":"2017-09-11T18:41:38+0000","config":{"colWidth":12,"editorMode":"ace/mode/r","results":{},"enabled":true,"editorSetting":{"language":"r"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600406_886955647","id":"20170811-185109_995138400","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:492","user":"anonymous","dateFinished":"2017-09-11T18:41:38+0000","dateStarted":"2017-09-11T18:41:38+0000"},{"text":"%md\n# Example of reading a CSV from Object Store\n\nThis example shows SparkR features to read a CSV from Object Store via Spark's DataSources mechanisms\n\n\n","dateUpdated":"2017-09-05T21:23:20+0000","config":{"editorSetting":{"language":"text","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/text","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Example of reading a CSV from Object Store</h1>\n<p>This example shows SparkR features to read a CSV from Object Store via Spark&rsquo;s DataSources mechanisms</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646600407_886570898","id":"20170810-001731_1366310690","dateCreated":"2017-09-05T21:23:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:493"},{"text":"%r\nbiketrips <- read.df(\"swift://journeyC.default/citibike/raw/201612-citibike-tripdata.csv\", \"csv\", header = \"true\", inferSchema = \"true\", na.strings = \"NA\")\nhead(biketrips)\n","dateUpdated":"2017-09-11T18:41:46+0000","config":{"colWidth":12,"editorMode":"ace/mode/r","results":{},"enabled":true,"editorSetting":{"language":"r","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600408_884647154","id":"20170810-001850_158683843","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:494","user":"anonymous","dateFinished":"2017-09-11T18:42:01+0000","dateStarted":"2017-09-11T18:41:46+0000"},{"text":"%md\n# Example of making a R dataframe into a SparkSQL table\n\nHere is an example of converting a R data.frame into a Spark DataFrame and registering it as a Spark SQL table.  You can more examples like this <a href=\"https://rpubs.com/wendyu/sparkr\" target=\"_blank\">here</a>.\n","dateUpdated":"2017-09-05T21:23:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Example of making a R dataframe into a SparkSQL table</h1>\n<p>Here is an example of converting a R data.frame into a Spark DataFrame and registering it as a Spark SQL table. You can more examples like this <a href=\"https://rpubs.com/wendyu/sparkr\" target=\"_blank\">here</a>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646600409_884262405","id":"20170810-002107_611682017","dateCreated":"2017-09-05T21:23:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:495"},{"title":"Load an R data frame","text":"%r\ndata(iris)\niris","dateUpdated":"2017-09-11T18:42:20+0000","config":{"editorSetting":{"language":"r"},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600410_885416651","id":"20170808-174600_955896680","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:496","user":"anonymous","dateFinished":"2017-09-11T18:42:20+0000","dateStarted":"2017-09-11T18:42:20+0000"},{"title":"SparkR code to register an R dataframe as a SparkSQL table","text":"%r\nirisDF <- as.DataFrame(iris)\nregisterTempTable(irisDF,\"iris\")\nirisDF\n","dateUpdated":"2017-09-11T18:42:28+0000","config":{"editorSetting":{"language":"r"},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600410_885416651","id":"20170808-185507_1332635419","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:497","user":"anonymous","dateFinished":"2017-09-11T18:42:29+0000","dateStarted":"2017-09-11T18:42:28+0000"},{"title":"SparkSQL querying R data","text":"%sql\nselect * from iris\n\n","dateUpdated":"2017-09-11T18:42:52+0000","config":{"editorSetting":{"language":"sql"},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"scatterChart","height":300,"optionOpen":false,"setting":{"scatterChart":{"xAxis":{"name":"Sepal_Length","index":0,"aggr":"sum"},"yAxis":{"name":"Sepal_Width","index":1,"aggr":"sum"},"group":{"name":"Species","index":4,"aggr":"sum"}}}},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600411_885031903","id":"20170810-002439_1141063356","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:498","user":"anonymous","dateFinished":"2017-09-11T18:42:55+0000","dateStarted":"2017-09-11T18:42:52+0000"},{"text":"%md\n# Machine Learning with R and Spark\n\nThis example shows running a Spark machine learning algorithm - Generalized Linear Model (glm).\n\nWe will use our citibike data and model tripduration based on age and gender.\n","dateUpdated":"2017-09-05T21:23:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Machine Learning with R and Spark</h1>\n<p>This example shows running a Spark machine learning algorithm - Generalized Linear Model (glm).</p>\n<p>We will use our citibike data and model tripduration based on age and gender.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646600411_885031903","id":"20170810-004712_451598661","dateCreated":"2017-09-05T21:23:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:499"},{"title":"SparkR code to build generalized linear model (GLM) of tripduration based on gender and age","text":"%r\nageGender  <- sql(\"SELECT tripduration, (2016-birthyear) age, gender from bike_trips\")\ntraining <- dropna(ageGender)\n\nmodel <- glm(tripduration ~ age + gender,\n    family = \"gaussian\", data = training)\nsummary(model)","dateUpdated":"2017-09-11T18:43:03+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600412_883108158","id":"20170810-004706_1398119785","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:500","user":"anonymous","dateFinished":"2017-09-11T18:43:45+0000","dateStarted":"2017-09-11T18:43:04+0000"},{"title":"Check our predictions (not so good)","text":"%r\nfitted <- predict(model, training)\nregisterTempTable(fitted,\"fitted\")\ncompare <- sql(\"select prediction, tripduration, age, gender from fitted\")\nhead(compare)\n","dateUpdated":"2017-09-11T18:44:46+0000","config":{"editorSetting":{"language":"r"},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600412_883108158","id":"20170810-010230_308509598","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:501","user":"anonymous","dateFinished":"2017-09-11T18:44:46+0000","dateStarted":"2017-09-11T18:44:46+0000"},{"title":"SparkSQL to view predictions","text":"%sql\nselect prediction, tripduration, gender, age from fitted\nlimit 100\n","dateUpdated":"2017-09-05T21:23:20+0000","config":{"editorSetting":{"language":"sql","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/sql","title":true,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":true,"setting":{"lineChart":{},"scatterChart":{"xAxis":{"name":"prediction","index":0,"aggr":"sum"},"yAxis":{"name":"tripduration","index":1,"aggr":"sum"},"group":{"name":"gender","index":2,"aggr":"sum"}},"stackedAreaChart":{}},"keys":[],"groups":[],"values":[{"name":"tripduration","index":1,"aggr":"sum"},{"name":"prediction","index":0,"aggr":"sum"}],"commonSetting":{}},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600412_883108158","id":"20170808-202112_1798282605","dateCreated":"2017-09-05T21:23:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:502"},{"text":"%md\n# Example of writing a DataFrame back to Object Store\n\nThe follow shows an example of writing a DataFrame back to the Object Store.  We use the write.df method from SparkR.  It supports multiple source types (csv, json, parquet, etc).","dateUpdated":"2017-09-05T21:23:20+0000","config":{"editorSetting":{"language":"text","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/text","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Example of writing a DataFrame back to Object Store</h1>\n<p>The follow shows an example of writing a DataFrame back to the Object Store. We use the write.df method from SparkR. It supports multiple source types (csv, json, parquet, etc).</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646600413_882723409","id":"20170811-191501_1517148443","dateCreated":"2017-09-05T21:23:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:503"},{"title":"R code to write our predictions back to the Object Store","text":"%r\n# Since we know the resulting file is small, we will do a repartition command to force Spark to write the output as a single file.  This is an optional step.\nfitted_singlepartition <- repartition(fitted,1)\nwrite.df(fitted_singlepartition, \"swift://journeyC.default/citibike/results/201612-fitted-projections\", source=\"csv\", mode=\"overwrite\")\n","dateUpdated":"2017-09-11T18:44:55+0000","config":{"editorSetting":{"language":"r","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/r","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"\n\n\n\n"}]},"apps":[],"jobName":"paragraph_1504646600413_882723409","id":"20170811-190712_164268436","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:504","user":"anonymous","dateFinished":"2017-09-11T18:45:15+0000","dateStarted":"2017-09-11T18:44:56+0000"},{"title":"Explore the contents of the Object Store","text":"%sh\n# this command will show you the contents of the Object Store that were just written\nhadoop fs -ls swift://journeyC.default/citibike/results/201612-fitted-projections\n","dateUpdated":"2017-09-11T18:45:29+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":"false"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600414_883877656","id":"20170807-214237_845297194","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:505","user":"anonymous","dateFinished":"2017-09-11T18:45:24+0000","dateStarted":"2017-09-11T18:45:20+0000"},{"text":"%md\n### Change Log\nSeptember 12, 2017 - Confirmed it works with 17.3.5\nAugust 13, 2017 - Confirmed it works with BDCSCE 17.3.3-20\nAugust 11, 2017 - First version\n","dateUpdated":"2017-09-11T18:45:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Change Log</h3>\n<p>September 12, 2017 - Confirmed it works with 17.3.5<br/>August 13, 2017 - Confirmed it works with BDCSCE 17.3.3-20<br/>August 11, 2017 - First version</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1504646600414_883877656","id":"20170811-191623_826620851","dateCreated":"2017-09-05T21:23:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:506","user":"anonymous","dateFinished":"2017-09-11T18:45:18+0000","dateStarted":"2017-09-11T18:45:18+0000"},{"text":"%md\n","dateUpdated":"2017-09-05T21:23:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":"true"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1504646600415_883492907","id":"20170811-191958_1291497317","dateCreated":"2017-09-05T21:23:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:507"}],"name":"DataSci Tutorial 2 Using R with Zeppelin","id":"2CUXNWME6","angularObjects":{"2CUR9TKC3:shared_process":[],"2CV6GZ6KY:shared_process":[],"2CRXRKTZS:shared_process":[],"2CUEWBE5C:shared_process":[],"2CUNV7BVE:shared_process":[],"2CRQ5UM9P:shared_process":[],"2CRHKT1V7:shared_process":[],"2C4U48MY3_spark2:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}