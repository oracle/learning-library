{"paragraphs":[{"text":"%md\n# xtra tutorial: Working with Oracle Data Visualization Desktop and Hive\n\nThis tutorial was built for BDCS-CE version 17.3.5-20 and Data Visualization Desktop 3.0 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>.  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\nOracle Data Visualization Desktop ( <a href=\"https://docs.oracle.com/middleware/bidv1221/desktop/index.html\" target=\"_blank\">here</a> ) is a lightweight, single-file download tool to easily analyze data.  Data Visualization Desktop can connect to a variety of data sources.  In this tutorial, we will show you how you can configure the HiveServer2 process in BDCS-CE so that DVD can connect.\n\n","dateUpdated":"2017-10-18T13:45:39+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>xtra tutorial: Working with Oracle Data Visualization Desktop and Hive</h1>\n<p>This tutorial was built for BDCS-CE version 17.3.5-20 and Data Visualization Desktop 3.0 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>. Questions and feedback about the tutorial: <a href=\"mailto:&#100;avi&#100;&#x2e;&#x62;&#x61;y&#x61;rd&#64;&#111;&#114;&#97;c&#108;&#101;&#46;&#x63;&#x6f;&#x6d;\">&#100;avi&#100;&#x2e;&#x62;&#x61;y&#x61;rd&#64;&#111;&#114;&#97;c&#108;&#101;&#46;&#x63;&#x6f;&#x6d;</a></p>\n<p>Oracle Data Visualization Desktop ( <a href=\"https://docs.oracle.com/middleware/bidv1221/desktop/index.html\" target=\"_blank\">here</a> ) is a lightweight, single-file download tool to easily analyze data. Data Visualization Desktop can connect to a variety of data sources. In this tutorial, we will show you how you can configure the HiveServer2 process in BDCS-CE so that DVD can connect.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507665740033_-271092432","id":"20170504-171842_974565851","dateCreated":"2017-10-10T20:02:20+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:618","user":"anonymous","dateFinished":"2017-10-18T13:45:39+0000","dateStarted":"2017-10-18T13:45:39+0000"},{"text":"%md\n# Configuring the HiveServer2 process to use binary transport\n\nIn order to connect to Hive from DVD, we need to configure BDCS-CE's Hive Thrift Server to use the binary transport protocol.  By default, BDCS-CE's hive thrift server is configured to use the http transport protocol.  These changes are done using the Ambari web console.\n\nHere are the steps:\n\n1.Follow the note \"xtra Connecting to Ambari\" to login to Ambari.\n2.Once connected to Ambari, click on \"Hive\" on the left-hand list of services\n3.Then click on the \"Configs\" tab\n4.In the search box, type \"server2\"\n5.Click on the Advanced sub-tab\n6.In the General section, change the \"HiveServer2 Port\" to 10002 (it defaults to 10000, but that port will already be in use for something else)\n7.Also in the General section, change the \"hive.server2.transport.mode\" to binary.\n8.In the Custom hive-site section, delete the \"hive.server2.thrift.bind.host\" property (by clicking on the red minus symbol)\n9.Click save\n10.In the notes field, enter \"transport mode\"\n11.Click save again\n12.If you see a \"Configurations\" pop-up, click \"Proceed Anyway\"\n13.Click OK to acknowledge that changes were made successfully\n14.Then click Restart, then Restart All Affected\n15.Then click Confirm Restart All\n\n![AmbariHiveBinary](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/AmbariHiveBinary.gif)\n\n","dateUpdated":"2017-10-10T20:02:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Configuring the HiveServer2 process to use binary transport</h1>\n<p>In order to connect to Hive from DVD, we need to configure BDCS-CE&rsquo;s Hive Thrift Server to use the binary transport protocol. By default, BDCS-CE&rsquo;s hive thrift server is configured to use the http transport protocol. These changes are done using the Ambari web console.</p>\n<p>Here are the steps:</p>\n<p>1.Follow the note &ldquo;xtra Connecting to Ambari&rdquo; to login to Ambari.<br/>2.Once connected to Ambari, click on &ldquo;Hive&rdquo; on the left-hand list of services<br/>3.Then click on the &ldquo;Configs&rdquo; tab<br/>4.In the search box, type &ldquo;server2&rdquo;<br/>5.Click on the Advanced sub-tab<br/>6.In the General section, change the &ldquo;HiveServer2 Port&rdquo; to 10002 (it defaults to 10000, but that port will already be in use for something else)<br/>7.Also in the General section, change the &ldquo;hive.server2.transport.mode&rdquo; to binary.<br/>8.In the Custom hive-site section, delete the &ldquo;hive.server2.thrift.bind.host&rdquo; property (by clicking on the red minus symbol)<br/>9.Click save<br/>10.In the notes field, enter &ldquo;transport mode&rdquo;<br/>11.Click save again<br/>12.If you see a &ldquo;Configurations&rdquo; pop-up, click &ldquo;Proceed Anyway&rdquo;<br/>13.Click OK to acknowledge that changes were made successfully<br/>14.Then click Restart, then Restart All Affected<br/>15.Then click Confirm Restart All</p>\n<p><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/300/AmbariHiveBinary.gif\" alt=\"AmbariHiveBinary\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507665740040_-273785675","id":"20170910-212147_1316147767","dateCreated":"2017-10-10T20:02:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:621"},{"text":"%md\n# Connecting to the HiveServer2 port\n\nNow, you need to decide how you want to connect to the Hive Thrift Server port, which you set to port 10002.  You can either choose to use a SSH tunnel (which is very secure) or choose to open port 10002 to the outside world (which can be less secure).\n\n+ If you want to use a SSH tunnel, refer to the note \"xtra Connecting to Ambari\" which has an example of setting up a SSH tunnel (but you would use port 10002 instead of Ambari's 8080).\n+ If you want to open up port 10002, you will need to create a new access rule for port 10002.  Refer to the note \"xtra Connecting via SSH\" or \"OEHCS Tutorial 1\" for examples of working with network access rules.\n\n","dateUpdated":"2017-10-10T20:02:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Connecting to the HiveServer2 port</h1>\n<p>Now, you need to decide how you want to connect to the Hive Thrift Server port, which you set to port 10002. You can either choose to use a SSH tunnel (which is very secure) or choose to open port 10002 to the outside world (which can be less secure).</p>\n<ul>\n  <li>If you want to use a SSH tunnel, refer to the note &ldquo;xtra Connecting to Ambari&rdquo; which has an example of setting up a SSH tunnel (but you would use port 10002 instead of Ambari&rsquo;s 8080).</li>\n  <li>If you want to open up port 10002, you will need to create a new access rule for port 10002. Refer to the note &ldquo;xtra Connecting via SSH&rdquo; or &ldquo;OEHCS Tutorial 1&rdquo; for examples of working with network access rules.</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1507665740040_-273785675","id":"20170910-213057_586545895","dateCreated":"2017-10-10T20:02:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:622"},{"text":"%md\n## Note about the jdbc interpreter\n\nWhen you make the above changes to the HiveServer2 port and transport mode, you will break the configuration of the jdbc interpreter in Zeppelin.  If you want to fix it, navigate to Settings..Notebook..JDBC Interpreter and adjust the hive.url parameter to jdbc:hive2://localhost:10002/","dateUpdated":"2017-10-10T20:02:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Note about the jdbc interpreter</h2>\n<p>When you make the above changes to the HiveServer2 port and transport mode, you will break the configuration of the jdbc interpreter in Zeppelin. If you want to fix it, navigate to Settings..Notebook..JDBC Interpreter and adjust the hive.url parameter to jdbc:hive2://localhost:10002/</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507665740041_-274170424","id":"20170914-163532_877686177","dateCreated":"2017-10-10T20:02:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:623"},{"text":"%md\n# Define a connection in DV Desktop for the Hive connection\n\n+ Open up DV Desktop\n+ Click on Data Sources\n+ Click on Connection (Under Create)\n+ Click on Hortonworks Hive\n+ Enter the Connection Name\n+ Enter the Hostname.  If you chose to use SSH tunneling, enter \"127.0.0.1\" for the hostname.  If you chose to open port 10002 to the outside, enter the hostname or ip address of your BDCS-CE server.\n+ Enter to port, which is 10002\n+ Set the Username to hive\n+ Set the Password to x\n\n![DVDconnection](https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/DVDconnection.gif)\n\n\n\n\n","dateUpdated":"2017-10-10T20:02:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Define a connection in DV Desktop for the Hive connection</h1>\n<ul>\n  <li>Open up DV Desktop</li>\n  <li>Click on Data Sources</li>\n  <li>Click on Connection (Under Create)</li>\n  <li>Click on Hortonworks Hive</li>\n  <li>Enter the Connection Name</li>\n  <li>Enter the Hostname. If you chose to use SSH tunneling, enter &ldquo;127.0.0.1&rdquo; for the hostname. If you chose to open port 10002 to the outside, enter the hostname or ip address of your BDCS-CE server.</li>\n  <li>Enter to port, which is 10002</li>\n  <li>Set the Username to hive</li>\n  <li>Set the Password to x</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/DVDconnection.gif\" alt=\"DVDconnection\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507665740041_-274170424","id":"20170728-174228_1743240708","dateCreated":"2017-10-10T20:02:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:624"},{"text":"%md\n# Create a DV Desktop Data Source for your connection\n\n+ Double click on your Connection\n+ Double click on the default database\n+ Double click on the bike_trips_small table\n+ Click on Add All\n+ Now click on the rightmost icon in the dataflow pipeline (it will be the icon after the filter icon). Then, click on the Refresh property. Change this to be “Live - Always use the database”. **NOTE: This step is not yet captured in the screenshot below**\n+ Click on Add\n+ Click Create Project\n\n![DVDdatasource](https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/DVDdatasource.gif \"HODBC\")\n","dateUpdated":"2017-10-10T20:02:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Create a DV Desktop Data Source for your connection</h1>\n<ul>\n  <li>Double click on your Connection</li>\n  <li>Double click on the default database</li>\n  <li>Double click on the bike_trips_small table</li>\n  <li>Click on Add All</li>\n  <li>Now click on the rightmost icon in the dataflow pipeline (it will be the icon after the filter icon). Then, click on the Refresh property. Change this to be “Live - Always use the database”. <strong>NOTE: This step is not yet captured in the screenshot below</strong></li>\n  <li>Click on Add</li>\n  <li>Click Create Project</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/millerhoo/journey2-new-data-lake/master/workshops/journey2-new-data-lake/images/300/DVDdatasource.gif\" alt=\"DVDdatasource\" title=\"HODBC\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507665740041_-274170424","id":"20170731-202416_1602004865","dateCreated":"2017-10-10T20:02:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:625"},{"text":"%md\n# Tip - Viewing the Hive queries issued by DVD\n\nRun the following shell paragraph to see the recent SQL commands sent to the Hive Server. ","dateUpdated":"2017-10-10T20:02:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":"true"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Tip - Viewing the Hive queries issued by DVD</h1>\n<p>Run the following shell paragraph to see the recent SQL commands sent to the Hive Server.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1507665740045_-275709419","id":"20170911-184628_727273517","dateCreated":"2017-10-10T20:02:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:627"},{"title":"Shell command to see the recent SQL sent to Hive Server","text":"%sh\n#grep \"Parsing command\" /data/var/log/hive/hiveserver2.log | tail -300\negrep $'Parsing|\\x0d|limit|group' /data/var/log/hive/hiveserver2.log | tail -300","dateUpdated":"2017-10-10T20:02:20+0000","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":"false"},"colWidth":12,"editorMode":"ace/mode/sh","editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2017-09-21 14:14:23,972 INFO  [HiveServer2-Handler-Pool: Thread-42]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: use default\n2017-09-21 14:14:24,263 INFO  [HiveServer2-Handler-Pool: Thread-42]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: select T1000002.TRIPDURATION as `TRIPDURATION` from (select TRIPDURATION, BIKEID, BIRTHYEAR, ENDSTATIONID, ENDSTATIONLATITUDE, ENDSTATIONLONGITUDE, ENDSTATIONNAME, GENDER, STARTSTATIONID, STARTSTATIONLATITUDE, STARTSTATIONLONGITUDE, STARTSTATIONNAME, STARTTIME, STOPTIME, USERTYPE from default.bike_trips bike_trips) T1000002\n2017-09-21 14:15:24,710 INFO  [HiveServer2-Handler-Pool: Thread-47]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: use default\n2017-09-21 14:15:25,022 INFO  [HiveServer2-Handler-Pool: Thread-47]: parse.ParseDriver (ParseDriver.java:parse(185)) - Parsing command: select 0 as `c1`,\r\n     D101.c1 as `c2`,\r\n     0 as `c6`,\r\n     0 as `c7`,\r\n     0 as `c8`,\r\n     D101.c2 as `c12`\r\nfrom \r\n     (select T1000002.GENDER as `c1`,\r\n               T1000002.TRIPDURATION as `c2`\r\n          from \r\n               (select TRIPDURATION, BIKEID, BIRTHYEAR, ENDSTATIONID, ENDSTATIONLATITUDE, ENDSTATIONLONGITUDE, ENDSTATIONNAME, GENDER, STARTSTATIONID, STARTSTATIONLATITUDE, STARTSTATIONLONGITUDE, STARTSTATIONNAME, STARTTIME, STOPTIME, USERTYPE from default.bike_trips bike_trips) T1000002\r\n"}]},"apps":[],"jobName":"paragraph_1507665740045_-275709419","id":"20170911-184719_1445882523","dateCreated":"2017-10-10T20:02:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:628"},{"text":"%md\n","dateUpdated":"2017-10-10T20:02:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":"true"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1507665740046_-274555173","id":"20170920-211628_15062498","dateCreated":"2017-10-10T20:02:20+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:630"}],"name":"xtra Connecting DV Desktop and Hive","id":"2CWJJW6NN","angularObjects":{"2CXZJ9QJB:shared_process":[],"2CXPDTWPH:shared_process":[],"2CWDYXPTB:shared_process":[],"2CVW3CJG6:shared_process":[],"2CUQSP17V:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CWBKB9Z5:shared_process":[],"2CX6D87EF:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}