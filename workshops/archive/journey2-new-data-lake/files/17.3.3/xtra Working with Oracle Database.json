{"paragraphs":[{"text":"%md\n# xtra Tutorial: Working with Oracle Database\n\nThis tutorial was built for BDCS-CE version 17.3.3-20 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>.  Questions and feedback about the tutorial: <david.bayard@oracle.com>\n\nContents\n\n + Identifying your Oracle Database Cloud Service connection details\n + Setting up an Access Rule for DBCS to allow BDCS-CE to connect\n + Using the Zeppelin JDBC Interpreter to query the Oracle Database\n + Examples with the JDBC Interpreter\n + Using Spark to query the Oracle Database\n + Examples with Spark SQL\n + Using Spark to write to the Oracle Database\n + Examples writing to the Oracle Database\n\n","user":"anonymous","dateUpdated":"2017-08-13T18:42:31+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>xtra Tutorial: Working with Oracle Database</h1>\n<p>This tutorial was built for BDCS-CE version 17.3.3-20 as part of the New Data Lake User Journey: <a href=\"https://github.com/oracle/learning-library/tree/master/workshops/journey2-new-data-lake\" target=\"_blank\">here</a>. Questions and feedback about the tutorial: <a href=\"mailto:&#100;a&#118;&#x69;&#x64;&#x2e;&#x62;&#97;&#x79;&#x61;r&#100;&#x40;&#111;r&#97;&#99;&#108;e&#46;c&#x6f;&#109;\">&#100;a&#118;&#x69;&#x64;&#x2e;&#x62;&#97;&#x79;&#x61;r&#100;&#x40;&#111;r&#97;&#99;&#108;e&#46;c&#x6f;&#109;</a></p>\n<p>Contents</p>\n<ul>\n  <li>Identifying your Oracle Database Cloud Service connection details</li>\n  <li>Setting up an Access Rule for DBCS to allow BDCS-CE to connect</li>\n  <li>Using the Zeppelin JDBC Interpreter to query the Oracle Database</li>\n  <li>Examples with the JDBC Interpreter</li>\n  <li>Using Spark to query the Oracle Database</li>\n  <li>Examples with Spark SQL</li>\n  <li>Using Spark to write to the Oracle Database</li>\n  <li>Examples writing to the Oracle Database</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1502648591360_759295215","id":"20170414-115315_151675592","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T18:42:31+0000","dateFinished":"2017-08-13T18:42:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:274"},{"text":"%md\n# Identifying your Oracle Database Cloud Service Connection Details\n\nThis tutorial will assume you are using an Oracle Database running in the Oracle Database Cloud Service.  To connect from BDCS-CE, we need to:\n\n + Identify the database connect string (which embeds the database hostname and service name)\n + Ensure that an Access Rule allows network traffic from BDCS-CE to the Database server\n\nIn general, a very useful resource will be the \"Oracle Database Cloud - Database as a Service Quick Start\" which can be found <a href=\"http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html\" target=\"_blank\">here</a>.  In particular, the topic \"Finding the Connection Details for your Database Instance\" provides the necessary details.  For simplicity, we will repeat the steps here:\n\nFollow these steps:\n\n + Navigate to the Oracle Database Cloud Service page for your DBCS instance.\n + Click on the Connect String to see the full value, highlight the full connect string, copy it into the clipboard, and save it somewhere for later use.\n![DBCS](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSconnectstring.gif \"DBCS\")\n\n \n\n","user":"anonymous","dateUpdated":"2017-08-13T19:19:13+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Identifying your Oracle Database Cloud Service Connection Details</h1>\n<p>This tutorial will assume you are using an Oracle Database running in the Oracle Database Cloud Service. To connect from BDCS-CE, we need to:</p>\n<ul>\n  <li>Identify the database connect string (which embeds the database hostname and service name)</li>\n  <li>Ensure that an Access Rule allows network traffic from BDCS-CE to the Database server</li>\n</ul>\n<p>In general, a very useful resource will be the &ldquo;Oracle Database Cloud - Database as a Service Quick Start&rdquo; which can be found <a href=\"http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html\" target=\"_blank\">here</a>. In particular, the topic &ldquo;Finding the Connection Details for your Database Instance&rdquo; provides the necessary details. For simplicity, we will repeat the steps here:</p>\n<p>Follow these steps:</p>\n<ul>\n  <li>Navigate to the Oracle Database Cloud Service page for your DBCS instance.</li>\n  <li>Click on the Connect String to see the full value, highlight the full connect string, copy it into the clipboard, and save it somewhere for later use.<br/><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSconnectstring.gif\" alt=\"DBCS\" title=\"DBCS\" /></li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1502648591361_758910467","id":"20170504-100100_110721875","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:19:13+0000","dateFinished":"2017-08-13T19:19:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:275"},{"title":"Shell command to identify the private IP address of your BDCS-CE instance (used by next paragraph)","text":"%sh\nifconfig eth0","user":"anonymous","dateUpdated":"2017-08-13T19:11:27+0000","config":{"colWidth":12,"editorMode":"ace/mode/sh","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"editOnDblClick":"false","language":"sh"},"editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648591362_760064713","id":"20170701-092625_199273309","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:11:17+0000","dateFinished":"2017-08-13T19:11:18+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:276"},{"text":"%md\n# Setting up an Access Rule for DBCS to allow BDCS-CE to connect\n\nWe need to ensure that your BDCS-CE instance can communicate with the database listener (port 1521) in your DBCS instance.  If you defined an Association between your BDCS-CE instance and your DBCS database when you created your BDCS-CE instance, then this access rule was created for you.  \n\nMost likely, you probably did NOT define an association between your DBCS database and your BDCS-CE instance at the time you provisioned the BDCS-CE instance.  Therefore, you will probably need to manually define a new access rule.  For this manually defined rule, you will need to use the private IP address of your BDCS-CE instance, which can be looked up via running the shell paragraph above.\n\nFor reference, review the  “Oracle Database Cloud - Database as a Service Quick Start” which can be found <a href=\"http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html\" target=\"_blank\">here</a>. In particular, the topic “Enabling Secure Network Access to your Database Instance” provides the necessary details. \n\nHere is an animation showing you how to:\n\n- Identify the private IP address of your BDCS-CE instance\n- Navigate to the DBCS instance console\n- Add a new Access Rule to the DBCS instance\n\n\n![DBCS2](https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSaccess.gif \"DBCS2\")","user":"anonymous","dateUpdated":"2017-08-13T19:12:56+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Setting up an Access Rule for DBCS to allow BDCS-CE to connect</h1>\n<p>We need to ensure that your BDCS-CE instance can communicate with the database listener (port 1521) in your DBCS instance. If you defined an Association between your BDCS-CE instance and your DBCS database when you created your BDCS-CE instance, then this access rule was created for you. </p>\n<p>Most likely, you probably did NOT define an association between your DBCS database and your BDCS-CE instance at the time you provisioned the BDCS-CE instance. Therefore, you will probably need to manually define a new access rule. For this manually defined rule, you will need to use the private IP address of your BDCS-CE instance, which can be looked up via running the shell paragraph above.</p>\n<p>For reference, review the “Oracle Database Cloud - Database as a Service Quick Start” which can be found <a href=\"http://www.oracle.com/webfolder/technetwork/tutorials/obe/cloud/dbaas/obe_dbaas_QS/oracle_database_cloud_service_dbaas_quick_start.html\" target=\"_blank\">here</a>. In particular, the topic “Enabling Secure Network Access to your Database Instance” provides the necessary details. </p>\n<p>Here is an animation showing you how to:</p>\n<ul>\n  <li>Identify the private IP address of your BDCS-CE instance</li>\n  <li>Navigate to the DBCS instance console</li>\n  <li>Add a new Access Rule to the DBCS instance</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/oracle/learning-library/master/workshops/journey2-new-data-lake/images/600/DBCSaccess.gif\" alt=\"DBCS2\" title=\"DBCS2\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1502648591362_760064713","id":"20170701-085521_963139788","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:12:56+0000","dateFinished":"2017-08-13T19:12:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:277"},{"title":"Script to set the Zeppelin JDBC settings for Oracle","text":"%sh\n#curl -X GET http://127.0.0.1:9995/api/interpreter/setting | python -m json.tool\n\necho \"Script to set some zeppelin jdbc parameters\"\n\necho \"Set the User, Password, and ConnectString parameters in the script as appropriate\"\nUser=scott\nPassword=tiger\nConnectString=\"CD-DBCS-ORCL12:1521/PDB1.gse00010212.oraclecloud.internal\"\necho $ConnectString\n\ncat <<EOF > /tmp/jdbc_settings.py\n#!/usr/local/bin/python\n#based on https://community.hortonworks.com/articles/36031/sample-code-to-automate-interacting-with-zeppelin.html by Ali Bajwa\ndef post_request(url, body):\n  import json, urllib2\n  encoded_body = json.dumps(body)\n  req = urllib2.Request(str(url), encoded_body)\n  req.get_method = lambda: 'PUT'\n  try:\n    response = urllib2.urlopen(req, encoded_body).read()\n  except urllib2.HTTPError, error:\n    print 'Exception: ' + error.read()\n  jsonresp = json.loads(response.decode('utf-8'))\n  print jsonresp['status']\n        \n \n \nimport json, urllib2\nzeppelin_int_url = 'http://127.0.0.1:9995/api/interpreter/setting/'\ndata = json.load(urllib2.urlopen(zeppelin_int_url))\nfor body in data['body']:\n  if body['group'] == 'jdbc':\n    jdbcbody = body\n  elif body['group'] == 'spark':\n    sparkbody = body    \n    \n\n \njdbcbody['properties']['orcl.driver'] = 'oracle.jdbc.OracleDriver'\njdbcbody['properties']['orcl.user'] = '$User'\n#jdbcbody['properties']['orcl.password'] = '$Password'  \n#Zeppelin seems to be setting password to null, so leave it out\n#so for now, put the password in the connect string\njdbcbody['properties']['orcl.url'] = 'jdbc:oracle:thin:$User/$Password@//$ConnectString'\n\n\nmy_dict = {'groupArtifactVersion':  '/u01/bdcsce/opt/oracle/bdcsce/current/lib/ojdbc7.jar',       'local': False}\njdbcbody['dependencies'].append(my_dict)\npost_request(zeppelin_int_url + jdbcbody['id'], jdbcbody)\nEOF\ncat /tmp/jdbc_settings.py\necho \"..\"\npython /tmp/jdbc_settings.py\n\necho \"..\"\n\n#make a small permission fix so that spark can query the local file system for later in this tutorial\nchmod a+rx /var/lib/zeppelin\necho \"done\"","user":"anonymous","dateUpdated":"2017-08-13T19:19:24+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":"false"},"editorMode":"ace/mode/sh","editorHide":false,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502649775218_2060806034","id":"20170813-184255_14699384","dateCreated":"2017-08-13T18:42:55+0000","dateStarted":"2017-08-13T19:16:10+0000","dateFinished":"2017-08-13T19:16:10+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:278"},{"title":"Example of JDBC(orcl)","text":"%jdbc(orcl)\nselect table_name from user_tables","user":"anonymous","dateUpdated":"2017-08-13T19:20:32+0000","config":{"colWidth":4,"editorMode":"ace/mode/text","editorHide":false,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":false,"language":"text"},"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648591364_757756220","id":"20170504-132054_979805353","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:00:22+0000","dateFinished":"2017-08-13T19:01:21+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:279"},{"title":"JDBC Interpreter in action","text":"%jdbc(orcl)\nselect * from emp","user":"anonymous","dateUpdated":"2017-08-13T19:04:53+0000","config":{"colWidth":8,"editorMode":"ace/mode/text","editorHide":false,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"EMPNO","index":0,"aggr":"sum"}],"values":[{"name":"ENAME","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"EMPNO","index":0,"aggr":"sum"},"yAxis":{"name":"ENAME","index":1,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"editOnDblClick":false,"language":"text"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648591364_757756220","id":"20170414-115717_230408128","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:04:53+0000","dateFinished":"2017-08-13T19:05:19+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:280"},{"title":"Another example","text":"%jdbc(orcl)\nselect deptno, count(*) from emp group by deptno","user":"anonymous","dateUpdated":"2017-08-13T19:23:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/text","editorHide":false,"results":[{"graph":{"mode":"pieChart","height":300,"optionOpen":false,"keys":[{"name":"DEPTNO","index":0,"aggr":"sum"}],"values":[{"name":"COUNT(*)","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"DEPTNO","index":0,"aggr":"sum"},"yAxis":{"name":"COUNT(*)","index":1,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"editOnDblClick":false,"language":"text"},"title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648591365_757371471","id":"20170504-132141_1183948525","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:23:50+0000","dateFinished":"2017-08-13T19:24:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:281","errorMessage":""},{"text":"%md\n# Using Spark to query the Oracle Database\n\nIn this section of the tutorial, we will show you working code examples that define a Spark Dataframe as an Oracle SQL query.  We then define a Spark SQL temporary table against that Dataframe to show you how you can futher use Spark SQL to filter and manipulate your selected data.\n\nTo run the spark code, you should **first edit the code and insert your specific database connect string, username, and password**.\n\n\n\nTo learn more about how Spark Data Frames work with JDBC data sources, check out <a href=\"https://spark.apache.org/docs/2.1.0/sql-programming-guide.html#jdbc-to-other-databases\" target=\"_blank\">here</a>.\n\n\n\n\n","user":"anonymous","dateUpdated":"2017-08-13T19:10:26+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Using Spark to query the Oracle Database</h1>\n<p>In this section of the tutorial, we will show you working code examples that define a Spark Dataframe as an Oracle SQL query. We then define a Spark SQL temporary table against that Dataframe to show you how you can futher use Spark SQL to filter and manipulate your selected data.</p>\n<p>To run the spark code, you should <strong>first edit the code and insert your specific database connect string, username, and password</strong>.</p>\n<p>To learn more about how Spark Data Frames work with JDBC data sources, check out <a href=\"https://spark.apache.org/docs/2.1.0/sql-programming-guide.html#jdbc-to-other-databases\" target=\"_blank\">here</a>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1502648591365_757371471","id":"20170414-115733_409524242","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:10:26+0000","dateFinished":"2017-08-13T19:10:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:282"},{"title":"Spark code to query the Oracle Database and define results and Spark SQL tables","text":"%spark\n\n// BEFORE RUNNING THIS, YOU WILL NEED TO EDIT THIS\n//  1.Insert your database Connect String\n//  2.Insert your database user name\n//  3.Insert your database password\n\n\n//define URL for the Oracle JDBC driver\nprintln(\">>>>>>>Defining url for Oracle JDBC\")\n\nval url=\"jdbc:oracle:thin:@//\" + \"CD-DBCS-ORCL12:1521/PDB1.gse00010212.oraclecloud.internal\"\n\n//define the username and password as properties\nprintln(\">>>>>>>Defining Oracle JDBC username and password\")\nval prop = new java.util.Properties\n\n\nprop.setProperty(\"user\",\"scott\")\nprop.setProperty(\"password\",\"tiger\")\n\n\nprop.setProperty(\"driver\",\"oracle.jdbc.OracleDriver\") //the driver is needed to be defined with Spark 1.6.1 due to https://issues.apache.org/jira/browse/SPARK-14204\n\n//now you can use JDBC commands like: val movies = sqlContext.read.jdbc(url,\"movie\",prop)\nval emp = sqlContext.read.jdbc(url,\"emp\",prop)\n//emp.explain()\nemp.printSchema()\nemp.show()\n\n//register the emp dataframe as a SparkSQL table\nemp.registerTempTable(\"emp_sparksql\")\n\n//we can also do specific queries like the following (note that we write our query as if it was a subquery in the FROM section of a select statement)\nval emp_query = sqlContext.read.jdbc(url, \"(select e.deptno, d.dname, count(*) dcount from emp e, dept d where e.deptno=d.deptno group by e.deptno, d.dname) eq\", prop)\nemp_query.show()\n//emp_query.explain()\n\nprintln(\"done\")","user":"anonymous","dateUpdated":"2017-08-13T19:25:14+0000","config":{"tableHide":false,"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648591366_758525718","id":"20170414-115750_30775030","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:25:14+0000","dateFinished":"2017-08-13T19:26:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:283","errorMessage":""},{"title":"SparkSQL Example against our Oracle Database-based Data Frame","text":"%sql\nselect * from emp_sparksql\nwhere deptno=10","user":"anonymous","dateUpdated":"2017-08-13T19:27:13+0000","config":{"colWidth":12,"editorMode":"ace/mode/sql","editorHide":false,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"EMPNO","index":0,"aggr":"sum"}],"values":[{"name":"ENAME","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"EMPNO","index":0,"aggr":"sum"},"yAxis":{"name":"ENAME","index":1,"aggr":"sum"}}}}],"enabled":true,"editorSetting":{"language":"sql"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648591367_758140969","id":"20170414-120105_774930594","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:27:13+0000","dateFinished":"2017-08-13T19:27:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:284","errorMessage":""},{"text":"%md\n# Using Spark to write to the Oracle Database\n\nNow we will show a working example of writing back to the Oracle Database from Spark.  If you observed above, we created a Spark dataframe called emp_query.  In the following example, we will write this dataframe back to the Oracle Database as a new table called emp_query.\n\nFor this example, we will use Spark to read in some Citibike data and write that data into an Oracle table.\n","user":"anonymous","dateUpdated":"2017-08-13T19:12:34+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":"true","language":"markdown"},"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Using Spark to write to the Oracle Database</h1>\n<p>Now we will show a working example of writing back to the Oracle Database from Spark. If you observed above, we created a Spark dataframe called emp_query. In the following example, we will write this dataframe back to the Oracle Database as a new table called emp_query.</p>\n<p>For this example, we will use Spark to read in some Citibike data and write that data into an Oracle table.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1502648591367_758140969","id":"20170504-134249_302037388","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:12:34+0000","dateFinished":"2017-08-13T19:12:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:285"},{"title":"Spark Scala to read CSV and register as Spark SQL temporary table","text":"%spark\n\n//a previous tutorial placed the csv file into /var/lib/zeppelin/bikes/201612-citibike-tripdata.csv\n\nval df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"file:/var/lib/zeppelin/citibike/201612-citibike-tripdata.csv\")\n\n//cache the data frame for performance\ndf.cache()\n\n\nprintln(\"Here is the schema detected from the CSV\")\ndf.printSchema()\nprintln(\"..\")\n\nprintln(\"# of rows: %s\".format(\n  df.count() \n)) \nprintln(\"..\")\n\ndf.registerTempTable(\"bike_trips_csvtemp\")\nprintln(\"done\")","user":"anonymous","dateUpdated":"2017-08-13T19:27:36+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648591370_756986722","id":"20170701-170923_1753081660","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:27:36+0000","dateFinished":"2017-08-13T19:27:50+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:286","errorMessage":""},{"title":"Spark to write a DataFrame to an Oracle table","text":"%spark\n\n\n\n// To make sure we have Oracle friendly column names, lets select against our Spark SQL temp table and rename columns\nprintln(\"Renaming column names via bike_query...\")\nval bike_query = sqlContext.sql(\"\"\"select `Trip Duration` TRIPDURATION, \n`Start Time` STARTTIME, \n`Stop Time` STOPTIME, \n`Start Station ID` STARTSTATIONID, \n`Start Station Name` STARTSTATIONNAME, \n`Start Station Latitude` STARTSTATIONLATITUDE, \n`Start Station Longitude` STARTSTATIONLONGITUDE, \n`End Station ID` ENDSTATIONID, \n`End Station Name` ENDSTATIONNAME, \n`End Station Latitude` ENDSTATIONLATITUDE, \n`End Station Longitude` ENDSTATIONLONGITUDE, \n`Bike ID` BIKEID, \n`User Type` USERTYPE, \n`Birth Year` BIRTHYEAR, \n`Gender` GENDER \n from bike_trips_csvtemp\"\"\")\n \nbike_query.show()\nbike_query.printSchema()\n\n\nimport org.apache.spark.sql.SaveMode\n//possible SaveModes are SaveMode.Append, SaveMode.Overwrite, SaveMode.ErrorIfExists, SaveMode.Ignore\n\n\nprintln(\"Writing Spark DataFrame to Oracle Database.  This may take a few minutes.\")\nbike_query.write\n   .mode(SaveMode.Overwrite)\n   .jdbc(url,\"CITIBIKE_ORCL\",prop)\n\n\n//your Spark dataframe needs to use valid Oracle column names (i.e. no spaces, no reserved words, etc).  If you need to rename dataframe fields, you can do operations like this\n//val newdDF=oldDF.withColumnRenamed(\"Birth Year\",\"BirthYear\")\n\n\nprintln(\"done\")","user":"anonymous","dateUpdated":"2017-08-13T19:28:51+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648752832_403785587","id":"20170813-182552_758023941","dateCreated":"2017-08-13T18:25:52+0000","dateStarted":"2017-08-13T19:28:51+0000","dateFinished":"2017-08-13T19:29:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:287","errorMessage":""},{"text":"%jdbc(orcl)\nselect * from CITIBIKE_ORCL","user":"anonymous","dateUpdated":"2017-08-13T19:29:29+0000","config":{"colWidth":12,"editorMode":"ace/mode/text","editorHide":false,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true,"editorSetting":{"editOnDblClick":false,"language":"text"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648591371_756601973","id":"20170504-145612_585260865","dateCreated":"2017-08-13T18:23:11+0000","dateStarted":"2017-08-13T19:29:29+0000","dateFinished":"2017-08-13T19:29:55+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:288"},{"dateUpdated":"2017-08-13T18:23:11+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1502648591377_765066449","id":"20170414-131833_1025546137","dateCreated":"2017-08-13T18:23:11+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:289"}],"name":"xtra Working with Oracle Database","id":"2CPUME2RP","angularObjects":{"2CQA2VQ3C:shared_process":[],"2CSX451P1:shared_process":[],"2CQH9FYAV:shared_process":[],"2CPQ7W1ZD:shared_process":[],"2CQDB4M3A:shared_process":[],"2CSD8BUF1:shared_process":[],"2C4U48MY3_spark2:shared_process":[],"2CRZ9M6JB:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}